{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddba29aa-4893-4363-90d3-76b04f3c0c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: avalanche-lib==0.5 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (4.11.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (5.9.0)\n",
      "Requirement already satisfied: gputil in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (1.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (1.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (3.7.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (1.24.3)\n",
      "Requirement already satisfied: pytorchcv in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (0.0.67)\n",
      "Requirement already satisfied: wandb in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (0.17.3)\n",
      "Requirement already satisfied: tensorboard>=1.15 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (2.14.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (4.66.4)\n",
      "Requirement already satisfied: torch in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (0.15.0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (1.4.0.post0)\n",
      "Requirement already satisfied: gdown in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (5.2.0)\n",
      "Requirement already satisfied: qpsolvers[open_source_solvers] in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (4.2.0)\n",
      "Requirement already satisfied: dill in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (0.3.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from avalanche-lib==0.5) (23.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (1.64.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (3.6)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (5.27.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (2.32.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (3.0.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tensorboard>=1.15->avalanche-lib==0.5) (0.43.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from gdown->avalanche-lib==0.5) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from gdown->avalanche-lib==0.5) (3.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from matplotlib->avalanche-lib==0.5) (6.1.1)\n",
      "Requirement already satisfied: daqp>=0.5.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.5.1)\n",
      "Requirement already satisfied: ecos>=2.0.8 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (2.0.14)\n",
      "Requirement already satisfied: osqp>=0.6.2 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.6.7.post0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (1.10.1)\n",
      "Requirement already satisfied: scs>=3.2.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (3.2.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from scikit-learn->avalanche-lib==0.5) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from scikit-learn->avalanche-lib==0.5) (3.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from torch->avalanche-lib==0.5) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from torch->avalanche-lib==0.5) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from torch->avalanche-lib==0.5) (3.1.4)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from torchmetrics->avalanche-lib==0.5) (0.11.3.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from tqdm->avalanche-lib==0.5) (0.4.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (3.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (6.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (2.7.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from wandb->avalanche-lib==0.5) (1.3.3)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb->avalanche-lib==0.5) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.5) (4.0.11)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.5) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.5) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.5) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->avalanche-lib==0.5) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->avalanche-lib==0.5) (3.17.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=1.15->avalanche-lib==0.5) (7.0.1)\n",
      "Requirement already satisfied: qdldl in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from osqp>=0.6.2->qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.1.7.post4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.5) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.5) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.5) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib==0.5) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.5) (2.1.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from beautifulsoup4->gdown->avalanche-lib==0.5) (2.5)\n",
      "Requirement already satisfied: piqp>=0.2.2 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.4.1)\n",
      "Requirement already satisfied: proxsuite>=0.2.9 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.6.6)\n",
      "Requirement already satisfied: clarabel>=0.4.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.9.0)\n",
      "Requirement already satisfied: cvxopt>=1.2.6 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (1.3.2)\n",
      "Requirement already satisfied: highspy>=1.1.2.dev3 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (1.7.2)\n",
      "Requirement already satisfied: qpalm>=1.2.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (1.2.3)\n",
      "Requirement already satisfied: quadprog>=0.1.11 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.1.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from requests[socks]->gdown->avalanche-lib==0.5) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from sympy->torch->avalanche-lib==0.5) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.5) (5.0.1)\n",
      "Requirement already satisfied: cmeel in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.5) (0.53.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib==0.5) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15->avalanche-lib==0.5) (3.2.2)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in c:\\users\\ahmed\\anaconda3\\envs\\ddp\\lib\\site-packages (from cmeel->proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.5) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: qpsolvers 4.2.0 does not provide the extra 'open-source-solvers'\n"
     ]
    }
   ],
   "source": [
    "pip install avalanche-lib==0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a87dda-6a58-438f-8c8e-eee309fc4cd0",
   "metadata": {},
   "source": [
    "# importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d61f42-6d82-4ab3-a321-3d23f59cf87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num. examples processed: 50000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "import avalanche.checkpointing.checkpoint\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Correctly loading CIFAR10 and CIFAR100 datasets\n",
    "train_cifar10 = CIFAR10(\n",
    "    './data/cifar10', train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_cifar10 = CIFAR10(\n",
    "    './data/cifar10', train=False, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_cifar100 = CIFAR100(\n",
    "    './data/cifar100', train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_cifar100 = CIFAR100(\n",
    "    './data/cifar100', train=False, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Iterate over CIFAR100 dataset\n",
    "for i, example in enumerate(train_cifar100):\n",
    "    pass\n",
    "print(\"Num. examples processed: {}\".format(i + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c46c079-f199-431a-9604-e6a7cf111746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "RNGManager.set_random_seeds(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a8a627-c4cb-4bc8-879e-9791ddef8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    List,\n",
    "    Any,\n",
    "    Sequence,\n",
    "    Union,\n",
    "    Optional,\n",
    "    TypeVar,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Tuple,\n",
    "    Mapping,\n",
    "    overload,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca308f16-73f5-4fd1-b41e-6fcc65a4a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.utils.utils import*\n",
    "from typing import TypeVar, SupportsInt, Sequence, Protocol\n",
    "from avalanche.benchmarks.utils.data import AvalancheDataset\n",
    "from avalanche.benchmarks.utils.data_attribute import *\n",
    "\n",
    "T_co = TypeVar(\"T_co\", covariant=True)\n",
    "TTargetType_co = TypeVar(\"TTargetType_co\", covariant=True)\n",
    "TTargetType = int\n",
    "\n",
    "class IDataset(Protocol[T_co]):\n",
    "    \"\"\"\n",
    "    Protocol definition of a Dataset.\n",
    "\n",
    "    Note: no __add__ method is defined.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index: int) -> T_co: ...\n",
    "\n",
    "    def __len__(self) -> int: ...\n",
    "        \n",
    "class IDatasetWithTargets(IDataset[T_co], Protocol[T_co, TTargetType_co]):\n",
    "    \"\"\"\n",
    "    Protocol definition of a Dataset that has a valid targets field.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> Sequence[TTargetType_co]:\n",
    "        \"\"\"\n",
    "        A sequence of elements describing the targets of each pattern.\n",
    "        \"\"\"\n",
    "        ...\n",
    "TClassificationDataset = TypeVar(\n",
    "    \"TClassificationDataset\", bound=\"ClassificationDataset\"\n",
    ")        \n",
    "class TaskAwareClassificationDataset(AvalancheDataset[T_co]):\n",
    "    @property\n",
    "    def task_pattern_indices(self) -> Dict[int, Sequence[int]]:\n",
    "        \"\"\"A dictionary mapping task ids to their sample indices.\"\"\"\n",
    "        return self.targets_task_labels.val_to_idx  # type: ignore\n",
    "\n",
    "    @property\n",
    "    def task_set(self: TClassificationDataset) -> TaskSet[TClassificationDataset]:\n",
    "        \"\"\"Returns the datasets's ``TaskSet``, which is a mapping <task-id,\n",
    "        task-dataset>.\"\"\"\n",
    "        return TaskSet(self)\n",
    "\n",
    "    def subset(self, indices):\n",
    "        data = super().subset(indices)\n",
    "        return data.with_transforms(self._flat_data._transform_groups.current_group)\n",
    "\n",
    "    def concat(self, other):\n",
    "        data = super().concat(other)\n",
    "        return data.with_transforms(self._flat_data._transform_groups.current_group)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return id(self)                \n",
    "class TaskAwareSupervisedClassificationDataset(TaskAwareClassificationDataset[T_co]):\n",
    "    # TODO: remove? ClassificationDataset should have targets\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        assert \"targets\" in self._data_attributes, (\n",
    "            \"The supervised version of the ClassificationDataset requires \"\n",
    "            + \"the targets field\"\n",
    "        )\n",
    "        assert \"targets_task_labels\" in self._data_attributes, (\n",
    "            \"The supervised version of the ClassificationDataset requires \"\n",
    "            + \"the targets_task_labels field\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> DataAttribute[TTargetType]:\n",
    "        return self._data_attributes[\"targets\"]\n",
    "\n",
    "    @property\n",
    "    def targets_task_labels(self) -> DataAttribute[int]:\n",
    "        return self._data_attributes[\"targets_task_labels\"]\n",
    "        \n",
    "\n",
    "class ISupportedClassificationDataset(IDatasetWithTargets[T_co, SupportsInt], Protocol):\n",
    "    \"\"\"\n",
    "    Protocol definition of a Dataset that has a valid targets field (like the\n",
    "    Datasets in the torchvision package) for classification.\n",
    "\n",
    "    For classification purposes, the targets field must be a sequence of ints.\n",
    "    describing the class label of each pattern.\n",
    "\n",
    "    This class however describes a targets field as a sequence of elements\n",
    "    that can be converted to `int`. The main reason for this choice is that\n",
    "    the targets field of some torchvision datasets is a Tensor. This means that\n",
    "    this protocol class supports both sequence of native ints and Tensor of ints\n",
    "    (or longs).\n",
    "\n",
    "    On the contrary, class :class:`IClassificationDataset` strictly\n",
    "    defines a `targets` field as sequence of native `int`s.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> Sequence[SupportsInt]:\n",
    "        \"\"\"\n",
    "        A sequence of ints or a PyTorch Tensor or a NumPy ndarray describing the\n",
    "        label of each pattern contained in the dataset.\n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "class TaskAwareSupervisedClassificationDataset(TaskAwareClassificationDataset[T_co]):\n",
    "    # TODO: remove? ClassificationDataset should have targets\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        assert \"targets\" in self._data_attributes, (\n",
    "            \"The supervised version of the ClassificationDataset requires \"\n",
    "            + \"the targets field\"\n",
    "        )\n",
    "        assert \"targets_task_labels\" in self._data_attributes, (\n",
    "            \"The supervised version of the ClassificationDataset requires \"\n",
    "            + \"the targets_task_labels field\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def targets(self) -> DataAttribute[TTargetType]:\n",
    "        return self._data_attributes[\"targets\"]\n",
    "\n",
    "    @property\n",
    "    def targets_task_labels(self) -> DataAttribute[int]:\n",
    "        return self._data_attributes[\"targets_task_labels\"]      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84fcbccb-9cca-461e-b6ef-77db7ca24d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.benchmarks.utils.transform_groups import*\n",
    "def _as_taskaware_supervised_classification_dataset(\n",
    "    dataset,\n",
    "    *,\n",
    "    transform: Optional[XTransform] = None,\n",
    "    target_transform: Optional[YTransform] = None,\n",
    "    transform_groups: Optional[Mapping[str, TransformGroupDef]] = None,\n",
    "    initial_transform_group: Optional[str] = None,\n",
    "    task_labels: Optional[Union[int, Sequence[int]]] = None,\n",
    "    targets: Optional[Sequence[TTargetType]] = None,\n",
    "    collate_fn: Optional[Callable[[List], Any]] = None\n",
    ") -> TaskAwareSupervisedClassificationDataset:\n",
    "    if (\n",
    "        transform is not None\n",
    "        or target_transform is not None\n",
    "        or transform_groups is not None\n",
    "        or initial_transform_group is not None\n",
    "        or task_labels is not None\n",
    "        or targets is not None\n",
    "        or collate_fn is not None\n",
    "        or not isinstance(dataset, TaskAwareSupervisedClassificationDataset)\n",
    "    ):\n",
    "        result_dataset = _make_taskaware_classification_dataset(\n",
    "            dataset=dataset,\n",
    "            transform=transform,\n",
    "            target_transform=target_transform,\n",
    "            transform_groups=transform_groups,\n",
    "            initial_transform_group=initial_transform_group,\n",
    "            task_labels=task_labels,\n",
    "            targets=targets,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "\n",
    "        if not isinstance(result_dataset, TaskAwareSupervisedClassificationDataset):\n",
    "            raise ValueError(\n",
    "                \"The given dataset does not have supervision fields \"\n",
    "                \"(targets, task_labels).\"\n",
    "            )\n",
    "\n",
    "        return result_dataset\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c97659-9ddd-4570-a476-48b1e9bbbca2",
   "metadata": {},
   "source": [
    "# splitcifar110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a60de5-e048-49c7-a573-cd5240078f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The benchmark instance contains 5 training experiences.\n",
      "Train experience 0\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 1\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 2\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 3\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 4\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 110\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "The benchmark instance contains 5 training experiences.\n",
      "Train experience 0\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 1\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 2\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 3\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train experience 4\n",
      "X tensor: torch.Size([300, 3, 32, 32])\n",
      "Y tensor: torch.Size([300])\n",
      "T tensor: torch.Size([300])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import (\n",
    "    List,\n",
    "    Any,\n",
    "    Sequence,\n",
    "    Union,\n",
    "    Optional,\n",
    "    TypeVar,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Tuple,\n",
    "    Mapping,\n",
    "    overload,\n",
    ")\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Sequence, Optional, Union, Any\n",
    "from avalanche.benchmarks.utils.classification_dataset import *\n",
    "from torchvision import transforms\n",
    "from avalanche.benchmarks.utils.utils import (\n",
    "    TaskSet,\n",
    "    _count_unique,\n",
    "    find_common_transforms_group,\n",
    "    _init_task_labels,\n",
    "    _init_transform_groups,\n",
    "    _split_user_def_targets,\n",
    "    _split_user_def_task_label,\n",
    "    _traverse_supported_dataset,\n",
    ")\n",
    "\n",
    "from avalanche.benchmarks.classic.classic_benchmarks_utils import (\n",
    "    check_vision_benchmark,\n",
    ")\n",
    "\n",
    "from avalanche.benchmarks.datasets.external_datasets.cifar import (\n",
    "    get_cifar100_dataset,\n",
    "    get_cifar10_dataset,\n",
    ")\n",
    "def _concat_taskaware_classification_datasets_sequentially(\n",
    "    train_dataset_list: Sequence[ISupportedClassificationDataset],\n",
    "    test_dataset_list: Sequence[ISupportedClassificationDataset],\n",
    ") -> Tuple[\n",
    "    TaskAwareSupervisedClassificationDataset,\n",
    "    TaskAwareSupervisedClassificationDataset,\n",
    "    List[list],\n",
    "]:\n",
    "    \n",
    "    remapped_train_datasets: List[TaskAwareSupervisedClassificationDataset] = []\n",
    "    remapped_test_datasets: List[TaskAwareSupervisedClassificationDataset] = []\n",
    "    next_remapped_idx = 0\n",
    "\n",
    "    train_dataset_list_sup = list(\n",
    "        map(_as_taskaware_supervised_classification_dataset, train_dataset_list)\n",
    "    )\n",
    "    test_dataset_list_sup = list(\n",
    "        map(_as_taskaware_supervised_classification_dataset, test_dataset_list)\n",
    "    )\n",
    "    del train_dataset_list\n",
    "    del test_dataset_list\n",
    "\n",
    "    # Obtain the number of classes of each dataset\n",
    "    classes_per_dataset = [\n",
    "        _count_unique(\n",
    "            train_dataset_list_sup[dataset_idx].targets,\n",
    "            test_dataset_list_sup[dataset_idx].targets,\n",
    "        )\n",
    "        for dataset_idx in range(len(train_dataset_list_sup))\n",
    "    ]\n",
    "\n",
    "    new_class_ids_per_dataset = []\n",
    "    for dataset_idx in range(len(train_dataset_list_sup)):\n",
    "        # Get the train and test sets of the dataset\n",
    "        train_set = train_dataset_list_sup[dataset_idx]\n",
    "        test_set = test_dataset_list_sup[dataset_idx]\n",
    "\n",
    "        # Get the classes in the dataset\n",
    "        dataset_classes = set(map(int, train_set.targets))\n",
    "\n",
    "        # The class IDs for this dataset will be in range\n",
    "        # [n_classes_in_previous_datasets,\n",
    "        #       n_classes_in_previous_datasets + classes_in_this_dataset)\n",
    "        new_classes = list(\n",
    "            range(\n",
    "                next_remapped_idx,\n",
    "                next_remapped_idx + classes_per_dataset[dataset_idx],\n",
    "            )\n",
    "        )\n",
    "        new_class_ids_per_dataset.append(new_classes)\n",
    "\n",
    "        # AvalancheSubset is used to apply the class IDs transformation.\n",
    "        # Remember, the class_mapping parameter must be a list in which:\n",
    "        # new_class_id = class_mapping[original_class_id]\n",
    "        # Hence, a list of size equal to the maximum class index is created\n",
    "        # Only elements corresponding to the present classes are remapped\n",
    "        class_mapping = [-1] * (max(dataset_classes) + 1)\n",
    "        j = 0\n",
    "        for i in dataset_classes:\n",
    "            class_mapping[i] = new_classes[j]\n",
    "            j += 1\n",
    "\n",
    "        a = _taskaware_classification_subset(train_set, class_mapping=class_mapping)\n",
    "\n",
    "        # Create remapped datasets and append them to the final list\n",
    "        remapped_train_datasets.append(\n",
    "            _taskaware_classification_subset(train_set, class_mapping=class_mapping)\n",
    "        )\n",
    "        remapped_test_datasets.append(\n",
    "            _taskaware_classification_subset(test_set, class_mapping=class_mapping)\n",
    "        )\n",
    "        next_remapped_idx += classes_per_dataset[dataset_idx]\n",
    "\n",
    "    return (\n",
    "        _concat_taskaware_classification_datasets(remapped_train_datasets),\n",
    "        _concat_taskaware_classification_datasets(remapped_test_datasets),\n",
    "        new_class_ids_per_dataset,\n",
    "    )\n",
    "\n",
    "from avalanche.benchmarks import nc_benchmark, NCScenario\n",
    "\n",
    "_default_cifar100_train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "_default_cifar100_eval_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def SplitCIFAR100(\n",
    "    n_experiences: int,\n",
    "    *,\n",
    "    first_exp_with_half_classes: bool = False,\n",
    "    return_task_id=False,\n",
    "    seed: Optional[int] = None,\n",
    "    fixed_class_order: Optional[Sequence[int]] = None,\n",
    "    shuffle: bool = True,\n",
    "    class_ids_from_zero_in_each_exp: bool = False,\n",
    "    class_ids_from_zero_from_first_exp: bool = False,\n",
    "    train_transform: Optional[Any] = _default_cifar100_train_transform,\n",
    "    eval_transform: Optional[Any] = _default_cifar100_eval_transform,\n",
    "    dataset_root: Optional[Union[str, Path]] = None\n",
    "):\n",
    "    \n",
    "    cifar_train, cifar_test = get_cifar100_dataset(dataset_root)\n",
    "\n",
    "    return nc_benchmark(\n",
    "        train_dataset=cifar_train,\n",
    "        test_dataset=cifar_test,\n",
    "        n_experiences=n_experiences,\n",
    "        task_labels=return_task_id,\n",
    "        seed=seed,\n",
    "        fixed_class_order=fixed_class_order,\n",
    "        shuffle=shuffle,\n",
    "        per_exp_classes={0: 50} if first_exp_with_half_classes else None,\n",
    "        class_ids_from_zero_in_each_exp=class_ids_from_zero_in_each_exp,\n",
    "        class_ids_from_zero_from_first_exp=class_ids_from_zero_from_first_exp,\n",
    "        train_transform=train_transform,\n",
    "        eval_transform=eval_transform,\n",
    "    )\n",
    "\n",
    "\n",
    "def SplitCIFAR110(\n",
    "    n_experiences: int,\n",
    "    *,\n",
    "    seed: Optional[int] = None,\n",
    "    fixed_class_order: Optional[Sequence[int]] = None,\n",
    "    class_ids_from_zero_from_first_exp: bool = False,\n",
    "    train_transform: Optional[Any] = _default_cifar100_train_transform,\n",
    "    eval_transform: Optional[Any] = _default_cifar100_eval_transform,\n",
    "    dataset_root_cifar10: Optional[Union[str, Path]] = None,\n",
    "    dataset_root_cifar100: Optional[Union[str, Path]] = None\n",
    ") -> NCScenario:\n",
    "    \"\"\"\n",
    "    Creates a CL benchmark using both the CIFAR100 and CIFAR10 datasets.\n",
    "\n",
    "    If the datasets are not present in the computer, this method will\n",
    "    automatically download and store them in the data folder.\n",
    "\n",
    "    The CIFAR10 dataset is used to create the first experience, while the\n",
    "    remaining `n_experiences-1` experiences will be created from CIFAR100.\n",
    "\n",
    "    The returned benchmark will return experiences containing all patterns of a\n",
    "    subset of classes, which means that each class is only seen \"once\".\n",
    "    This is one of the most common scenarios in the Continual Learning\n",
    "    literature. Common names used in literature to describe this kind of\n",
    "    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n",
    "    an equal amount of classes will be assigned to each experience.\n",
    "\n",
    "    This generator will apply a task label 0 to all experiences.\n",
    "\n",
    "    The benchmark instance returned by this method will have two fields,\n",
    "    `train_stream` and `test_stream`, which can be iterated to obtain\n",
    "    training and test :class:`Experience`. Each Experience contains the\n",
    "    `dataset` and the associated task label (always 0 for this specific\n",
    "    benchmark).\n",
    "\n",
    "    The benchmark API is quite simple and is uniform across all benchmark\n",
    "    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n",
    "    which contains usage examples ranging from \"basic\" to \"advanced\".\n",
    "\n",
    "    :param n_experiences: The number of experiences for the entire benchmark.\n",
    "        The first experience will contain the entire CIFAR10 dataset, while the\n",
    "        other n-1 experiences will be obtained from CIFAR100.\n",
    "    :param seed: A valid int used to initialize the random number generator.\n",
    "        Can be None.\n",
    "    :param fixed_class_order: A list of class IDs used to define the class\n",
    "        order ONLY for the incremental part, which is based on cifar100. The\n",
    "        classes must be in range 0-99.\n",
    "        If None, value of ``seed`` will be used to define the class order for\n",
    "        the incremental batches on cifar100. If non-None, ``seed`` parameter\n",
    "        will be ignored. Defaults to None.\n",
    "    :param class_ids_from_zero_from_first_exp: If True, original class IDs\n",
    "        will be remapped so that they will appear as having an ascending\n",
    "        order. For instance, if the resulting class order after shuffling\n",
    "        (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and\n",
    "        class_ids_from_zero_from_first_exp is True, then all the patterns\n",
    "        belonging to class 23 will appear as belonging to class \"0\",\n",
    "        class \"34\" will be mapped to \"1\", class \"11\" to \"2\" and so on.\n",
    "        This is very useful when drawing confusion matrices and when dealing\n",
    "        with algorithms with dynamic head expansion. Defaults to False.\n",
    "        Mutually exclusive with the ``class_ids_from_zero_in_each_exp``\n",
    "        parameter.\n",
    "    :param train_transform: The transformation to apply to the training data,\n",
    "        e.g. a random crop, a normalization or a concatenation of different\n",
    "        transformations (see torchvision.transform documentation for a\n",
    "        comprehensive list of possible transformations).\n",
    "        If no transformation is passed, the default train transformation\n",
    "        will be used.\n",
    "    :param eval_transform: The transformation to apply to the test data,\n",
    "        e.g. a random crop, a normalization or a concatenation of different\n",
    "        transformations (see torchvision.transform documentation for a\n",
    "        comprehensive list of possible transformations).\n",
    "        If no transformation is passed, the default test transformation\n",
    "        will be used.\n",
    "    :param dataset_root_cifar10: The root path of the CIFAR-10 dataset.\n",
    "        Defaults to None, which means that the default location for\n",
    "        'cifar10' will be used.\n",
    "    :param dataset_root_cifar100: The root path of the CIFAR-100 dataset.\n",
    "        Defaults to None, which means that the default location for\n",
    "        'cifar100' will be used.\n",
    "\n",
    "    :returns: A properly initialized :class:`NCScenario` instance.\n",
    "    \"\"\"\n",
    "\n",
    "    cifar10_train, cifar10_test = get_cifar10_dataset(dataset_root_cifar10)\n",
    "    cifar100_train, cifar100_test = get_cifar100_dataset(dataset_root_cifar100)\n",
    "\n",
    "    (\n",
    "        cifar_10_100_train,\n",
    "        cifar_10_100_test,\n",
    "        _,\n",
    "    ) = _concat_taskaware_classification_datasets_sequentially(\n",
    "        [cifar10_train, cifar100_train], [cifar10_test, cifar100_test]\n",
    "    )\n",
    "    # cifar10 classes\n",
    "    class_order = [_ for _ in range(10)]\n",
    "    # if a class order is defined (for cifar100) the given class labels are\n",
    "    # appended to the class_order list, adding 10 to them (since the classes\n",
    "    # 0-9 are the classes of cifar10).\n",
    "    if fixed_class_order is not None:\n",
    "        class_order.extend([c + 10 for c in fixed_class_order])\n",
    "    else:\n",
    "        random.seed(seed)\n",
    "        # random shuffling of the cifar100 classes (labels 10-109)\n",
    "        cifar_100_class_order = random.sample(range(10, 110), 100)\n",
    "        class_order.extend(cifar_100_class_order)\n",
    "\n",
    "    return nc_benchmark(\n",
    "        cifar_10_100_train,\n",
    "        cifar_10_100_test,\n",
    "        n_experiences=n_experiences,\n",
    "        task_labels=False,\n",
    "        shuffle=False,\n",
    "        seed=None,\n",
    "        fixed_class_order=class_order,\n",
    "        class_ids_from_zero_from_first_exp=class_ids_from_zero_from_first_exp,\n",
    "        per_exp_classes={0: 10},\n",
    "        train_transform=train_transform,\n",
    "        eval_transform=eval_transform,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Split 100\")\n",
    "    benchmark_instance = SplitCIFAR100(5)\n",
    "    check_vision_benchmark(benchmark_instance)\n",
    "\n",
    "    print(\"Split 110\")\n",
    "    benchmark_instance = SplitCIFAR110(5)\n",
    "    check_vision_benchmark(benchmark_instance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569f455-f45f-46cf-858c-cd40206a4527",
   "metadata": {},
   "source": [
    "# SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9675cfc3-8dcc-4f8b-9cb2-b75f81fa6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, num_classes=110):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.25),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(64, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730f29d2-b7bc-48a1-b83e-2193f7681234",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN05(nn.Module):\n",
    "    #p=0.05\n",
    "\n",
    "    def __init__(self, num_classes=110):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.05),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(64, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173aef7a-bf31-4221-9198-20d7db66796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN01(nn.Module):\n",
    "    #p=0.01\n",
    "\n",
    "    def __init__(self, num_classes=110):\n",
    "        super(SimpleCNN01, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.01),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.01),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.01),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(64, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feeecacf-20a2-4de1-96f7-4e8f42cad06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN64(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, num_classes=110):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.05),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(128, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bb1e84-d75d-4de3-b257-e82f97660d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.models.simple_cnn import MTSimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36f44ac-d4c0-4c72-aa3e-91a80a9df6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (\n",
    "    Module,\n",
    "    Sequential,\n",
    "    BatchNorm2d,\n",
    "    Conv2d,\n",
    "    ReLU,\n",
    "    ConstantPad3d,\n",
    "    Identity,\n",
    "    AdaptiveAvgPool2d,\n",
    "    Linear,\n",
    ")\n",
    "class IcarlNet(Module):\n",
    "    def __init__(self, num_classes: int, n=5, c=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_train = True\n",
    "        input_dims = c\n",
    "        output_dims = 16\n",
    "\n",
    "        first_conv = Sequential(\n",
    "            conv3x3(input_dims, output_dims, stride=(1, 1)),\n",
    "            batch_norm(16),\n",
    "            ReLU(True),\n",
    "        )\n",
    "\n",
    "        input_dims = output_dims\n",
    "        output_dims = 16\n",
    "\n",
    "        # first stack of residual blocks, output is 16 x 32 x 32\n",
    "        layers_list = []\n",
    "        for _ in range(n):\n",
    "            layers_list.append(ResidualBlock(input_dims))\n",
    "        first_block = Sequential(*layers_list)\n",
    "\n",
    "        input_dims = output_dims\n",
    "        output_dims = 32\n",
    "\n",
    "        # second stack of residual blocks, output is 32 x 16 x 16\n",
    "        layers_list = [ResidualBlock(input_dims, increase_dim=True)]\n",
    "        for _ in range(1, n):\n",
    "            layers_list.append(ResidualBlock(output_dims))\n",
    "        second_block = Sequential(*layers_list)\n",
    "\n",
    "        input_dims = output_dims\n",
    "        output_dims = 64\n",
    "\n",
    "        # third stack of residual blocks, output is 64 x 8 x 8\n",
    "        layers_list = [ResidualBlock(input_dims, increase_dim=True)]\n",
    "        for _ in range(1, n - 1):\n",
    "            layers_list.append(ResidualBlock(output_dims))\n",
    "        layers_list.append(ResidualBlock(output_dims, last=True))\n",
    "        third_block = Sequential(*layers_list)\n",
    "        final_pool = AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "        self.feature_extractor = Sequential(\n",
    "            first_conv,\n",
    "            first_block,\n",
    "            second_block,\n",
    "            third_block,\n",
    "            final_pool,\n",
    "            Flatten(),\n",
    "        )\n",
    "\n",
    "        input_dims = output_dims\n",
    "        output_dims = num_classes\n",
    "\n",
    "        self.classifier = Linear(input_dims, output_dims)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)  # Already flattened\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6004ea7-3e0d-4401-aa86-271a827db37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.models.slim_resnet18 import MLP,MTSlimResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fb73260-101f-4a6e-9753-0c6fa42baa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Same example as in all_mnist.py, but using early stopping to dynamically stop\n",
    "# the training procedure when the model converged instead of training for a\n",
    "# fixed number of epochs.\n",
    "# IMPORTANT: In this example we use the test set to detect when the\n",
    "# generalization error stops decreasing. In practice, one should *never* use\n",
    "# the test set for early stopping, but rather measure the generalization\n",
    "# performance on a held-out validation set.\n",
    "# \"\"\"\n",
    "\n",
    "# import torch\n",
    "# import argparse\n",
    "# from torch.nn import CrossEntropyLoss\n",
    "# from torch.optim import SGD\n",
    "\n",
    "# from avalanche.benchmarks.classic import PermutedMNIST, RotatedMNIST, SplitMNIST\n",
    "# from avalanche.models import SimpleMLP\n",
    "# from avalanche.training.plugins.early_stopping import EarlyStoppingPlugin\n",
    "# from avalanche.training.supervised import Naive\n",
    "\n",
    "\n",
    "# def main(args):\n",
    "#     # Device config\n",
    "#     device = torch.device(\n",
    "#         f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "#     )\n",
    "\n",
    "#     # model\n",
    "#     model = SimpleMLP(num_classes=10)\n",
    "\n",
    "#     # Here we show all the MNIST variation we offer in the \"classic\" benchmarks\n",
    "#     if args.mnist_type == \"permuted\":\n",
    "#         benchmark = PermutedMNIST(n_experiences=5, seed=1)\n",
    "#     elif args.mnist_type == \"rotated\":\n",
    "#         benchmark = RotatedMNIST(\n",
    "#             n_experiences=5, rotations_list=[30, 60, 90, 120, 150], seed=1\n",
    "#         )\n",
    "#     else:\n",
    "#         benchmark = SplitMNIST(n_experiences=5, seed=1)\n",
    "\n",
    "#     # Than we can extract the parallel train and test streams\n",
    "#     train_stream = benchmark.train_stream\n",
    "#     test_stream = benchmark.test_stream\n",
    "\n",
    "#     # Prepare for training & testing\n",
    "#     optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#     criterion = CrossEntropyLoss()\n",
    "\n",
    "#     # Continual learning strategy with default logger\n",
    "#     cl_strategy = Naive(\n",
    "#         model,\n",
    "#         optimizer,\n",
    "#         criterion,\n",
    "#         train_mb_size=32,\n",
    "#         train_epochs=100,\n",
    "#         eval_mb_size=32,\n",
    "#         device=device,\n",
    "#         eval_every=1,\n",
    "#         plugins=[EarlyStoppingPlugin(args.patience, \"test_stream\")],\n",
    "#     )\n",
    "\n",
    "#     # train and test loop\n",
    "#     results = []\n",
    "#     for train_task, test_task in zip(train_stream, test_stream):\n",
    "#         print(\"Current Classes: \", train_task.classes_in_this_experience)\n",
    "#         cl_strategy.train(train_task, eval_streams=[test_task])\n",
    "#         results.append(cl_strategy.eval(test_stream))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--mnist_type\",\n",
    "#         type=str,\n",
    "#         default=\"split\",\n",
    "#         choices=[\"rotated\", \"permuted\", \"split\"],\n",
    "#         help=\"Choose between MNIST variations: \" \"rotated, permuted or split.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--cuda\",\n",
    "#         type=int,\n",
    "#         default=0,\n",
    "#         help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--patience\",\n",
    "#         type=int,\n",
    "#         default=3,\n",
    "#         help=\"Number of epochs to wait without generalization\"\n",
    "#         \"improvements before stopping the training .\",\n",
    "#     )\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976bf765-0e0b-4dc9-86f1-0115224cbdc8",
   "metadata": {},
   "source": [
    "# Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aea7e93-db2c-45e7-8759-6d980435cc55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--cuda CUDA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\ahmed\\AppData\\Roaming\\jupyter\\runtime\\kernel-570c70f2-8a28-4cbd-b282-07d942ce5ce8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\DDP\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example on how to use the checkpoint plugin.\n",
    "\n",
    "This is basically a vanilla Avalanche main script, but with the checkpointing\n",
    "functionality enabled. Proper comments are provided to point out the changes\n",
    "required to use the checkpoint plugin.\n",
    "\"\"\"\n",
    "import argparse\n",
    "\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "from avalanche.logging import InteractiveLogger\n",
    "\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.supervised import Naive\n",
    "\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create the strategy (as usual)\n",
    "    strategy = Naive(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    ")\n",
    "\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint.pkl\"  # name of the checkpoint file\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--cuda\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "    )\n",
    "    # Parse known arguments to ignore extra ones\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    main_with_checkpointing(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff260bd-7cdc-4ee1-b8e1-9b461e4618c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Mapping cuda:0 to cuda:0\n",
      "[InteractiveLogger] Resuming from checkpoint. Current time is 2024-08-13 11:29:48 +0100\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:28<00:00, 27.55it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2863\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0757\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5557\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 116.26it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0568\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5898\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6298\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 782/782 [00:06<00:00, 120.64it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0083\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0837\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 120.24it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9967\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7364\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6524\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 120.20it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9652\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9408\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6632\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:06<00:00, 124.19it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9621\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2794\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6666\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 122.12it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9536\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0343\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6682\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 121.49it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9309\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7001\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6759\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.99it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9284\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0551\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6771\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:06<00:00, 119.26it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9199\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9611\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6813\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 114.90it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0701\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6788\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.15it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8945\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6864\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 121.26it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9043\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6966\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6873\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 113.35it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9085\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9411\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6864\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.17it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9026\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0645\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6888\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:06<00:00, 115.29it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8917\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5682\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 118.26it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8851\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4355\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6948\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 782/782 [00:06<00:00, 120.53it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8865\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9065\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6939\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 118.02it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8867\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2926\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6933\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.73it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8763\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7873\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6977\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 115.68it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8733\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6978\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6996\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:06<00:00, 118.37it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7356\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6979\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 116.19it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8788\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8612\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6985\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 113.36it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8639\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5329\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7024\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.35it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8690\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9965\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7024\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 102.64it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8665\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4828\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7022\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.54it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8657\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0664\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7024\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.14it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8752\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7060\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6997\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 108.85it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8621\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5968\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7053\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.16it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8568\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7901\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7050\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.42it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7630\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7382\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 16.4206\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.6833\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 16.1693\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 16.2572\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.14it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 16.1470\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.4492\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3691\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.59it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.7686\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 5.1362\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.50it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.7247\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.3166\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0307\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.32it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.1410\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.7938\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0504\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.80it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.7461\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.4240\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0481\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.92it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5026\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.4039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.98it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3590\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2585\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.88it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2732\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2484\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.63it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2186\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2007\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0487\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.81it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1815\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1653\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0486\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.66it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1546\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1479\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0452\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.88it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1343\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1256\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0453\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.88it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1186\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1129\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0432\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.89it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1060\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1013\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0458\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.85it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0956\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0897\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0436\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.88it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0870\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0843\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0459\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.87it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0797\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0754\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.73it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0735\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0717\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0447\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.52it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0681\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0680\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0482\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.11it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0635\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0617\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0488\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.58it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0593\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0603\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.66it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0557\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0532\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.54it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0525\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0501\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.39it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0496\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0457\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0463\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.33it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0468\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0459\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0449\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.65it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0445\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0435\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0474\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.57it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0423\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0397\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.88it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0403\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0406\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.25it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0385\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0394\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0442\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.07it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0369\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0334\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0457\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.71it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0353\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0353\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:15<00:00, 10.01it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.1171\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.12it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.0340\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0500\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.13it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.0520\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.13it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 7.9195\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.14it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.1688\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 8.0661\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.0826\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0050\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.32it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.4032\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 6.6798\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.18it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.0165\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 5.4018\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.76it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.8760\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.4635\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.65it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.1137\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.8583\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0330\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.93it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.6851\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.5328\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0473\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.02it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4557\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3568\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0477\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.15it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3281\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2976\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0461\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 117.68it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2520\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2330\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0500\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.22it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2029\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1850\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0490\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.36it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1689\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1549\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0473\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.70it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1444\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0466\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.42it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1257\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1165\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0476\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.83it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1057\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0462\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.86it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0994\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0952\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0465\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.52it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0898\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0852\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0440\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.76it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0819\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0790\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0443\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.09it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0750\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0721\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.54it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0694\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0685\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0450\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.16it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0644\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0629\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0449\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 111.65it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0601\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0586\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0429\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.24it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0563\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0555\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0431\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.12it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0527\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0526\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0436\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.87it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0497\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0499\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0457\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.26it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0471\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0462\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0444\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.14it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0445\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0426\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0442\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 117.55it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0423\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0427\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0476\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.20it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0403\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0404\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0452\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 116.13it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0384\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0374\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0439\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.86it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0367\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0359\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.46it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0351\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0347\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.60it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.7628\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 6.9793\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.0338\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0500\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.3166\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.4927\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 8.4186\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.4055\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0050\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:19<00:00,  8.18it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.6651\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 6.9532\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.91it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.2611\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 5.6414\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.36it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.0720\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.4507\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.48it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.2418\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.9917\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0124\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.71it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.7604\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.6267\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.40it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5003\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3564\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0493\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.14it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3560\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2962\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0459\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.06it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2704\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2218\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0443\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.51it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2158\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1954\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0461\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.73it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1785\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1624\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0436\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.36it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1518\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1403\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.55it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1315\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1239\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0465\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.54it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1159\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1121\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0430\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.28it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1034\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0992\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.75it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0933\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0886\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0439\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.33it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0849\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0824\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0442\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.20it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0776\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0757\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0476\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.76it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0715\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0689\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0438\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 117.83it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0663\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0639\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.31it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0618\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0603\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0437\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.46it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0578\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0573\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0441\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.90it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0542\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0529\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0472\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 117.77it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0511\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0519\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0425\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 114.46it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0482\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0467\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0412\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 117.78it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0457\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0446\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0463\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.89it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0433\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0444\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.11it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0412\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0403\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0453\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.66it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0392\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0380\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0486\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.62it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0375\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0375\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.87it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0358\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0363\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.55it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.1277\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.04it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 7.6602\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 6.9916\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.0345\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0500\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.04it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.6903\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 8.6315\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.5646\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0050\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:19<00:00,  7.92it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 8.0367\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 7.3000\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.98it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.6169\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 5.9542\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.79it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.3737\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.7795\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.00it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4487\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.1722\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.31it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.8819\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.7230\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0475\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.78it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5715\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.4574\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0490\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.58it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4010\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0480\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.40it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3009\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2686\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.44it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2377\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2153\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0459\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.87it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1951\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1762\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.41it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1646\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1549\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.04it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1419\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0471\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.09it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1245\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1162\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.65it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1107\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0463\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.62it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0995\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0972\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0459\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 115.11it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0902\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0876\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0448\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.53it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0823\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0815\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0457\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.95it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0758\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0723\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0435\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.58it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0700\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0682\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.85it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0652\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0628\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0448\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.48it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0609\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0599\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0462\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.70it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0570\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0536\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0473\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.68it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0536\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0499\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.21it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0506\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0486\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 117.08it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0478\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0457\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 119.35it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0453\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0439\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0453\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.62it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0431\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0422\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0448\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.96it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0410\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0427\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0450\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 113.83it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0391\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0366\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.86it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0374\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0383\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0449\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.25it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.3525\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.0279\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 7.6518\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 7.0233\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.0360\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0500\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:14<00:00,  2.14it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 8.7547\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.6256\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0050\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.64it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 8.1021\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 7.2364\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.63it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.6833\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 5.9361\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.70it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.4362\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.8549\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.39it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4974\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.1095\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.32it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.9140\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.7176\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0403\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.32it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5919\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.5095\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0491\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.21it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4144\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3465\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.67it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3104\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2855\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0481\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.03it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2447\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2146\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0468\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.39it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2006\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1875\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.49it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1690\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1569\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0449\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.75it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1455\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1362\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0490\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.65it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1274\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1181\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0487\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.36it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1132\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1085\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0455\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.94it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1016\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0988\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0449\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.51it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0922\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0899\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0452\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.19it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0841\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0815\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.41it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0774\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0735\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0456\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 124.27it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0715\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0681\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0459\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.47it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0665\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0656\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 127.74it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0620\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0582\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0435\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.06it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0582\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0579\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0466\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 118.40it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0546\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0552\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0446\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.13it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0516\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0514\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.97it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0487\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0475\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0471\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 123.70it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0462\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0436\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0484\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.82it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0438\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0457\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0471\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 126.88it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0418\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0394\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.10it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0399\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0425\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0458\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 125.42it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0380\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0400\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0444\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.72it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.5425\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.2978\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.0408\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.13it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 7.6852\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 7.0405\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.0367\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0500\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.6814\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0050\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy (as usual)\n",
    "    strategy = Naive(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Naive.pkl\"  # name of the checkpoint file\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "766b3629-847f-42ca-ac84-e90aad4abd09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Mapping cuda:0 to cuda:0\n",
      "[InteractiveLogger] Resuming from checkpoint. Current time is 2024-08-11 14:30:33 +0100\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.65it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.0745\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6286\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1372\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.98it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0086\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8157\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4935\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.64it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7784\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7546\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5001\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.77it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7430\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7328\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4968\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.13it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7284\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7224\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4959\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 95.84it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7204\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7547\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4945\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 96.68it/s] \n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7155\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7195\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4945\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.44it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7122\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7107\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4873\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.27it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7096\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7083\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.74it/s] \n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7077\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7124\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4921\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.86it/s] \n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7061\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6964\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4998\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.60it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7048\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5013\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.59it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7036\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7057\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5090\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.72it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7030\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5007\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.32it/s] \n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7023\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7017\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4970\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 99.53it/s] \n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7014\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6980\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5092\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.56it/s] \n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7010\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6971\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5012\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.92it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7006\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6971\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4939\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.22it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7002\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7003\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4963\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.58it/s] \n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6998\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7061\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4989\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 94.90it/s] \n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6996\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4940\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.03it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6995\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4961\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.40it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6989\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6958\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4991\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.27it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6989\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6976\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4923\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.34it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6985\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6988\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.73it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6984\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6984\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4955\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.55it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6981\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6973\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5007\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.27it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6978\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6976\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4991\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.32it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6976\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6957\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5030\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.00it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6975\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6975\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5007\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6974\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 13.1275\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.1586\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.2585\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 13.1039\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.6692\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1000\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:19<00:00,  8.16it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.8360\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5862\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0291\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.97it/s] \n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9817\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8075\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4878\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.23it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7735\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7519\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4950\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.58it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7408\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7361\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5023\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.68it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7273\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7246\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4964\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.20it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7196\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7152\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4972\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.01it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7150\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7143\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4884\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.19it/s] \n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7115\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7100\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4890\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.57it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7090\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7082\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5079\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.53it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7071\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7090\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5051\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.73it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7058\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7050\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4946\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.72it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7046\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7102\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4978\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.25it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7034\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5105\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.28it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7029\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4883\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.33it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7020\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7046\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5030\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.91it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7015\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7024\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4927\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.07it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7010\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7005\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4957\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.56it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7004\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7001\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4952\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.46it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7001\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7043\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4949\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.00it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6997\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7029\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5013\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.97it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6993\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6983\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4952\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.18it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6992\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7029\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.66it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6988\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6972\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4990\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.12it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6988\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6961\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4979\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.24it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6984\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6968\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4927\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.78it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6981\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6990\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4950\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.08it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6980\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6985\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4888\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 99.02it/s] \n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6979\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7003\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.10it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6977\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6952\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4999\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.87it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6976\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7012\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4951\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.9029\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6973\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.0028\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.1022\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.9483\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.5307\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1000\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.45it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.7213\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5279\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0406\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.06it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9702\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8076\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4916\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.86it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7727\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7506\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.82it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7404\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7278\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5015\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.36it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7270\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7239\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.83it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7195\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7185\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4916\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.64it/s] \n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7148\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7144\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.08it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7115\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7117\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5008\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.92it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7092\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6966\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4990\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 108.10it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7074\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7067\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4992\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.00it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7058\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7032\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4936\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 109.35it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7046\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6983\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4966\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.82it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7038\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7027\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4964\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 108.75it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7028\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7035\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4896\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 108.25it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7023\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6940\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.69it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7016\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6981\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4962\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.93it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7011\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6993\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4937\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.80it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7006\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7011\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5050\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.55it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7002\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4945\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.48it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6996\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6961\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4963\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.51it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6994\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7068\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5002\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.32it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6991\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6963\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4964\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.33it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6989\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7012\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4905\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.00it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6986\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7010\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5016\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.64it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6983\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6982\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4971\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 108.02it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6982\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6980\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4953\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.79it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6981\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6983\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4907\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.76it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6978\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6975\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4990\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.40it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6977\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6948\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4983\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.40it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6973\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6974\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5041\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.4783\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 7.8967\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.6974\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.5000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.9599\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.8071\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.5679\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1000\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.66it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.3183\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6058\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2775\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.52it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3448\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2542\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8555\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 108.02it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1667\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3547\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9380\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.74it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1196\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1963\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9590\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.50it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0913\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0522\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9663\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 99.75it/s] \n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0792\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0081\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9695\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.47it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0700\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1305\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9742\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.86it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0697\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0008\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9764\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 99.28it/s] \n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0580\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0449\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.55it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0575\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0736\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9802\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.65it/s] \n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0533\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0164\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9823\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.67it/s] \n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0509\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0703\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9824\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.57it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0460\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0082\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9837\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.24it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0518\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0195\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9808\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.72it/s] \n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0412\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0013\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9859\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 96.15it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0465\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0416\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9827\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.67it/s] \n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0436\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1154\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9840\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.20it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0424\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0007\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9854\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 93.28it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0360\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5124\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9873\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 95.14it/s] \n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0472\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0047\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9828\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.69it/s] \n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0389\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1914\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9865\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.98it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0285\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0004\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9891\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.34it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0391\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0045\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9866\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.20it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0336\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9884\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.32it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0359\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0025\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9863\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.81it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0312\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0024\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9885\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.18it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0328\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0059\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9886\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.91it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0341\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0063\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9887\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.85it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0347\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1195\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9871\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.41it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0317\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9890\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.6497\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.4029\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.3240\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0005\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0271\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9910\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 13.1156\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.9039\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1983\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7460\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2792\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8245\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.28it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2299\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0523\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9142\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.90it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1925\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0137\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9273\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.85it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1814\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0529\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9316\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 108.71it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1723\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2453\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9335\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.79it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1642\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0415\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9388\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.05it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1477\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1766\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 99.89it/s] \n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1506\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0409\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9426\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.10it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1555\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0452\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9401\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.92it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1455\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0189\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9452\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.53it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1444\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0587\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9447\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.98it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1454\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3098\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.52it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1421\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1344\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9457\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.71it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1349\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0974\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9502\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.62it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1291\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0314\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9498\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.31it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1223\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0222\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9513\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.28it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1227\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0070\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9524\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.46it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1266\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3514\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9500\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.84it/s] \n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1334\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0239\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9474\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.87it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1222\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2254\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9538\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.73it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1095\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0578\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9575\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.45it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1200\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0194\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9542\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.13it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1198\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0741\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9564\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.13it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1093\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0752\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9593\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.30it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1074\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0282\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9592\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.01it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1054\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6198\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9587\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.80it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1139\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0124\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9582\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.66it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1076\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0160\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9587\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.54it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1033\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9613\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.20it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1130\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2399\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9591\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.1173\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.4073\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.9895\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0025\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  2.00it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 10.9572\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1427\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9495\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.3228\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1904\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100 \n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR10(5)\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy (as usual)\n",
    "    strategy = Naive(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Naive.pkl\"  # name of the checkpoint file\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp =0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e8ed82-b7f6-483f-9e1c-49c519c6ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--cuda CUDA]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\ahmed\\AppData\\Roaming\\jupyter\\runtime\\kernel-c29ab336-1769-4f96-96da-75267df62715.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\DDP\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from avalanche.models import MlpVAE\n",
    "from avalanche.training.supervised import VAETraining\n",
    "from avalanche.training.plugins import GenerativeReplayPlugin\n",
    "\n",
    "def main(args):\n",
    "    # --- CONFIG\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "\n",
    "    # --- BENCHMARK CREATION\n",
    "    benchmark = SplitCIFAR110(n_experiences=4, seed=1234)\n",
    "    # ---------\n",
    "\n",
    "    # MODEL CREATION\n",
    "    model = MlpVAE((3, 32, 32), nhid=2, device=device)\n",
    "\n",
    "    # CREATE THE STRATEGY INSTANCE (GenerativeReplay)\n",
    "    cl_strategy = VAETraining(\n",
    "        model,\n",
    "        torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "        train_mb_size=100,\n",
    "        train_epochs=4,\n",
    "        device=device,\n",
    "        plugins=[GenerativeReplayPlugin()],\n",
    "    )\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    print(\"Starting experiment...\")\n",
    "    f, axarr = plt.subplots(benchmark.n_experiences, 10)\n",
    "    k = 0\n",
    "    for experience in benchmark.train_stream:\n",
    "        print(\"Start of experience \", experience.current_experience)\n",
    "        cl_strategy.train(experience)\n",
    "        print(\"Training completed\")\n",
    "\n",
    "        samples = model.generate(10)\n",
    "        samples = samples.detach().cpu().numpy()\n",
    "\n",
    "        for j in range(10):\n",
    "            axarr[k, j].imshow(samples[j, 0], cmap=\"gray\")\n",
    "            axarr[k, 4].set_title(\"Generated images for experience \" + str(k))\n",
    "        np.vectorize(lambda ax: ax.axis(\"off\"))(axarr)\n",
    "        k += 1\n",
    "\n",
    "    f.subplots_adjust(hspace=1.2)\n",
    "    plt.savefig(\"VAE_output_per_exp\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--cuda\",\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    ")\n",
    "args = parser.parse_args()\n",
    "main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02bc8e78-b499-40af-8d56-d234a652fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting experiment...\n",
      "Start of experience  0\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 500/500 [00:22<00:00, 22.23it/s]\n",
      "Epoch 0 ended.\n",
      "100%|██████████| 500/500 [00:22<00:00, 22.59it/s]\n",
      "Epoch 1 ended.\n",
      "100%|██████████| 500/500 [00:22<00:00, 22.27it/s]\n",
      "Epoch 2 ended.\n",
      "100%|██████████| 500/500 [00:22<00:00, 22.51it/s]\n",
      "Epoch 3 ended.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Start of experience  1\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.10it/s]\n",
      "Epoch 0 ended.\n",
      "100%|██████████| 125/125 [00:05<00:00, 20.91it/s]\n",
      "Epoch 1 ended.\n",
      "100%|██████████| 125/125 [00:05<00:00, 20.85it/s]\n",
      "Epoch 2 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 19.22it/s]\n",
      "Epoch 3 ended.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Start of experience  2\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.63it/s]\n",
      "Epoch 0 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.79it/s]\n",
      "Epoch 1 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.41it/s]\n",
      "Epoch 2 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.79it/s]\n",
      "Epoch 3 ended.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Start of experience  3\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 125/125 [00:05<00:00, 21.60it/s]\n",
      "Epoch 0 ended.\n",
      "100%|██████████| 125/125 [00:05<00:00, 21.00it/s]\n",
      "Epoch 1 ended.\n",
      "100%|██████████| 125/125 [00:05<00:00, 21.37it/s]\n",
      "Epoch 2 ended.\n",
      "100%|██████████| 125/125 [00:05<00:00, 21.08it/s]\n",
      "Epoch 3 ended.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Start of experience  4\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.56it/s]\n",
      "Epoch 0 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 19.91it/s]\n",
      "Epoch 1 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.68it/s]\n",
      "Epoch 2 ended.\n",
      "100%|██████████| 125/125 [00:06<00:00, 20.29it/s]\n",
      "Epoch 3 ended.\n",
      "-- >> End of training phase << --\n",
      "Training completed\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGbCAYAAADKlJnyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOy9eZBV1bk2/px5HnqmAW0EFEQJEUR/EVREBQUr4tUQiVFQA8aIKY0ab3njkGg0mqjJBRGSfKXGxLoVlUTLaxLNlS9xitFPJaKiTYOADD336T7ztH5/cJ/V7959Gno4LSj7qerq7n322XuN7/y+y6aUUrBgwYIFCxYsHDawH+wGWLBgwYIFCxY+W1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM38IhjXHjxmHZsmUHvM9ms+GOO+4Y8fYc6mhsbMS8efMQiURgs9nwxz/+8WA36ZDFsmXLMG7cuIPdDAsWDgos5j9C2LZtG1auXIljjjkGfr8ffr8fU6ZMwTXXXIN//etfB7t5ZcXzzz9vMd5DBEuXLsV7772HH//4x3j88cdx4oknHuwmWfgMsGvXLixevBjRaBThcBjnn38+tm7derCbZeEQhs2q7V9+PPfcc/j6178Op9OJSy65BNOmTYPdbsfmzZuxfv16bN++Hdu2bUNDQ8PBbmpZsHLlSjz00EMYiaU0btw4zJkzB48++uh+70un03A6nXA6nWVvw+cFqVQKfr8f//Ef/4G77rrrYDfnkEcul0OxWITH4znYTRkW4vE4pk+fjlgshhtuuAEulwsPPvgglFJ49913UVVVdbCbaOEQxOFLKUcITU1NuPjii9HQ0ID/+Z//QX19veHze++9F2vWrIHdfugaXRKJBAKBwMFuxqDg9XoPdhMOOlpbWwEA0Wi0bM/8PK6FA4F9crlcB7spZcGaNWvQ2NiIf/7zn5g5cyYA4Nxzz8Xxxx+P+++/H3ffffdBbqGFQxLKQlmxYsUKBUD94x//GNT3PvzwQ3XhhReqiooK5fF41IwZM9QzzzxjuOeRRx5RANQrr7yirr/+elVdXa38fr9atGiRamlp6fPM559/Xs2ePVv5/X4VDAbVggUL1KZNmwz3LF26VAUCAbVlyxZ17rnnqmAwqM4//3yllFJ///vf1UUXXaSOOOII5Xa71dixY9V1112nksmk4fsA+vwQhUJBPfjgg2rKlCnK4/Go2tpatWLFCtXR0WFoR7FYVHfeeacaM2aM8vl8as6cOWrTpk2qoaFBLV269IDjB0Ddfvvt+v/bb79dAVAfffSRuuSSS1Q4HFbV1dXqBz/4gSoWi2rHjh3qq1/9qgqFQqqurk797Gc/Mzwvk8moW2+9VU2fPl2Fw2Hl9/vV7Nmz1UsvvdTn3W1tbeqb3/ymCoVCKhKJqMsuu0y9++67CoB65JFHDPcOZJ6z2ay644471MSJE5XH41GVlZVq1qxZ6oUXXui3/+yv/GloaNCfv/322+qcc85RoVBIBQIBNXfuXPX6668bnsH19X//7/9VV199taqpqVHRaHS/455Op9Vtt92mJkyYoNfITTfdpNLptL7nsssuUx6PR33wwQeG786bN09Fo1G1a9cuw/v/9re/qRUrVqjKykoVCoXUpZde2me9KDX89b106VLDGCk18PXa0NCgFi5cqF5++WU1c+ZM5fF41FFHHaUee+yxPu3s7OxU1113nWpoaFBut1uNGTNGXXrppaq1tXVQ49gfZs6cqWbOnNnn+rx589SECRMO+H0Lhycs5l9mjB49Wk2cOHFQ39m0aZOKRCJqypQp6t5771WrV69Wp512mrLZbGr9+vX6PhLHE044Qc2dO1etWrVK3XDDDcrhcKjFixcbnvmb3/xG2Ww2dc4556hVq1ape++9V40bN05Fo1G1bds2fd/SpUuVx+NREyZMUEuXLlVr165Vv/nNb5RSSl177bVqwYIF6u6771br1q1TV155pXI4HOqiiy7S33/ttdfU2WefrQCoxx9/XP8Q3/rWt5TT6VTLly9Xa9euVTfffLMKBAJq5syZKpvN6vt+8IMfKABqwYIFavXq1eqKK65Qo0ePVtXV1cNi/l/+8pfVkiVL1Jo1a9TChQsVAPXAAw+oSZMmqauvvlqtWbNGzZo1SzMdorW1VdXX16vvfe976uGHH1b33XefmjRpknK5XOqdd97R9xUKBfWVr3xFORwOtXLlSrV69Wp19tlnq2nTpvVh/gOd51tuuUXZbDa1fPly9atf/Urdf//9asmSJeonP/lJv/3fuHGjevDBBxUAtWTJEvX444+rP/zhD/q9gUBA1dfXqzvvvFP95Cc/UUcddZTyeDwGIZXra8qUKer0009Xq1at2u87C4WCmjdvnvL7/eq6665T69atUytXrlROp1MzWKX2Mb+xY8eqmTNnqnw+r5RSau3atXrNmN8/depUdeqpp6r//M//VNdcc42y2+3qtNNOU8ViUd9bjvVdivkPdL02NDSoSZMmqbq6OnXLLbeo1atXq+nTpyubzWYQQHp6etTxxx+vHA6HWr58uXr44YfVnXfeqWbOnKnX0UDHsb858Hg86uqrr+7zGfdUd3f3fp9h4fCExfzLiFgspgCoRYsW9fmss7NTtba26h+pPZ955plq6tSpBim/WCyqU045RR199NH6GonjWWedZSCE119/vXI4HKqrq0sptY/gRKNRtXz5ckMb9u7dqyKRiOE6Nfd///d/79Nm2UbinnvuUTabTW3fvl1fu+aaawzaPvHyyy8rAOp3v/ud4fqf//xnw/WWlhbldrvVwoULDf265ZZbFIBhMf8VK1boa/l8Xo0dO1bZbDYDU+vs7FQ+n8/wnnw+rzKZjOEdnZ2dqq6uTl1xxRX62tNPP60AqJ///Of6WqFQUHPnzu3D/Ac6z9OmTVMLFy48YJ/N2LZtmwKgfvrTnxquL1q0SLndbtXU1KSv7d69W4VCIXXaaafpa1xfs2fP1kx6f3j88ceV3W5XL7/8suE6Gfurr76qr/3lL39RANRdd92ltm7dqoLBYJ99wvfPmDHDwGjvu+8+BUBbSMq1vs3Mf6DrVal9zB+A+vvf/66vtbS0KI/Ho2644QZ97bbbblMADMIdwbU+mHE0o7W1VQFQP/rRj/p89tBDDykAavPmzf1+38Lhi0PX8fw5RHd3NwAgGAz2+WzOnDmoqanRPw899BAAoKOjAy+99BIWL16Mnp4etLW1oa2tDe3t7Zg/fz4aGxuxa9cuw7NWrFgBm82m/z/11FNRKBSwfft2AMCLL76Irq4uLFmyRD+vra0NDocDJ598MjZs2NCnfVdffXWfaz6fT/+dSCTQ1taGU045BUopvPPOOwccjyeffBKRSARnn322oR0zZsxAMBjU7fjrX/+KbDaLa6+91tCv66677oDvOBC+9a1v6b8dDgdOPPFEKKVw5ZVX6uvRaBSTJk0yREc7HA643W4AQLFYREdHB/L5PE488US8/fbb+r4///nPcLlcWL58ub5mt9txzTXXGNoxmHmORqN4//330djYOOz+FwoFvPDCC1i0aBHGjx+vr9fX1+Mb3/gGXnnlFb1uieXLl8PhcBzw2U8++SSOPfZYTJ482TC/c+fOBQDDOps3bx6uuuoq/OhHP8K//du/wev1Yt26dSWfu2LFCoM//uqrr4bT6cTzzz8PoHzru1R/BrJeiSlTpuDUU0/V/9fU1PRZR08//TSmTZuGCy64oM/7uNYHM45mpFIpACgZtMg4GN5jwYKEFfBXRoRCIQD7om/NWLduHXp6etDc3IxvfvOb+vqWLVuglMKtt96KW2+9teRzW1paMGbMGP3/kUceafi8oqICANDZ2QkAmmmQeJgRDocN/zudTowdO7bPfTt27MBtt92GZ599Vj+biMViJZ8t0djYiFgshtra2pKft7S0AIAWWo4++mjD5zU1NbpvQ4V5rCKRCLxeL6qrq/tcb29vN1x77LHHcP/992Pz5s3I5XL6+lFHHaX/3r59O+rr6+H3+w3fnThxouH/wczzj370I5x//vk45phjcPzxx+Occ87BpZdeii996UsD7/j/orW1FclkEpMmTerz2bHHHotisYidO3fiuOOOK9m//aGxsREffvghampq+u2PxM9+9jM888wzePfdd/HEE0/0uy7M6yAYDKK+vh6ffPKJfi8w/PVdqj8DWa+EeW0B+/ai3CtNTU248MILD/jewYyjBAX0TCbT57N0Om24x4IFCYv5lxGRSAT19fXYtGlTn89OPvlkANAEjCgWiwCAG2+8EfPnzy/5XDMj6U8rU/+basdnPv744xg1alSf+8zpcB6Pp0/2QaFQwNlnn42Ojg7cfPPNmDx5MgKBAHbt2oVly5bpd+wPxWIRtbW1+N3vflfy8/6IXTlRaqwONH4A8Nvf/hbLli3DokWLcNNNN6G2thYOhwP33HMPmpqaBt2OwczzaaedhqamJjzzzDN44YUX8Otf/xoPPvgg1q5da7BkjBQGyiyKxSKmTp2KBx54oOTnRxxxhOH/d955RzOy9957D0uWLBlS+8qxvvt77mDW60DW0UAw2HGUqKyshMfjwZ49e/p8xmujR48eVHssHB6wmH+ZsXDhQvz617/GP//5T5x00kkHvJ+mWJfLhbPOOqssbZgwYQIAoLa2dsjPfO+99/Dxxx/jsccew2WXXaavv/jii33ulaZ6czv++te/YtasWftlKKx30NjYaDBNt7a29rE4fFZ46qmnMH78eKxfv97Qv9tvv91wX0NDAzZs2IBkMmnQ/rds2WK4b7DzXFlZicsvvxyXX3454vE4TjvtNNxxxx2DZv41NTXw+/346KOP+ny2efNm2O32/TKX/WHChAnYuHEjzjzzzH7XAJFIJHD55ZdjypQpOOWUU3Dffffhggsu0KlpEo2NjTjjjDP0//F4HHv27MGCBQv0e4Hhre/++jOQ9TrYZ5ZSBsz3DHQczbDb7Zg6dSreeuutPp+98cYbGD9+vLZIWrAgYfn8y4zvf//78Pv9uOKKK9Dc3Nznc7NWUFtbizlz5mDdunUlpXfmbg8G8+fPRzgcxt13320wVw/mmdRqZHuVUvjFL37R517mgXd1dRmuL168GIVCAXfeeWef7+TzeX3/WWedBZfLhVWrVhne9/Of//yA7RwplOr/G2+8gddff91w3/z585HL5fCrX/1KXysWizqmgxjMPJvdD8FgEBMnTixp2h1IP+bNm4dnnnnGYHVqbm7GE088gdmzZ/cxkw8Uixcvxq5duwx9J1KpFBKJhP7/5ptvxo4dO/DYY4/hgQcewLhx47B06dKSffrlL39pWLcPP/ww8vk8zj33XADlWd/99Wcg63UwuPDCC7Fx40b84Q9/6PMZ19ZgxrEULrroIrz55psGAeCjjz7CSy+9hK997WuDbrOFwwOW5l9mHH300XjiiSewZMkSTJo0SVf4U0ph27ZteOKJJ2C32w0+yIceegizZ8/G1KlTsXz5cowfPx7Nzc14/fXX8emnn2Ljxo2DakM4HMbDDz+MSy+9FNOnT8fFF1+Mmpoa7NixA//93/+NWbNmYfXq1ft9xuTJkzFhwgTceOON2LVrF8LhMJ5++umSmviMGTMAAN/97ncxf/58OBwOXHzxxTj99NNx1VVX4Z577sG7776LefPmweVyobGxEU8++SR+8Ytf4KKLLkJNTQ1uvPFG3HPPPTjvvPOwYMECvPPOO/jTn/7Uxzf/WeG8887D+vXrccEFF2DhwoXYtm0b1q5diylTphhiOhYtWoSTTjoJN9xwA7Zs2YLJkyfj2WefRUdHBwCjVWSg8zxlyhTMmTMHM2bMQGVlJd566y089dRTWLly5ZD6ctddd+HFF1/E7Nmz8Z3vfAdOpxPr1q1DJpPBfffdN+QxuvTSS/H73/8e3/72t7FhwwbMmjULhUIBmzdvxu9//3v85S9/wYknnoiXXnoJa9aswe23347p06cDAB555BHMmTMHt956a582ZLNZnHnmmVi8eDE++ugjrFmzBrNnz8ZXv/pVAOVZ36Uw0PU6GNx000146qmn8LWvfQ1XXHEFZsyYgY6ODjz77LNYu3Ytpk2bNuBx7A/f+c538Ktf/QoLFy7EjTfeCJfLhQceeAB1dXW44YYbBj0OFg4THIwUg8MBW7ZsUVdffbWaOHGi8nq9yufzqcmTJ6tvf/vb6t133+1zf1NTk7rsssvUqFGjlMvlUmPGjFHnnXeeeuqpp/Q9TIV68803Dd/dsGGDAqA2bNjQ5/r8+fNVJBJRXq9XTZgwQS1btky99dZb+h4WQSmFDz74QJ111lkqGAyq6upqtXz5crVx48Y+KWz5fF5de+21qqamRtlstj5pf7/85S/VjBkzlM/nU6FQSE2dOlV9//vfV7t379b3FAoF9cMf/lDV19eXtciPLKSyv/6efvrp6rjjjtP/F4tFdffdd6uGhgbl8XjUCSecoJ577rmSueGtra3qG9/4hi7ys2zZMvXqq68qAOq//uu/DPcOZJ7vuusuddJJJ6loNKrXzY9//GND+lsp9Jfqp9S+Ij/z589XwWBQ+f1+dcYZZ6jXXnvNcE9/62t/yGaz6t5771XHHXec8ng8qqKiQs2YMUP98Ic/VLFYTHV3d6uGhgY1ffp0lcvlDN+9/vrrld1u18WGzEV+KioqVDAYVJdccolqb2/v8+7hru9Sc6nUwNYri/yYcfrpp6vTTz/dcK29vV2tXLlSjRkzRhfwWbp0qWpraxvwOB4IO3fuVBdddJEKh8MqGAyq8847TzU2Nh7wexYOX1i1/S1YGAH88Y9/xAUXXIBXXnkFs2bNOtjN+Vzg0UcfxeWXX44333zTOpDIgoURhuXzt2BhmDDnURcKBaxatQrhcFibuS1YsGDhUILl87dgYZi49tprkUql8JWvfAWZTAbr16/Ha6+9hrvvvtvKsbZgwcIhCYv5W7AwTMydOxf3338/nnvuOaTTaUycOBGrVq0acoCeBQsWLIw0LJ+/BQsWLFiwcJjB8vlbsGDBggULhxks5m/BggULFiwcZhiwz9/n82Hs2LH6kI2xY8fC6XQiHA4jmUyiWCzCZrOhUCggm83C7/cjm82io6MDdrsdLpcLDocDo0aNwo4dOwwlJ10uFyoqKtDS0qIrq7ndbng8HrjdbrS2tkIpha1bt2Lv3r3o6upCd3c3MpmMPrxioFiwYAGy2SycTie8Xi+cTifS6TSKxSKcTiey2azui81mg1LKUBfcZrPBbrfD4XDAbrcjkUjAZrPp/wuFAmw2G/L5PJRSsNlscDqdcDgcyOfzsNls2LNnD9rb2xGLxZBMJvW9g8VgS4F+VhhsX74o/QC+OH35ovQD2Ffbv7q6Gna7HXa7HU6nE8ViEfl8Hk6nE0opFItFKKXgcDj0vpfv4/dyuZze1/zcbrfr8waKxaJ+Rj6f19cTiQQymQxyuZx+12D7wjYA0PSJ75Tt4edm8Jpsr/k7sk3ymbwu224eo8FA0tHKykqMHTsWNTU1OPbYY+H1epHNZtHS0oKenh5UVFSgsrISW7ZsQT6fR1VVFXw+H/L5PKqrq1EoFOByufDxxx/Dbrejvr4esVgMxx13HOLxOLLZLOLxOGw2G4488ki8//77GDt2LBKJBGpqamCz2bBjxw4opfDwww8Puh+HIgYyJwNm/jxiMxKJoKGhAVOnTsXYsWMxZswYPbjJZBK5XA4ul0unP3V2dsLj8SAQCMDv98Pn82HXrl0oFovweDwIBoMIhUKw2Wz49NNP4fP5NDNVSiGdTiObzcLj8SCVSqGrqwtKKRQKhSEtuilTpqCqqgqVlZWIRqMIBALweDx6MSaTSX1voVBAPp/XRIIbxuVyIZ/Pw263w+12a6LB73Mzyg3idDq1EPG3v/0Nb775JrZu3YpMJoN8Pj/ofliw8FlCEjkzwZPMsNT/vGb+/oH2b7nCkYLBIKLRKEKhECorK1FdXQ2fz4eamhpkMhlNS7i/0+k0PB6PFsodDgecTqfep2TAxWJRM3uHw4FkMgm73Y58Po9sNqu/m06n8eabb6KlpQWFQmFAh2KVgsvlgt/v13QzGo0iHA4jGo2iWCzqd3J8s9ks7HY7bDYbcrkcHA4HPB6PVnBIu/gdm80Gt9uNeDwOh8OBXC5nKJ9cLBbR2NiI7u5uLQQNB/x+oVBAoVBARUUFNm/erMcnHo9rAYp8IJlMarrc2dmJqqoqpNNpOBwOpFIpRCIReDwe7Ny5Ex9++CGOOeYYpNNpJBIJ5HI5fPzxx8hms0ilUujo6MDYsWMRCoWQzWYxbty4YfXn84YBM3+HwwGv1wu73Q6Px4MxY8bg//v//j8A+xZFW1sbenp6kMvltDbt9XoxZswYRKNROBwOdHV1IRQKwev1IhwOo6urC3a7HdFoVG+siooK7N27F3a7HaFQCA6HA62trQiHw6irq8O2bdsMWvlgMW3aNNTW1qKyshKhUAg+n09bJoB9R2NSmud74vG4lpa52bmJXC6Xvg5AS/YAtCWgUCjAbrcjEAggm82ivb0dXV1dSCaTWiOwYOFQg9QUuf/70/YorNvtdsNn/J8aI/cUrWCEZELFYlEz0WKxOCyGCexj/kcccQQqKiowatQojBs3DqNHj4bP50MikUAqlYJSSlsDXS4X7HY7MpmMQUMtFovI5XJwu92aCTmdTthsNq3sxONxA8P0er3IZDJoaWnRgv5Qhf1AIIAxY8aguroaRxxxBI4++mgcc8wx2iLBfrhcLni9XoM1kgoJBZV0Og23241YLIZ8Pg+Px6PpdqFQ0LQc2De3brcbqVQKGzZsQGNjo9bKyyEAkJkTiURCa+xk/LlcTitPPEskkUjA4XAgm81qay6wj4b39PQgmUxi8+bNcLvdmm77/X5Nb/P5PBKJBDweDxwOB95///1h9eXzhgEzf2nGstvt8Pv9CIVCSCaTBtO13W6H1+tFsViEy+XSJm8yyEKhgGg0itraWi3JUXJzu92amWYyGTgcDoTDYbjdbmSz2T7tGcrCq6mpQV1dHUKhEPx+P7xeL4Bey4bL5dKme24el8sFpZSh/3RJsL3cYF6vFzabDZlMRj+TmkUoFEKhUEB1dTUikQh8Pp+2OliwcKiBe8Dj8aCyshJHHXWUZoTpdFpbxOjCU0rB7XZrwZlmdp/Ph2w2i3Q6DZvNBpfLhXQ6rRlNIpHQ9IGWQ4fDgebmZsTjcaRSKaRSqSELAG63WysctbW1GDt2LI466igAQE9PD7q7u2Gz2RAKhRCJRADs27Nk6A6HQ7eJNK67uxuFQgEejwfFYlGblbu6ujTTLBQKCAaDyGQyqK6uxq5duxCLxYZMu9xuN4LBIGpqatDQ0IBjjz0Wxx13HGw2G9LptFZS/H4/AoEAHA4HCoWCZnacD9K8QqGAWCyGQqGg5y0ej6NQKKC7u9tgvXC73chkMti6dSs6OjrQ3d2NRCKBQqEwpDkBjO4EpRTi8Tg6Ozu1lk9BKZFIIJvN6poZVDBpaaVVxmazIZlM6rM3KKSl02ltpfX7/Xr+MpkMOjo6tFWku7t7yH35PGLAzJ+TE4lEkMvlkEgk0N7ejlwuhz179ujN6XQ69aaQphqllDYVhcNhfX8ul0MymUQoFEKxWEQqlUKhUEA8HtcLjJsqFosZzE1DYZqUAIFepmy325HNZvVmkeYzbgzJ/F0ul26X9PGxTXwOhR9aDZRS8Hg8BoGB91iwcKiBjLqiogITJkzAnDlzNFOhhuv1ejF27FjtQ6ewTg3TZrOhoqICyWRSM1m/349UKoXm5mbt281kMshkMuju7kZlZSWKxSL+9a9/Yffu3Whvb0c+nx+WhYz72+v1aqG/WCzC5/NpbT4SiSASiSCVSmmFhDE7LpdLWwmppdJMnsvl4PF4kEgktICfzWaRSCS0sOTz+QyC0VBBJke6QXrjdDoN7aRQQq2ZNIa00+fzIR6PIxAI6DYyVqunpweBQABut1t/P5/P6/EjDSOdGw4oAOTzebS2tuoTL6k4cd5pwcjn89pq4ff7kUwmEYlEtHJK64rH44HX69UCAIXLnp4ebU1OpVLo7u5GW1sbnE6n4bC1wYJz4vV6tcXaTNc571L4IqjgMgaF93Ot0c1MAdjhcOj9QJd7JpPRfGYgGDDXoY+op6cHTU1NqKqqQm1trV5g9O17PB7s2rULU6dORWNjo/ZT5fN5xGIxKKXQ0dGhF1IwGEQwGNSLVZqmMpkMtm3bprVm+ufMAzcYULigKZ6Eqq2tDR6PRwsDlDrz+TwKhYKBwafTafh8Pm1eYvvJ1Olrc7vd2szJzeXz+bQ1BNg3qW63e0h9GQyobZhdJmbT62BwsEtElCKi0uwsTcnEwW7zQCDn6mC2l4y6qqoKRx55JCZPnqwJrs/nQzgcht/vh81mQ2VlJbLZLOrr6+HxeABAKwOpVAoOh0MT3mAwiGw2i7179+o91NHRgfb2dnR2diIcDiOdTqO9vR3ZbBaZTEabgYcCMn7uUY6t3W5HVVWVNvvStF1VVaWVE/YvmUwiGAzqUy1DoZCOI2hpaQEA7NixQ68/+pkTiYTe85JhD0UAoEWBjJBCRyqV0qZwl8sFl8uFTCajj2r2+XxaaEulUggGg2hra9PCTyQSgdfrxd69exEIBLS1gLSxublZMzPSZio1w7VaFotFJBIJ7N27F7lcTite5BWku1xDZIjJZBKpVEqvDbqWqNAFg0F0dHTotUQLUywW05as9vZ2TaeHa4H1eDyoq6vDlClTcOaZZyIcDqOiogIAtABJQXHSpEnaOkxXzfjx47F3714tKFOwpODb09NjCEgPhUJoamqC0+nEyy+/jDfeeAOffPKJFgIGgkFp/lKi7ejowCeffILq6mptekmlUujs7EQul8MLL7ygmX4gENAmm6amJr3Z8vk8amtrYbPZ8MEHH2DChAlaiqHZJ5fL6YXa2dmpicBQNxA3OBeWx+NBLpczBPyR6cfjca3pUyCgT58+QWlFYGANNSJaCrjJgsGgthYA0D6s4UrPEvsbk/6CtsxZDaUYTqlrB5s5SZjXgxRyOOYDDTQ7WCg1P/sLpBvpftBaRxN9NpvFqFGjkEgkEAwGUSwWdTYPNXZm8lRUVCAUCqGzsxO7d+9GJBJBIpHQmqNELpfTwrjL5UJbWxu8Xq8m2IPN6DHD5/Nphsa+0Ezf0dGhmRrpTiwWg8vl0lYAp9OJYDCIvXv3IpFIAIC2ChYKBXR1dWkGL2MbAGhhgf2gJjeUuaNWyPdmMhnEYjE4nU40NzfD5XIhm81qwYBzE4lEkEwmtTbc3NyMzs5Ora1mMhn4fD7EYjH4fD493tKd2dbWpucwlUppJlQOcMwYg0Fli/0EoLVa0lXyIvId6S4iY6UlmX+TVgPAJ598oueAAukHH3wwrH54vV5UVlYiHA7DZrNpgcvtdmtrDN0SlZWV2kLu8XgQj8cxZcoUOBwO7N69G11dXdrtNG7cOJ1ZFovF9Bgdd9xxqKmpwQcffKAtJYPBoDT/RCIBl8ul/XAej0ebTBKJhDbTk+FFIhFks1ns2bMHTqcTfr9f+1oAaBcCJecNGzZg8uTJWppVSqGiokJLa5LwDcf/R/MJJU0G9ZHAcdHRXFYsFg1RphRMqBm1trZqsxiFIRIuoDcYir8ZxUrJ+bOI9t8f45d/9xepfShoz7IN1LBKMUmOM8GNzzVzqAgB/Qlqsn2lrDSl5mkk+iJdXWQE2WwWgUBAMwheY6wM93Rzc7MmXrlcDj09PfB6vUilUmhtbdVBWsyuSaVS6OnpQSaT0fEBNOHKINqhgP777u5udHd367bn83m4XC7kcjkDXXI6ndoKKPd5Op3WDFIphU8//RTbt2+H2+1GPp/X2QOxWAyZTAZ+vx8dHR36fTKjYKhaJl0jXV1d2hfO5+VyOWQyGa39kbHIeWRbOzo6tLV19+7dAPZZM/bu3YtoNIru7m7E43Gt4PT09BiCnsupsCilkMlksHfvXqRSKZ1NZZ5zr9er3b60PFDT557gd6iQ0uQvLTI+n8/gomZ8Q1VV1bD7ImNY6urqtMsEgA48bGtr0xbfYrGo196ePXt0ijzTzymUMCuNMR2Mn9m9e7det4xRK7vZn4yPGm8sFkNnZ6f2szCwIp1OI5VKwefzob29XUeRAkB7eztSqZRmoLFYDOFwWEcRFwoFbTpLp9Pa3E+/jQwCkRM9GJDpA9DtIHFgIFI2m9WTFgwG0dXVpfsv04EcDoeeaJvNpjUaZgxIPxwXHrVrLlbeNxIwExhzvQIJMkezgMXFZF5QnzXjNDN3M4NkO7mhKeVLYivbfCgIMPv7X0bOS4uMFATM6XMjKQAwPYqMAgDC4TB8Ph+SySQ6OzvhcDjQ0dGhmWMymdSBVB6PR5tBM5mMtoJRA6egTd8nhe9STGCwoDWRUeQ0GXNPywDfeDwOr9eL9vZ2vceVUjrFuLOzU6ceM3aA97W1tel0Z45bIBDQ8RBkVEOdJ2mBoeJCVwqZMp9PbZeZUnJ92O12dHZ2amsLLQJdXV1aWyadpVWGFlIKZ0NNtS4F0n6uAWZZ8DMGlprTDmnRk7yAbeKcAr17ikIL47gowNCV0dPTM+Q+0NLIn4qKCnR0dOhAUq/Xi0QioWmUUkpbt2KxmGbqDLikOyIejyMWi+l7SQ9CoRBaW1u1UkwaOBhXzKDM/tKvQgZMLZZBMvF4HF1dXdrkz0AXMj+avuSk0S3AVBP69ukfYzQnNQG2ZSiLjxPORcXFTELDwCNJgNra2rQZiu2mICRzf3kN2KfJMPJfxg5Q8pYmrXJDLnqzttyfJimDdwYSUCmFl5GGuT9c6PJz9o1mNun3lwWXShGtz6oPpcZVzpHU5uVclWL48l7zc8tJlLlHqS329PTowDcG5jLjh0J7Op3W8S+SPrC2B4lUNBpFLBbTjIt7ia42c1uGCgovZMpKKZ1iKwVvxhn4/X6D1Y7FdVKplHYFUnOkYE96ZxbUpHVvuPudY8S+cPyVUlqLJPNubW1FIBAwuElloSIzI5KZGaSFtLhImjvUgmQD7R/pkDlAkcxe7gdzfQbeJ0FFQAZp0krLMaGiMJyAUtIe8iwpuPv9fkQiEb0f2Bcqh3S10PXi9/sNGTVMPwWg54ZzLoXKwWJQzF9uUkonNAfR102TBaU1EgkAhhxXLi6aZRgpSTMiJ4n+N7NkO1RtQGr9ZPZS0mX7ZY4ppWu2SUafkggwaI9uBZoz2WYZqUkLBlDeClGSOQIwSIHmz8ySKhcvxxlAn3Eu5RIYab+/uY0yjQyAIdKZ/9P3yTGQgUSAMcbCbFofqT6Y+2LuH9taSnCTEbyS+JUSJsrdD74vm82iu7sbLpdLrxUSIZooC4UCAoGAgWDF43EdHNvV1YVAIIBwOKzngJoe6QH3oVyHHIOhQhbrokBvDsaTGUa8L5VK6TiEYrGotX+ZFWQm+FJoYz8odALD2+9S8SKt6unp0eZ8zgndAsViUVsAyPgdDgdisRiA3kp/1HzJ/OV+IL2n4ESho5x0C+hd72T8ZjedmYaarV7mPcx5kEGAAHTQHYUe6S4YjvuVzJwp4LlcTmdSeL1evS+Yhsg9zfRNzo/P59OWs2w2C6/XqyvR5nI5xONxLUCMGjVqWPFvgw74Y8QhfU6snERmKCUaLnguPqaOBAIBzXAp4dDvz0lhhSn6Cils0Gw/1MWXSCS0GYzghDC4iVYMqbFwczPy0mbbFwHMlBMuVvotKyoqNBHkuNhsNu1jlONabgGAREhqx1IjIUGTpUwpgEmrjLR0mKVL82YcCZjNWWbiyqIdoVAIgUAAiURCrz0pIbNoCfspf39WkIKLuX+SAHNOOK5mi5NkiuY+jIQgQyLECGRgn1VL5kxTUO7o6ACwL+KcJn+awcmoGA+TSqXw6aefwuv1ajM8lQEZVEalYjj7hM9gZkF7e7umRfThk95QuAH2zQ+Dk9PpNJLJJMLhsC7Ty3nxeDzo6uoy7B3SCSpI0uow1Pkh4+c4dXR0aOsig4w5H/xN3z81x2QyiVgspqP6AaNWTVou93c8HofT6URXV5d2aZZ7//B9tBbbbDZtfSVtJQ8AeveT5AulLF/SWsD7mApIBYG8arjM3+PxIBKJ6NoOMvuLyiCFYsZrUFioqKhANptFXV2drj3g9/u1UsyYtPb2dvT09CAcDqOlpQWBQAChUAjBYFC7x8tu9gd6yzAWCgWk02l88sknOm0EgIGA0RfW1dUFAIaqUy0tLTrKlGaRfD6P3bt3o7a2VkcPx2IxpNNpRCIR7ZNhAM5wiAFTlQDovFG2paenRxOiYrGozZLcTFJrZ+oMAyF9Ph9cLpeuXsh2A/sIUDQa1W0wa2/lADUyacqSpi0ZJCfTjuSYynGhdmE2uZn9aiPBRKU1ghYk9iMQCOh2VFVVoa6uTm+GyspKVFZWwul0Ih6Po6WlBe3t7bqfZi1a/h4JmK0VUsvnD+dEamBSqKJpmcyGc2I2MUuhoRzgO8lwGK1PbZ51KoDePaWU0v50CpmcFz6PVgTpD+/u7tZxA+wn92IpbW8wsNls6O7uRigU0mmFHG/GH1CAB3rLyjLwmMqGx+PRxX3YT+b2M0WR36XiUlVVpRUk9muooMIRj8fR09OjI/3ZDxkUxj6zH3RzUNskLQX2KUQyY4FmaLaXRYoYyFiOOAwJs8YurXaMNZCWAI6FtFbK/Hh+Ln9zr7DPfIecE6ksDRYUyjleVVVV6Ozs1MIZszP8fj8qKyt1rj8LJlVUVGgLGhUxxgPU19ejoqICDocD0WgU6XQaO3bswLZt2/DlL39ZWwPYp4Huk0Exf9kJ+uW5wGTaWiwW02UjlVK6I9IXWCzuywYoFArYs2ePIS6A6UAsNJHJZFBTU6OZtDT/DxZ+v19/j5pAPp/XPjBJjBgFKmMQKJ3KcpJkRjKdhgGK1dXVqKysNAQTsa/StzZckLlw81OD5AaRGg2ZjHRbcMFxM5GZlDKdcfNzXkcCUmhh2VUKj8xLDofDmhG6XC4cf/zxqKur04VK8vk8Ro0ahf/3//4f7Ha7Di5LpVK68JTZLDsS/eDYS8sFzXxk/lwT0k1En6x0ndlsNu3flXPCvxmgVi6Bhgyb+dQ0MTN1jSlIbrcbHR0dWpvhXEkNi1oci7Q0NzdrwZ/CglQuSNCk5WMooMDB4KlwOIyqqirYbPvSsRizQA3a6XSip6cH8XhcWziCwaDhYB/OARkqq8UB0BYR1imhJUS6nobSFwpitFh0dnaiurpaFymKx+O6+BgtL6yax1iYQCCg9zvnUsZm0JVRLBa15sk4Lu4hMqlyrTNJuxilL6uqcs8wrkpav0jfSKfMljDub/kZhVK6nAFoK/RQQd7FOhEejwdHHnmkto7zvAju0Z6eHl1lVimF3bt3Ix6Po7a2VveRbpyenh58+umn2koVDocxZswY2Gw2LXSGw2E9PmVn/iQCQK/UxehILmyZCsJGM6qSRDoQCOiAOqYL0jTe3d2tTwmkLyQYDCKdTmPv3r19TsAbysJTSuniF9K3p5TSVcvYProYSICo9dMXQ2ZODYh9LRaL2gRHUxkrpUkJ3CydDgeSyTscDh2URdDtwgIrZvO+lJylOZDEm9YBAAZrQDnzfc19IdNn21mMY9SoUVq7p8+roqICRx11FCZOnIju7m7Y7Xa0t7drzYzrkvdTCP0s4hUobNGELH2YJMjUDGUQk7QCSB8mGYs0U9JSRUGmnMyfzw0EAjoqnASbQiytdLIiHACd7sZYGFbA2717Nzwej04lkz7prq4uw3PKMU9SyCbh93g8iMVi2lIpffvMWmC8QiwWQyQS0Xn79OWy6BHrAQDQsQIs7EVXh2SWQ93zjFng80hjmXLN6O9icV96cldXl6ZNTMkOBAJaIKBFgzn2ssqcdAHI+idm5lsOUKiV+0AGlpvHjvuKQqMUmHlPOp020DXOCZ9tjisZTl/4bNItAAZrDwXojo4OnbpOmkq3NytC0v1KQa+pqQmhUEjPAzPrbLZ9xbWo8HGvDhSDYv5Ab6qcWdpk4QFpomPHSLDoP6QUJ300JByUdmTgBzW5cjAZ+vEp8fJ/oFdDYC1xFoggYeVi5BhwU9PcKbVnMia5KBhgJIWL4ZiazCAzoYtFavvc4AB0zAU1MgozJCjSrQH0VmqjoMCxA0oH25SrL1IAoGDDqnJHHHGELtpSU1ODk08+GUceeSRaW1ths9n0CW5Op1NvNqaRyUAsCn4j5b7gZmZQKM3k/N/v9wOAFnLpfspms4ZxJqHgfFIjkhuev4daCa8UOOfUaqg9m++RAi33OQVrxu3IiGWppXIsZGCTzPMf7r7nmmbwLrUupZRuA2kP++HxeHS/uVa456XvmOb1ZDJpqLJHLYyWDrPJf6iKCwVYVhDkPiYNS6VSBqFcRrqTUTLImeuJY0zmz/1GgZt0gXS/3MK+eSz4TpnaRhcj50IKuWahQMYHSIbOvcjKq/xOf+0YDGSbKOyGw2F9Yi15i8fjMZSA5jqiAs39n0wmDTEjdGNy7dGtTNeTPJBuoBiU2Z8DzYh3mpfYAMnQKOmTSDGogtIYN4hk/ObBpFlGBuiZzTqDBSV0c1SpXGTcXNT6pcTLBccBl8yPkiTPmpYaJrCPODPQkfeXi/lTE6PLhMRWap3UtFhXQQomlDYB6A1CYsixlqY+9lX6DssJaSZnyVKv14tIJAKXy4Wamhrtd62rq0NDQwNqa2u1WZeEK5FIYOfOnbowDQMCZV9Hov0E54RCDN9PbdPv9+tAM/abpn6m8gC9wgKZkJwP6W8sFoua2ZQLknHSZcI1LNc/54rWM+4fuurYH8YEkJBzjChkMuC2XPnkHKdUKoVYLIauri590iiFPwpSDNJlQSJeLxQKOn5J7ltJuIFegRnoDTSU9GM4fZHMn35/1kOh21IKh9T2pTBYKBQ0Xc3n89p1R4FLmpzld2g5MddeKKfALGOTSpmvzXEzpd4v6ZPsA9eppMmleMpwwawR0lvp6uM1WlRkDBktynQ1U8Gk4MDCejJWiNlw0rI0GOvFoDV/bgQW6WFVP25WoDeYSTI9KeWQ4ZsPh6CUKo/MLBb3Bd3xzGr+DHXCmG0ggw3po2dbaK5hf0m8pGbMTSfNSMyRDYfDhnQSWTCIAgOZQLkWHp8ZDAY18SJDIXMHoMuykrmTQLAvUhNjlDzQGyhDQs9xop+3nBuImxzoTUdi33hoBo+L5gZpbm7WZ0bQUkTtmYyFc0oiIys4joTmT9Mk/cWM95AbGIAWxigUsDCWFL64XorFfRXBpGAAQO8rBpqVqz9yvzO+h4I+iSmFe6btsV9kJhRG2HcSeBbFIsGi5YzR8dI8O5y+SFcJNSoW5+LZ9VITLBQK6Ozs1HNCxsgAO5bDlRH9drtda9MMsgOgDyOTFqfhzAW1eipcpJPUCgnODbMteI10m0Ikq+YB0EInTcp0X9psNh20WI5+mCHXEYMspVYvaTFjWng/939/vEHubRlDIK2a8tnD6QOfz7WUSqX0+QFMcXU4HNi+fbs+1TYWi2mrNq1SVHYo1EUiEW1FotLK1EGeIjkUYWzQAX/sIA9jYIOl2Y/BP5LBSb8LgD4mJPqrKGWS0NG0yyjX4Zqd6O/n4udGZXuA3txxRplKMxSD/0j8WIeAhJgVARndLCX+WCyGqqoqLQQNJjhjf5AbhxoNzckywIwBPFKQYewGx5QCmdmvTOGBmhx9hNJ9Uy5QOjcXeqGG6HK5kEqldPGMyspK1NbW6ghYt9uN7du3a42azJWll7mRQqGQPjdiJEz+7AdPHWP8AvtCwYTuGamtkxDRVSCJFdei9C2yYI1kZuXqE60JzB0nE+S6knEKkjATSikdhyGFGL/frwU7vocCAF0GMkVuuH0gPWGkPABtxifjo/DE6HkKX9TEZNof+8m4Dc6fpCXcW1R+htsXfp+uEx5DS9OwPEa8p6dHrxOOI+krBUsGbXIMaIlivAI/Z6qa9GOXa31J1xLXt/THk2bJuBYyfCqMZouwjJWRn9HFI3mNVAaGCu63dDqNtrY21NXVGayMzF6jEtDe3g4A2orT2dmpA/pCoZAWUkkXGC/EvdLa2oqamhqdci/HZqAYtNmfvwuFgi6XyY1NAiD9qOYB4kBLCQmANhdyA8lT8orFoq5DbfbzDBZdXV0YPXq0oU1k8NT+2RebzaY1dWmu5yIhgSBxpjuEhJqbjO32er1oa2vTzyKBHI7ESXDj8qQxWlZoaqK2TAuFNMcyjWTv3r2GzAQKRqFQyEBUKBDIQK5ympkpNHFMGa8QCoV0EOV7772nA8h4umQ0GkVNTQ1qamrQ1taG7du3a9/xnj179NyRCdDKxDkeibgFjh9T4zgPFAQYmMm1TqFw1KhRAIBPP/1Uzw9TspxOJyorKzWBM2s1LS0tZRXIaOXJ5/cduyozX6TQIt1gJFRc+9I1BuyzdphjE6S1UEYuD5dhkihSoIjFYtrkSubOvSgDzZiqJeNd+FsKN7TCMFOJWjjdThQihqu4cAwojNHUT8ur0+k0pItx7BmfJfsh3TayH3w2NX7GP1CQlof6lNvaRwZMgUwyVLOLSQYls18yDolzJF26Su2LReFBbQSFjeG4YKkQKqUQjUZ1LAh5I6vYZjIZ7NixQ8drUAmh0MW6/U6nExUVFdizZ49Whmltstv3Vcfcvn27VmBodRrM+ho08+dioe+IvnFpumMDSOz4PfrapTTNiaEJVgoRJDJut1ubzyQhGMrio+mKtcVJAGTAIqUzWjOY4gQYi0swFsGsAVCY4GKiBM0JJPi9cmn/UjIMBoM6Wtnv9+v0o1wuB5/Ph56eHkQiEdTU1GDv3r36RCqOCWMyGH3NHGCOf0dHByorK/WzypGuKEFmJkGCTMHkX//6F6qqqtDS0oJPP/0UdXV1+OSTT/TcJZNJtLS0aELJeu0yeM5c4rWckEGLXA8UZJieQ62Km97lcqGqqgqffvopXC4XgsEgAGgC7nK5UFlZiZ6eHvj9ft12mgDD4bBOmSonqL1IwYnrm3tVuoYImXoo9zuDn0gTeJ0aKAWhcjEZaUKmC4O0wDz/cr/LOBGg90hw6bqhxYWR/+yLz+fT2RG0GJZL86c1geerUEOXQqxMZWPwMemNrNTH69Kq193drek2Y4jI+MuZTUJwb9CNYhZe+T6pZJDmcUy4p+X9HA/yH1o0SgnHwxUwZZEqeS6EdEs4HA50dnbqw3ykJYkWZHkYEWmIrC/BZ1KwlErDiDF/ObAyCEESaSmBUYqWEhvQG6kspThpjqLfjEyIz5cdG+pEkalw4Ln4OTn8m4wf6D1NipqKJOTsh1kIkMSRhIPPo4QoF+9wQPMyiU0oFNInVHm9Xn2cpMvl0ik+VVVVWsiZPHky8vk82tradOwG8+kpJFFDZbtZ6IV5w+XUnLnAOTYk2BTQvF4vqqurNcNkOlNTU5NOm2lvb9eBWGRaLKPJeaemOlIBi/Tf8zhnHmzDQ2GYOkcGVFlZqYMtp0yZoqu4SQGbB2HZbDZdPpSaLc9qp0BWrn5xDvhM6e+XrsBShMfsWyXIbOjblLEDZK7lYJal+sGaBdzjZh8xLZdsp6QT1N4lg5LBf3wP1xXHplyCjLSg0GTM5/PdfAczAOT4cs5kwCX74XA4tFtMfk8yXtmPcgoAtDjIPso+UyCU16TF0dxW0ioZzyH7LOvF8PvDbT+FMKaDcn/T1UAaRHpNAYxKNIUyCguS39AyLXmUdHcwIHMw/RhUwJ+Z+dNnJM0wHAjeBxhTMMwLj/fxO3KyJAGQh7UMB4xuJ3NmgAnN/Wathf5YtlGa6qXpU46TDKAj8ZPmSzKGcjB+oHcjuN1uRCIR+P1+VFRUwGaz6YDGYnFf1kQqlUIoFNJSMEtLMuBEbh6Xy6UD7OSZ6LlcDpWVlTogaKQ0Z84RpWESVAo5XB/JZBLt7e3I5/MIhUL6+FYSMvraaErO5/MGf99IaDJArzbD9ERaViiQORwOfbgNMxQ4J1VVVToyXq4vfpcxHBRUC4UCqqqqdJBjOVxJEmSK0vUGGANACflZfwxPCg38n8yf+6OcWr/cw/SXk9BK9wI/5/eofUkaZvatSubPe9l+mmzLtcakJinTjTkHHDO+W35H/pjH1mxSl7FCdB1wL45EjAzbzLE1W1ol05OKo1xr/cE8b3SBSMGnHO2nksKgPSobnCe6X81uGaA3RoN8Q8aYUCnmYVM8fdbj8WghdiiC8pB8/gA00WEDJUM3LyrzBMnNaBYqZNCQOQ3PTHCGAhJXDrIM7KMviIyP/WT5XmkhkJMkg7j4XZrLzBuOi48EerBBGqUgrQ7MipBWANYxr6urQzabhd/v1y4Zfs4COtRWmesbCAR0+dN0Oq3PQ/f5fGhtbdXugHJq/hwP5hwzwJSMW1bo49iz9CzQa6rldclEGbEuN95IgHNCBl8sFrUg5vf7dbWvuro6bb7jnEQiEUOpVcZucJ5Y74A+RJoQvV4v9uzZo+eunHMig9b4v5nY9Lf3zVq/NMVKpii1bO6NcoHvIFElIQV6CyRJIcasuEh3JJ8jrzNAFuilMYyL4houpwWDzF1aKWQ/zO2UfeEz5PxJqx6FIgpjfA+D5EZCUJZrxcwnKICYrawcU9IAuf5k/6Ugwb7yiF3O93D3CteODCKncidPs6XSId0n/B5P9OPckpfQMigFn1wuh2AwiI6ODn0M8GD5yJBVNqlxSEIgmaHZPCY3s/lvSQykaQroPYmvHOYmMvBIJAJgn1+MfrlUKqUJrfSRyWAgRlabpWQKD0zniEQihmpyZJAk5mQ+0jownD4xcpzm1GAwiGg0qq0QgUAAo0aNQl1dHT7++GMEg0FdEpL+vGg0qv25XKiMFeCYOBwOHTVP4aDcEf/UCPleRk+TuFVXV6OtrU2b75xOJ6qrq+FwOLB582ZdTCkej6O9vR2BQADt7e0GsxjnbqQEAJoqqWXQJ0yrC4lWdXU16urq8NFHH+kARgoHPT09uvofI7npS6bwmMvldJYHD6hiamE5QZOk3Hv7Y/7y7/3tV7OVQJr8y8X8zW2iACAFeUlbpKZsplMyiEw+UwoCNltvOp6s1lYOU7nZikEXohRazJq5+Z3SekBIJij7JN2v0upTbgGAFjxz//gej8djyEwgpM+fkAoj16z8ntSU5fgMh4ZJa0pFRQVyuZyuukj3En33dO1RMGDBK/IcmvtJlwOBgOYlSilNh5lqSmFhsHFXA6YQ/UlGcrPK+3ivZOZygMzPM1sA5CZUShmCV4YLpsEB0MzF7XZrcyoXCU3NbrdbmzxJ0LkQZe4yiTOlPgYE8j5Glkstm2M0XNB8X1dXp6OLGRDGsctkMjjyyCOhlNL+eqBXY9i7dy/sdrtOnaOfnfn8DEaLRqPYunWrDkYDylfm0wwGANG6xIAkRmyTycryo/F4HKFQSJdWJeOXBFIKqyMFCoPV1dUYM2YMUqkURo8erU/1oqY4atQorWWxTkMsFsPYsWN1Ku3o0aNRU1Ojc7sBYO/evQCAiooKVFZWoqmpSaeyAsPXZiTIYErtXXlPqb/lNfM6KUWAyWTL1XbJsNkPWbmvFLPcH73rry9S+5JCgNTIywGpKMlS26XecaB56g/sB4NjyVxGSli22+1ak6VLkjxDFitjn2XwIr9vFuA4TjLLAYCmvzLTQyqbQ4EUMCiUFQoFwxkCpMu0oPKMnFwup8+HYcqmzdYbw8MzI6jEMXuIRbekFWEw9GxQPn8zg5bBCYTZjF1KSiy1sfbX8HL5xvnubDarg+CkqYYpLlwckUjEUFmJQRpKKUQiEYOZjxo0C/wwqIsLy+fz6WIN8jjdcjAfCitK7Tvljlqy1BRra2v15olGo1pz5He2bduGo446Spf+bW1t1eYrt9uN0aNHo6urS/uleJZ0JBLR7o1ygWuGvi5eI3Ftbm7WfeFvEnOeSMbiRLTUSMlZmg3LySAlpO+Xpn0WwCGhO+qoo3Q9A1ppOCdHHHEEPvnkE30P54QFfnw+H8aPH4+uri5dFYw1JCoqKso+J4BxLw91zA70vVJa6XBRitaYNfGhMMn9fS7HvtxFcSSkheRAwtdgUGrMRkrr5x4k4zMH4skgU6lUAn1P4uO+k0HiXFOkJax6KJn1cOdHqX0VJLkfOS8UZO12uz7sjgKhWTCU/JQCADOpyKsoPDA1UJ6HMNh5GVK0v7nT5k0kCSyvmQWC/iA/k+4C8yQPFTSbSInR7/drjRKA9nsXCgVUV1cbUpxkqVLW9Jc+c0b6+/1+rfW7XC59ZGgwGMTu3bv7mAqHC0aV79mzB5FIRB8lKs37tbW1SKVSuugMF01PTw+i0SgqKyu1ps+jmuvq6hCPx7VPmv4rVnakeb5c80NIzVzOFbAvFUup3tMi+aOU0iY9uXYk0SplIuT7yg3GTuzdu1cH/DGdLxqNIhgMor6+HolEAtFoVG/uQmFfhbnKykrtNy4UCgiFQuju7sbYsWPR3d2ts1BYdz+ZTBq0GWmRKweGy/gH+56Rep5UNMzrQVogysFApQA7XJRqZ3+u0HL1Q7o3R3LeHQ4HKioqDEW3ZByGZN6EjEkw8x+2neB1mty9Xi86OjpK3jsUsL3pdBqtra3aJceS3DabTR9zz+qMdK0Wi0VtuWSGBvvL1EQKLFQOWAvBbrdrl8GIMv/+Oi1RytdnFgLMFoQDfb+UiW044LNktTFGtgO9vn3e6/f7td+LJXw5OTabTecrs0ohId0BXAT0/8sa7+XoG8ctHo9rMxf9TewTj4uU1RiZx0+mRDdHMBhEZ2enPguBloRQKISurq4+0djSV1gOSOLG5wPQkbM005mZuznq3EwUzGuq3GtLgpuTOdMA9OFCiURCWwVomWB/qCVIokfBtLW1VRMIEgWW+mRsQTmCSL/o2J/Wf6D/S7ku9ndtJLRl+Z6BWi9KKVYDeT7vH8l+AL3ZMVKAl3EUbIc5LkFaPs1WA/k5wT3GwnHlCsbks2TNGDJwu733OGTGN8i2MhBQ8h0qoaTjsta/rLlijmEYKIbF/DmwpaJ5gcEzbbPFgM8i0yxHIRma5xnYx0AW5l/SMpDNZhEIBHS1LhnRzvrW9P/T709BgCkxDPaiAMBFUG7GDxglW1ooGHMgjy+l9g70ulNisZg2SVEj5eZob29HRUWFoUhRR0eHHju5GcuNUhYjLnYZDU4BgBtDEiqlejNFzOt0pDVYAIa1293djUgkYjiWs7q6WkvyBAkFC9FUVFToOWGWBeNWuJ7pDpABtuUWyL4o6I8h9ndPqc/2F7NkfkZ/ik45Mdh+lFLADiQMj6RAyXf7fL4+SoUM4JNr2lyroJTp3sz8GQPAIDppKRuO6Z/0hTEJ8qwF6V6Q1WElzEV62Ee6BeVhXRwb0uShupWGxPyl1sioQ+k3MWuD8hqvm+8rBWk2Z8na4ZoxQ6EQwuEwIpGILmdJkzzNL3QFMFeTaUGMDZDBL/Trk5lTAmMKnWTw8ojMcqWYELRe1NbW6mh3SqDsZ3t7O9xut87RTyQSutqUy+XSPuVgMIhgMAiPx4O9e/fqDUOzNIPw5EKVubcjAal1cJPJdEzpvzdrXPvTjMrtXza32eFw6EA96Trh53v37kVFRYWO1WBAH6sqtrS06L8DgQDcbjdaWlpQLBZ1uiAPnZEpTxQ0LZRGf27IgTBL8339rXve/1nMQylh5EAY7F4dCeYvlTvWqudY0ywOQLtaSYeorVOLl2nT/CGNkkWaPB4PKisrMXXqVPzjH//QQkU53K8M9KMrjmBbg8GgoXyxtFiwn+SlHGtWhyV9t9lsunppNpvVAb5DscoMifmTGYRCIV2ARWpY+2P4cpGaNXz6KGWaEpl/NBpFZ2enNn0MdaKYSsXUKS4aSlcsiEP/C7VdCjlsEyvcxeNxQw19t9uN7u5unafNSeUZALQYyECT4S46uilYWlKp3lQ5Vofz+/3Yu3cvRo0ahU8//VQzPQo0W7du1T7m7u5uHWiye/duvVgZbFIsFrVPWtb8LzfjL0Vs5Doy+zv789/3Z7YdaU2MLhaa+AEYzln3eDzYvXs33G439uzZo+NKSDjef/99reHT95/JZLB7925dPYxWHgBob29HMBjULqZyRph/kSAZRCmFZX+MfH/PJA0kyJSkNabc2J/7tNT1gTyvPwvsSECpfe7JMWPG4LrrrsO6desM5W+VUoaaCRQAcrmcdn9RAKApnMIEc+Sj0aim4blcDpFIBIsXL8bOnTuRSCQMB+MMpx+Sb/AaBfFcLofW1lZN+5mGSMGAbuVMJmNg8jxhkWWAJb1jpp0sez+Y+R5SbX/6hevq6pBMJhEIBLTZmESPi0gOqHnTSRMOBQcSLvo5I5GIPqmOpvfhTBLPCmclPLvdrgtYMMeS0ZY8XYkaPLV+WgaYUkYhgovP7XYjHA5rRu/3+3V5xsrKSl3EhRM33I0lCVY4HNYLntW/uODoww+Hw4jFYvoEuOrqatTX1+v67fJULy5cRqlyQZKhlbOMrOyPtCTIRc2xKkW05f/9PdeMUibccoHPrK6uRiqV0gF/rJYG7Esn3bJlC8LhsK5KyLoFo0aN0mmWstAH2yuPi5UZDgwmsrAP5vml8iLdRoSkRaW0+/3tVSmYksDLILXhrrNS/TC7tEoJAf0JM/31p5TbtZTyVg6Q1o8aNQpf//rXcdJJJ+Ff//oXNm7ciD179qClpQXbtm2D0+nEEUccgd27d+t1zxoYzFAiDafCNW7cODQ3N8Pj8aC2thZHH300vvSlL+naGtFoVJfXJt8aDrhmKASQhkqzPM3+MttEujAYM0brpkx7lfSQAg4V5aG4Xm1qgDMpJx/oDc6QEZnSvGomxgcy8Zd6FzcPzTbMtR+seUviueeew6hRozBq1ChEo1EdYELNFoDW2Ki1kXkD0LnjZPKJREKnVdFnRaFABv9RwnW73Xjrrbfw17/+FW+99RY++eQT7Nmzx2AmGig4TswiqK+vx9SpU2Gz2bRmyB/201zJkPEJo0eP1sUmGDlOwYcWBDKuTCaj0x83bdqkg9CGmgq0PwK0P42mPx9ruTCU58m16/P5UFdXh+OPP17/z7XEbBEKf6xOSGJYLBZ19gXXXDwe1weA2Gw2HZvCH2ocH330kT7EaKjZDCPp3x0OhjInZpOumVCa6clQGZx5zEpZqSTKuU+G8ryhvLfUO4YzVlzvkUgEX/7yl/V6Z/oq16+sfMfzR4Dekwhlnj8tqhQOKOx5vV4Eg0HtQti9e7cuapZMJgddG988Ng7HvhM7q6qqtDXW7IJkf8i02VaZksjnSrdGKWsMeVBPT0/J6psHwqDN/tLkQGIjP9ufRCmlFvPzgL7SKH07pe4dKuirl+ZVvouSmvQjSe1cFp6gdElCTE2OVgNKoDLfm7mZ/ClXnexicV/d9b179+q2MiCPZjJZKEep3nMHuGkCgYAuQSnbJ0+Nkz98Dg8DKrfZv79nDUfw+yyh1L7AxNbWVmzcuFFby2S2B8dfCsbS5cXUIKWUIS9YHmEq54RCeGdn55BSf76oKMV09zc2Qx234TL3crzz8/iOYrGI7u5u/POf/9Q0k9ZjmvOpeEjmDsBQPU/WPKALjeCzWlpaDCXpKZiVIyWW+5TZPeaiT7K/5gwFs1YvwTZK9xHvla6Dwc7TsKL99ycFDmVzlfpuuRfeu+++qxk6KyjR3E8/CwC9AHt6enTQHDUynhHPWgCMH5BanxQa6BYgY+3o6NAmXnl64FDBRcBDHtgGs7muVLCh2XTY35xKSVRqkyN10MfnHdz8DMwBegO/+psTOV+8tz+hyrxHpOnamhMLnxeYlUmzAkkLl6Q/kjn2F+3P/UdIN6LUpvmMcgT98tmsBWN2W5ZqJ7+3P/cM7ykVODqcuLGROY7tEMbvf/97AEB9fb1OawN66z1Tc6dPsLu7W2vuQO/Rk6lUShdZYZAVvyvPBwBgYK4ejwdNTU3Ys2cPYrGY1uyGC+l64UIxW1XMm0tqnP2Z2Q8kxA1F4jxcwDmXubvmOZHayf5cHKWebUapGAkLFg51yPVqZu79WZEH8rk0pUuFpZSgUC5IoUP2SwoApZi9zJwq1SYp4Jvp9VCV5UH7/A81DHbifD4fJk2ahOrqah2BXygUNLM2DyRN3FKDZ5pcNBrVEfzSLOPz+dDZ2dknypcm9tbWVrS0tKCzs1MXfhiK5HkgH+Bw0d9CJQZimh/oew5FDIUoHKgvA+nrgQgenzNYQW0wOJzm5GDBmpO+18xrXyoo+3tPqc+HErsxnDkhU6ZbbqDvKNVnc4yd+R4p6EvBZiCWd/2MgTJ/CxYsWLBgwcIXA1YVEAsWLFiwYOEwg8X8LViwYMGChcMMFvO3YMGCBQsWDjNYzN+CBQsWLFg4zGAxfwsWLFiwYOEwg8X8LViwYMGChcMMFvO3YMGCBQsWDjNYzN+CBQsWLFg4zGAxfwsWLFiwYOEwg8X8LViwYMGChcMMFvO3YMGCBQsWDjNYzN+CBQsWLFg4zGAxfwsWLFiwYOEwg8X8LViwYMGChcMMFvO3YMGCBQsWDjNYzN+CBQsWLFg4zGAxfwsWLFiwYOEwg8X8LViwYMGChcMMFvO3YMGCBQsWDjNYzN+CBQsWLFg4zGAxfwsWLFiwYOEwg8X8LViwYMGChcMMFvO3YMGCBQsWDjNYzN/CIY1x48Zh2bJlB7zPZrPhjjvuGPH2HOpobGzEvHnzEIlEYLPZ8Mc//vFgN+mQxbJlyzBu3LiD3QwLFg4KLOY/Qti2bRtWrlyJY445Bn6/H36/H1OmTME111yDf/3rXwe7eWXF888/bzHeQwRLly7Fe++9hx//+Md4/PHHceKJJx7sJlkYYXz00Ue4/vrrccopp8Dr9cJms+GTTz452M2ycIjDppRSB7sRXzQ899xz+PrXvw6n04lLLrkE06ZNg91ux+bNm7F+/Xps374d27ZtQ0NDw8FualmwcuVKPPTQQxiJpTRu3DjMmTMHjz766H7vS6fTcDqdcDqdZW/D5wWpVAp+vx//8R//gbvuuutgN+eQRy6XQ7FYhMfjOdhNGRYeffRRXHnllZgyZQqcTifeffddbNu2zbJqWNgvDl9KOUJoamrCxRdfjIaGBvzP//wP6uvrDZ/fe++9WLNmDez2Q9fokkgkEAgEDnYzBgWv13uwm3DQ0draCgCIRqNle+bncS0cCOyTy+U62E0pC7761a+iq6sLoVAIP/vZz/Duu+8e7CZZ+Bzg0OVAn1Pcd999SCQSeOSRR/owfgBwOp347ne/iyOOOMJwffPmzbjoootQWVkJr9eLE088Ec8++6zhnkcffRQ2mw2vvvoqvve976GmpgaBQAAXXHCBJvwSf/rTn3DqqaciEAggFAph4cKFeP/99w33LFu2DMFgEE1NTViwYAFCoRAuueQSAMDLL7+Mr33tazjyyCPh8XhwxBFH4Prrr0cqlTJ8/6GHHgKwz+/OH6JYLOLnP/85jjvuOHi9XtTV1eGqq65CZ2enoR1KKdx1110YO3Ys/H4/zjjjjD5t3R/MPv877rgDNpsNH3/8Mb75zW8iEomgpqYGt956K5RS2LlzJ84//3yEw2GMGjUK999/v+F52WwWt912G2bMmIFIJIJAIIBTTz0VGzZs6PPu9vZ2XHrppQiHw4hGo1i6dCk2btwIm83Wx2IxkHnO5XL44Q9/iKOPPhperxdVVVWYPXs2XnzxxX77f8cdd2hL0k033QSbzWbQ/N555x2ce+65CIfDCAaDOPPMM/GPf/zD8Ayur7/97W/4zne+g9raWowdO3Z/w45MJoPbb78dEydO1Gvk+9//PjKZjL5n6dKl8Hq9+PDDDw3fnT9/PioqKrB7927D+//+97/jqquuQlVVFcLhMC677LI+6wUY/vou5fMf6HodN24czjvvPLzyyis46aST4PV6MX78ePzmN7/p086uri5cf/31GDduHDweD8aOHYvLLrsMbW1tgxrH/lBZWYlQKHTA+yxYMEBZKCtGjx6tJk6cOKjvbNq0SUUiETVlyhR17733qtWrV6vTTjtN2Ww2tX79en3fI488ogCoE044Qc2dO1etWrVK3XDDDcrhcKjFixcbnvmb3/xG2Ww2dc4556hVq1ape++9V40bN05Fo1G1bds2fd/SpUuVx+NREyZMUEuXLlVr165Vv/nNb5RSSl177bVqwYIF6u6771br1q1TV155pXI4HOqiiy7S33/ttdfU2WefrQCoxx9/XP8Q3/rWt5TT6VTLly9Xa9euVTfffLMKBAJq5syZKpvN6vt+8IMfKABqwYIFavXq1eqKK65Qo0ePVtXV1Wrp0qUHHEMA6vbbb9f/33777QqA+vKXv6yWLFmi1qxZoxYuXKgAqAceeEBNmjRJXX311WrNmjVq1qxZCoD629/+pr/f2tqq6uvr1fe+9z318MMPq/vuu09NmjRJuVwu9c477+j7CoWC+spXvqIcDodauXKlWr16tTr77LPVtGnTFAD1yCOPDHqeb7nlFmWz2dTy5cvVr371K3X//ferJUuWqJ/85Cf99n/jxo3qwQcfVADUkiVL1OOPP67+8Ic/6PcGAgFVX1+v7rzzTvWTn/xEHXXUUcrj8ah//OMf+hlcX1OmTFGnn366WrVq1X7fWSgU1Lx585Tf71fXXXedWrdunVq5cqVyOp3q/PPP1/d1dnaqsWPHqpkzZ6p8Pq+UUmrt2rV6zZjfP3XqVHXqqaeq//zP/1TXXHONstvt6rTTTlPFYlHfW471vXTpUtXQ0GDo00DXa0NDg5o0aZKqq6tTt9xyi1q9erWaPn26stlsatOmTfq+np4edfzxxyuHw6GWL1+uHn74YXXnnXeqmTNn6nU00HEcCH76058qAIYxsGChFCzmX0bEYjEFQC1atKjPZ52dnaq1tVX/JJNJ/dmZZ56ppk6dqtLptL5WLBbVKaecoo4++mh9jcTxrLPOMhDC66+/XjkcDtXV1aWU2kdwotGoWr58uaENe/fuVZFIxHB96dKlCoD693//9z5tlm0k7rnnHmWz2dT27dv1tWuuuUaVkiNffvllBUD97ne/M1z/85//bLje0tKi3G63WrhwoaFft9xyiwIwLOa/YsUKfS2fz6uxY8cqm81mYGqdnZ3K5/MZ3pPP51UmkzG8o7OzU9XV1akrrrhCX3v66acVAPXzn/9cXysUCmru3Ll9mP9A53natGlq4cKFB+yzGdu2bVMA1E9/+lPD9UWLFim3262ampr0td27d6tQKKROO+00fY3ra/bs2ZpJ7w+PP/64stvt6uWXXzZcJ2N/9dVX9bW//OUvCoC666671NatW1UwGOyzT/j+GTNmGBjtfffdpwCoZ555RilVvvVtZv4DXa9K7WP+ANTf//53fa2lpUV5PB51ww036Gu33XabAmAQ7giu9cGM44FgMX8LA4Vl9i8juru7AQDBYLDPZ3PmzEFNTY3+oam8o6MDL730EhYvXoyenh60tbWhra0N7e3tmD9/PhobG7Fr1y7Ds1asWGEwrZ966qkoFArYvn07AODFF19EV1cXlixZop/X1tYGh8OBk08+uaTp+uqrr+5zzefz6b8TiQTa2tpwyimnQCmFd95554Dj8eSTTyISieDss882tGPGjBkIBoO6HX/961+RzWZx7bXXGvp13XXXHfAdB8K3vvUt/bfD4cCJJ54IpRSuvPJKfT0ajWLSpEnYunWr4V632w1gnym4o6MD+XweJ554It5++21935///Ge4XC4sX75cX7Pb7bjmmmsM7RjMPEejUbz//vtobGwcdv8LhQJeeOEFLFq0COPHj9fX6+vr8Y1vfAOvvPKKXrfE8uXL4XA4DvjsJ598EsceeywmT55smN+5c+cCgGGdzZs3D1dddRV+9KMf4d/+7d/g9Xqxbt26ks9dsWKFwR9/9dVXw+l04vnnnwdQvvVdqj8DWa/ElClTcOqpp+r/a2pq+qyjp59+GtOmTcMFF1zQ531c64MZRwsWygUr4K+MoN8tHo/3+WzdunXo6elBc3MzvvnNb+rrW7ZsgVIKt956K2699daSz21pacGYMWP0/0ceeaTh84qKCgDQfkkyDRIPM8LhsOF/p9NZ0re7Y8cO3HbbbXj22Wf7+DxjsVjJZ0s0NjYiFouhtra25OctLS0AoIWWo48+2vB5TU2N7ttQYR6rSCQCr9eL6urqPtfb29sN1x577DHcf//92Lx5M3K5nL5+1FFH6b+3b9+O+vp6+P1+w3cnTpxo+H8w8/yjH/0I559/Po455hgcf/zxOOecc3DppZfiS1/60sA7/r9obW1FMpnEpEmT+nx27LHHolgsYufOnTjuuONK9m9/aGxsxIcffoiampp++yPxs5/9DM888wzeffddPPHEE/2uC/M6CAaDqK+v1+lr5VrfpfozkPVKmNcWsG8vyr3S1NSECy+88IDvHcw4WrBQDljMv4yIRCKor6/Hpk2b+nx28sknA0Cf/NtisQgAuPHGGzF//vySzzUzkv60MvW/qXZ85uOPP45Ro0b1uc+cDufxePpkHxQKBZx99tno6OjAzTffjMmTJyMQCGDXrl1YtmyZfsf+UCwWUVtbi9/97nclP++P2JUTpcbqQOMHAL/97W+xbNkyLFq0CDfddBNqa2vhcDhwzz33oKmpadDtGMw8n3baaWhqasIzzzyDF154Ab/+9a/x4IMPYu3atQZLxkhBWnz2h2KxiKlTp+KBBx4o+bk5qPWdd97RjOy9997DkiVLhtS+cqzv/p47mPU6kHU0EAx2HC1YKAcs5l9mLFy4EL/+9a/xz3/+EyeddNIB76cp1uVy4ayzzipLGyZMmAAAqK2tHfIz33vvPXz88cd47LHHcNlll+nrpSLOpane3I6//vWvmDVr1n4ZCqPUGxsbDabp1tbWklHenwWeeuopjB8/HuvXrzf07/bbbzfc19DQgA0bNiCZTBq0/y1bthjuG+w8V1ZW4vLLL8fll1+OeDyO0047DXfcccegmX9NTQ38fj8++uijPp9t3rwZdrt9yMxlwoQJ2LhxI84888x+1wCRSCRw+eWXY8qUKTjllFNw33334YILLsDMmTP73NvY2IgzzjhD/x+Px7Fnzx4sWLBAvxcY3vrurz8DWa+DfWYpZcB8z0DH0YKFcsHy+ZcZ3//+9+H3+3HFFVegubm5z+dmraC2thZz5szBunXrsGfPnj73l0rhOxDmz5+PcDiMu+++22CuHswzqdXI9iql8Itf/KLPvcwD7+rqMlxfvHgxCoUC7rzzzj7fyefz+v6zzjoLLpcLq1atMrzv5z//+QHbOVIo1f833ngDr7/+uuG++fPnI5fL4Ve/+pW+ViwWdUwHMZh5NrsfgsEgJk6cOKC0r1L9mDdvHp555hmD1am5uRlPPPEEZs+e3cdMPlAsXrwYu3btMvSdSKVSSCQS+v+bb74ZO3bswGOPPYYHHngA48aNw9KlS0v26Ze//KVh3T788MPI5/M499xzAZRnfffXn4Gs18HgwgsvxMaNG/GHP/yhz2dcW4MZRwsWygVL8y8zjj76aDzxxBNYsmQJJk2apCv8KaWwbds2PPHEE7Db7QYf5EMPPYTZs2dj6tSpWL58OcaPH4/m5ma8/vrr+PTTT7Fx48ZBtSEcDuPhhx/GpZdeiunTp+Piiy9GTU0NduzYgf/+7//GrFmzsHr16v0+Y/LkyZgwYQJuvPFG7Nq1C+FwGE8//XRJTXzGjBkAgO9+97uYP38+HA4HLr74Ypx++um46qqrcM899+Ddd9/FvHnz4HK50NjYiCeffBK/+MUvcNFFF6GmpgY33ngj7rnnHpx33nlYsGAB3nnnHfzpT3/q45v/rHDeeedh/fr1uOCCC7Bw4UJs27YNa9euxZQpUwwxHYsWLcJJJ52EG264AVu2bMHkyZPx7LPPoqOjA4DRKjLQeZ4yZQrmzJmDGTNmoLKyEm+99RaeeuoprFy5ckh9ueuuu/Diiy9i9uzZ+M53vgOn04l169Yhk8ngvvvuG/IYXXrppfj973+Pb3/729iwYQNmzZqFQqGAzZs34/e//z3+8pe/4MQTT8RLL72ENWvW4Pbbb8f06dMBAI888gjmzJmDW2+9tU8bstkszjzzTCxevBgfffQR1qxZg9mzZ+OrX/0qgPKs71IY6HodDG666SY89dRT+NrXvoYrrrgCM2bMQEdHB5599lmsXbsW06ZNG/A49odYLIZVq1YBAF599VUAwOrVqxGNRhGNRoe8bix8wXEwUgwOB2zZskVdffXVauLEicrr9Sqfz6cmT56svv3tb6t33323z/1NTU3qsssuU6NGjVIul0uNGTNGnXfeeeqpp57S9zAV6s033zR8d8OGDQqA2rBhQ5/r8+fPV5FIRHm9XjVhwgS1bNky9dZbb+l7li5dqgKBQMk+fPDBB+qss85SwWBQVVdXq+XLl6uNGzf2SWHL5/Pq2muvVTU1Ncpms/VJ+/vlL3+pZsyYoXw+nwqFQmrq1Knq+9//vtq9e7e+p1AoqB/+8Ieqvr5e+Xw+NWfOHLVp0ybV0NAwrFS/1tZWw3399ff0009Xxx13nP6/WCyqu+++WzU0NCiPx6NOOOEE9dxzz5XMDW9tbVXf+MY3VCgUUpFIRC1btky9+uqrCoD6r//6L8O9A5nnu+66S5100kkqGo3qdfPjH//YkP5WCv2l+iml1Ntvv63mz5+vgsGg8vv96owzzlCvvfaa4Z7+1tf+kM1m1b333quOO+445fF4VEVFhZoxY4b64Q9/qGKxmOru7lYNDQ1q+vTpKpfLGb57/fXXK7vdrl5//XXD+//2t7+pFStWqIqKChUMBtUll1yi2tvb+7x7uOu71FwqNbD12tDQUDId8/TTT1enn3664Vp7e7tauXKlGjNmjHK73Wrs2LFq6dKlqq2tbcDjuD9w3kv9lOqfBQtKKWXV9rdgYQTwxz/+ERdccAFeeeUVzJo162A353OBRx99FJdffjnefPNN60AiCxZGGJbP34KFYUKWOwb2ZUqsWrUK4XBYm7ktWLBg4VCC5fO3YGGYuPbaa5FKpfCVr3wFmUwG69evx2uvvYa77767bFHjFixYsFBOWMzfgoVhYu7cubj//vvx3HPPIZ1OY+LEiVi1apUVaGXBgoVDFpbP34IFCxYsWDjMYPn8LViwYMGChcMMFvO3YMGCBQsWDjMM2Od/qJadHKzX4hvf+AbOOOMMTJ48GaNHj0Y4HIZSCh6PB/l8HoFAAG63G0oppFIp5HI5FAoF2O12dHd3I5VKwel0IhAIIJfLIZ1Oo1gswm63w263o1AoIJvNIhQKoVgswuVywWazIR6Pw+v1IpPJ4M0338SGDRvwzjvvYMeOHUgkEkin04Pu+xdlTl5//XVMnDgRkUhEj30ul0Mmk4HH40GhUIBSCsViEdlsFtlsVs8DsC+6vlAo6L85Lna7HU6nU9d1DwQCsNlsuja8w+GAUgqFQgGvvPIKnn32Wbz66qvYsWMHMpnMgM4vMMNms8FmsyEcDuOEE07Aueeei/nz56O9vR2BQAAOhwPd3d3o7OxEMplEOp2Gx+OB2+1GOp2G0+lEdXU1EokEqqqq9OmCSikkEgm0traisrISVVVVCIVCcLlcerxcLheOOuoovPrqqygWiygWi9i9ezfeeOONkpUZD9SPQxFD8VJ+UfryRekH8MXpy+e5H4ddwF86nUZnZye6uroQCoXgdDpRKBSQTCbh8XiQTCbhcrlgt9t1Jbd0Og2Xy4VUKoVMJgObzYZMJoN8Pq+fm8/noZSCz+dDoVBAsVhEMpmEz+eDx+OBUgr5fB75fF6XNCVTOtzDLnK5HHp6euB0OpFOp5HL5ZDL5ZDP5zVTp6CVz+dRLBY1k5X3FotFOJ1OLYw5HA44HA4tmHV0dMDlculrFB7IKO12O2w2G5RSw97UZMjZbBYejwfHHnss0uk0YrEY/H4/QqEQgsEgdu7cCZfLhUwmo9cF10M8Hoff70dbWxvsdjui0SjGjx+PYDCIiooKJBIJ2O12+Hw+2Gw2dHZ2Yvv27brvqVQKyWRyQIfaWPh8geu/v3U6kDVspjtc+/29jwK4hS8GDjvmb7fbkc1mkclkkM1mkcvlNHFMp9NwOBxIJpPIZrPI5/MIh8Pw+/2a4TidTm0lcDqdmnA7HA6Dxsma43xOoVBALpeDUgrpdBrZbFYLCYc782fddKUUnE4n8vk8crkcbDabtohwzgAYtHxq7tlsVhM8WlzkqWtOp1P/UJv2er1aaOvs7EQ8HtcC3XDnxGazwefzobKyEl6vF9lsFjabTR8pTC0+k8mgtrYWmUwGra2tyOfz8Hq92hq1e/du2O12bbXwer1ayHG5XHC73XA6nchms/D7/Vr4icfj6OrqQmdnp0FItfD5hd1uh9vtRkVFBcaMGYMJEybg6KOPhtPp1FYyl8sFoFdYJs2icEz6RyZOyyStZy6XCx6PR1s0KUAD0JY3u92OTz/9FC+//DJ279590MbDwvAwosx/KNrTSDNCu90OpZRmGjT1u1wupNNpraGTWLtcLiSTSc1YyFSKxSLcbrcWHLjJuMEoLORyOcPf/C432+HO+AForTeZTMLtdmsiw8/4P5lYsVjUVhSOv3QNcN2RsdMdQ0FLWhR4P03wpQ6KGQqKxSJyuRwSiYRmwPl8Xr+ro6MD7e3t2jKQzWbR3t6OTCaDVCoFu92OdDqNtrY2OBwO3a7u7m74/X5kMhkUCgW43W643W4UCgX4fD49Hvl8Hul0Gul0uk8RIgufT5D+VFVV4eijj8bJJ5+M6dOnw+fzIZfLIRgMajdQKpVCd3c3vF6vgeHTuiYFY6mAeL1eg7AgwTUdDAbR2tqK6upq/Pa3v/1Mx+DzAMn3+DfHtz/LIumU5Afm75jfwWtD5SFDYv42mw0OhwNer9dgfqJ5FejVtCRzZEN5L82tbDz/J3GXBJ0MoByashx8/k3tjMyaptNCoYDu7m44nU79HUrIbBP9zEopLYGT0JPoO51OLXDIPh0MDEQo+yyFklQqpWMklFLaF08CRBeLFJgoFNDiIq0BJF7sA5kr1y3vowBHgsnnl2NeCoUCurq6sHPnTuzatQvZbBbJZBKZTAaxWAxdXV1IJpN6feTzeSQSCWSzWTgcDgSDQe16yuVyiMViOlagrq5Om/rdbjc8Hg8cDgei0ai2lnB95XI5dHd3D7s/XxRwX7vdbk23uCYkLeO64l7hGpOuOkm3gF4BVH4mY1XKsbZIdyORCCoqKhAMBhEIBGC32xEKheBwOLT1yG63IxwOa2UGgLZU+v1+bYVkv+x2u7YEmC0I7Hcul0NNTQ3Gjx+PcDiMDRs2DKs/+4OZTu3PzUGUYp6fJS2T7kSgbx/kOLNdZPqSJ0reSGumdLtI5i9p3WAwaObPhofDYUyYMAFOp1NLi4FAQC/EcDiMiooKeL1ebToiM3U4HPD5fJoY0hxOQtfV1YWuri50d3drTSidTmPXrl1IJBJD7qzu9P9ODieKvv2Wlha9aeiz3bVrl2YS0n9MU3M8HkckEtFBfalUCsViUUvXFIAKhQI8Hg+6uro0keBiLufiPNCGoeAlwf+5sKQGbSZkRDnbXCgUkEgkEAgEtJDFMUokEprRFwoF7a7h/2ZI1wtBIYLxARwDuflI8KVGNFRQkGDQYi6Xw86dO2Gz2ZDNZtHd3a2DR91uN3bt2qUJNMd+586d8Hg8mlkxXmDPnj1IJpMYPXo0isWiDhbMZDKIx+MIhUJobW1Fd3c3Ojo6sGfPniEdRftFA+fX4/EgHA6joaEBTqcTPp9Przua1b1eL/x+v3apcE0w9gfYZ5HiHo7H41BKoaenRzN5xqHk83kkk0ns2rULXV1dmtkOFWQQ8XhcW47I7FOplF7bhUJBxyjRtUn61dPTg3A4jO7ubt1H7pF4PI5gMGgQAHp6eqCUgtvt1u91Op3Yu3cvxowZM/zJEX2Twhb7IgWyUoKaFLikUkVhS9I1/pZ0rZxwOBwIh8N6ngBoFx2vkTeybT6fTwubVHSSySTi8bi22pAG8HO232azaZ44WAzZ7M+BdrlciEaj8Hq9CAQC2l8ZCARQXV2tg904CDRVZrNZ+Hw+RCIRbVqvq6vTPiRqYVyYTqcTbrd72CZMKVHxb7/frzdwIpEwBOeRgadSKS0VK6XgcrnQ0dGhtTMyJrfbbfBXezwe/f3Ozk74/X5DYFk5gstKway1mP82aznmDcTPOFZmAcBszhoOOJ40V9LnT2GKBJXBkub5ISPPZDLawiJdMhTyKNCRgPD71MClpD1c0GLU2tqKQqGAyspKfPTRR0gkElqYzWQymqEopZDNZpFOp5FMJvVzuE+o3TscDiQSCXR1daGystJAuJPJpP4uBejOzs6yuTI+z5AWR5fLhVAohEAgAI/HA7/fr915Ho9Hx1cwE4jMetSoUXru/H6/duF5vV643W50dnbq2JR0Oq0tLh6PR7cB2H9g3YEg6Re1xUwmoxmL1BSpcFAQSaVSmn4yEFRaVSkI8NhuxhBQcKabjUJsMpmE3+8f1rwQkkZRweJ8SSXKHMRLSKudpO+05EqLK983UhYBtpNjQ9ccBXyzBahQKMDr9er/ud95jRlnMqvJTKeHgiEzfyklB4NBvYmkCSoSiWgtm+ajiooKHcBEYsxALrfbDb/fjy1btmgJWZo2ymHypxmZxJfaVjKZNEwIibH0KfOHBDuTycDlchkWHhmpdImwvz09PX1SA8vN+CWTB3o3Et9FzVpK1VxI0qTJsZb9lgJCuTcOpV2OJ9Msc7mctqbwOu/nfNG/7fV6NfNzuVza9cS2ksC53W4A0OZMEtBSfrehguusubkZr7zyik4VzefzOtuEYx6Px7W1QxIv/t/V1aUDsWjmT6fTaGlp0UKOy+VCc3MzkskkamtrDW2wfP694Lon7XK5XPB6vfqHWhhdA5JBAtBuIgqoSimEQiGDtZC0hGuN7yvX2qLQQUGDgZ+kV1RiqJwx7kMGzTLWiQJBPp9HdXW1tmCQWfFeqXVT2AGAXbt2Dbs/hFRGyEC5jyn8ejwefQ+VSQo8VAi4dyjw0PJhZpwjBbaF2j6tS+l0GpFIBDU1Nfoz9pF0oKqqSluOstmsdgVyDVLYl7E8n6nPX3/5fxk7GZ2Mpq6oqNCpSpRkgsGg3gT0jYdCIUSjUR3wlc/nEQwGtYTN95QrYpmmVADazwpA5+0zMC+ZTOpccmrwJKSZTAbRaBRdXV1aSwCgg7no8+fm42KgKU0GogHl90lJjVdKyZSezQKAZPzsC+MupLncbEYrV9vNpn5aUbiBGYvBTcE28f1sH9tNQYFjzWvS1yYJBjUZPrtcoEDT3d2NYrGI7u5ubRHguqMwScIlTZb03zIOgvvL6/XC4/HotexyuQxWNwpLyWQSiURCv8tCb2AuGTOZfzQa1YyfhzFREFVK6TVKC6DUJgHobAsZF0CBT+43syttsKCFi8qL0+nUqbKyxkUqldLCsHRHUHune1Xulx07dmiTtVyLFIw5ZtLqEI1GhzkjveDccE1T2GUMjGT+FAA43hxXqYglk0mdCUH3BwD9nZE0/YdCIR1XQguKy+XC6NGjkU6ndZA5hdBCoYDa2lrN4FlvprW1FZ2dnXos6MZjkK/dbjdYCgeDYQX8cYKkhCYDATkZDEziRJIp2u12bTGgMJDNZhGJRLSUKv2mwzFxECSkNI2RqTgcDmSzWZ02RasApWluHt7Ljc9AMmpkUuqTAYLsA90gIxWMIpm6FMak5s9rMg7D7FOTgWisbUDTH9tdzrabfXX0bfE3JWEya6YxUUiRjFu6dHw+n24zmaMM9pNEQGoEw+0bXRPMIEilUojH41qap2WLbZdCCtsomT/nzuVyIZvN6nRBGe0fj8fh8/m0FhiLxYZcQOqLBu5FavT099O/7/f7NYPx+XyG9cB7KVCShlCbzOVymm5IaxSLUQHQ9M5smRss5LqUpmvSJ6A3ej+fzyMWi2mlijSLa4ixNNLFRwYr4wRocYtEIigWi7pPpMnlgDTxu1wu+Hw+rTRS4KUWLYU3Wgu5R7h3mDmUSqWQSCT6xD1JE3o5YbfbtTWcqbeBQEAH8NIVwH6R/zGtnPFzNPtXVVUhm83qNGBJK+iu/kzN/mQUbrcbwWBQBx5RI/H7/QZizM3j8XgM1+jLJ0N0u93o7u7WDJQMOJFI6OCH4YKbhUyDjIBBLVLT5WBzs1AipbRNhkiGSYKQSqUQCAT0exgcaI7aLIcbQ8LsIyOzkMEmbD+lTpfLpftitoqQeZnNleaMhXIwShnAJ4P7pBBGQYDMn/fKTABzfAMFMjnufIaMsuUclnM+OH7Uvnt6egzCLK0NMh1UCidmq4U5JoH7hPfm83lEo1FtWaOb6WDn+fdHnEbK57q/dkilxev1IhQKwe/365glamtSu/X5fAgGg8hkMgiFQpqx0OxMLZvxQtxnbrdbWxSpJA0H0h3H/nBuKUhKzZepopLOAb11SKgxkpkyeFEK+bKuiVkBKzfzJ12itZjWLKmsyM98Pp92UUhfPjNt0ul0n/mU7R9u4Hgp0EoRDAYRCoUQDocRDAa1VYkKDHlnOBxGIBBAe3s7PB4PqqurtVIi65EAvVZCrjmllKbPQ4lhGJbPnxIaAL2RGETDaEUWyQmHw/B4POjo6EBVVRVisZh+hsx9j0ajWlvp6elBa2urwcQ5XNCXRcZC5igDYEiM+UOzmrR0ADAIBKwRQNMfrQvMtWYAEaVmbtZyQmr2tLKQSMmIdkrN/IyEioFJQK85nRtPaqBse7k2DrULBnhK8ygFJwoBZKhsnyRqkjCy3ayySFMmBU4ZEc01XE5fIIlNJpPBnj17UCzui6SWz6ffVhZgocYmCbt8HtBLvNknFpli5grv45iORMBffwGfZmawvzVSzqDRgYDryul0IhgMaobPdDky+c7OThQKBYRCIW0dIPEOhULo6uoymKBpcmewryTOLpcL8Xhc043hMksZs0QXJNcLaRX9+BQ4uY64/7u7u7XVkpYO7utsNqstIIyHCofDcDgc6OnpQTAYNATfhUKhckyNFtQZN+bxeODz+XQVVqA3JkzyGc6PtNjlcjkEAgE0NzcjEAgYhGZp5RiJeCuOSU1NDbxeL0aNGqXjI2gR37lzJ7xeLyZMmKCzJWKxmKa/XHekGZlMBkceeaR2IxaLRV0nhAHkQ8GgmT8HUaaH1dTUaC2SUk9VVRUqKysBAJFIBIFAALFYDDbbvpz60aNH60VKyZjR89SKaDKVi3e4E0bLglnoIKOXggF95V1dXQZfOTc4TfuMBeDmDgQC6Ozs1N+hwEHhhgEzfF45hBqCRImbmpIzzdz8n7+lyZ+RzvTrUaqm+YqR6tLHVA4hIJlMagIjCRhNjAysAnoZGgsvEdR2pSmfZthcLqejsxkYKKXpUkyoHISB1gtGftP/KAN4uNYJs/tBtkcSMfqhZdQz+ycDVfP5PHp6eobdF9mOwYxTf5/L53xWQgDXOZk+zcUUFCkojR07FrlcTpuaqeSQiI8ePdrALPnsUCiETCaDSCSCUCiEXbt26b1YTqslBeCenh50dXUZ9jHjPADoolHm1ENqnna7HYlEArFYzKBdszgQLbnc97KmBoWBTZs2DbtfpIGkTz6fDxUVFZrJMzCTVgFaksPhsF7bFATo6wf28Z1EIgGfz4fOzk7NX2SJ9nKb/slb2JdisYhoNKp5YSgUQlVVFYB92SNMmYxEIvB4PJgzZ47OPslms9i0aZNWPrkW+cPzQD5Tsz9B00Uul9OBH0xvoZlfpovYbDZUVVVh7969qK6u1qkzHR0dmtkCvXnSdrsdNTU1SCQSOq1puKCJnzmxrDdgt9sRi8UM0aPUvqjBcXNwo8jAPrlxGOgoI2ZltHcqlTIEC5VL22QMhcxV5vhTw6fgITcbmQrNn9QoGZAZi8UAQPedC5NBR8MFTeGUYjneMu2PBCyZTBqyD+TYsV0cCxJ0ANoMymvZbFZvIACGOS9XPIO0GsksBQqbFCRlvIN8t9zUMkaEBFhmcjAwlT5GjiutJOXAcP3V5u8dSJAYCWGAY8VUZKWUXuc8KIkpfmR+pF+JREIL7IwfoRAqGTPfw/XMeg7lcC1xrTCegIy7ublZrwHGhLCYlIylkXEJZOa0FgLQ8SOkffF4XAsXPp/PUGiNharKAafTiUgkok3hZJLRaNRgEWBAIgUAuWcdDoeud0GXDc3+tHzK7BoqguVcZ3QTpdNp+Hw+1NXVIRAIGGqV0E3BWh7MFkmlUvjoo49wwgknaH5RUVGBcePG4e9//7sOCOQzCoUCwuEwdu7cObQxH8qXONCsMsXFz8UUi8UMhQsoObLR4XAYW7duRXV1tb4vHo9r87KM7qam1tXVZShuMFzQ7MvcaJqyuehJlKV/mAufJnJpUiVTB6BjGKRWyWdw8mTASbnMTzLYhJva5/NpSdLtdqOystIQ2EdNiClxnEcGMJFRkRFLE7sMahwO+AyOhyx2w2vUoOXYyfbI9CdqCvKZZJKUlDkfFDxkDINs03DANUC/vtlVIf37pb5bqg3S9E9XgdQqbTabHj/2vVzajVlDL8Ws5T370/rlPaWC2MpNlAmn06ndkE6nExUVFbo4GQVBCsncNzS1M5aJYJaFTBWVrhzGCcgCYeUw+9M6SeGbViXWxZD1Hiic0OIE9M6fOV++UCggGAxqusjP3W63dp1J8zR96sMFLTK0GEejUe0vr6io0MJAJBLR7ZBuYlbAZByH1+tFLpeDz+fD7t27dUwGA+s4huW0uBKSL8bjcezatQsNDQ2oq6vTtRFkVg6DMWtqalBXVwePx4MdO3bo6o2sElpZWYm33npL1w0h4+eZKEPZK0My+8sfauyJREKbwrkZgF5JlRJ0R0eHLqVbLBb7+HRYrYiakUyb6Y9QDgbUvOiLp5ZLH50MYpP+WKb7kbhSQJHBdDIti+2k5MnFZvbzl5PI0W9G31IgENCnx1HoGj16tB4HoHdcZV48zclk/qwTTjMZx4fS9XBBbZ/aPBm7zLCQgZM0lUsrjYyylhkJ0iTOZ5gDlWj+lYy/XHMi+yMFFzmGZv+jWcs3M1WilJVCWs/KGcMgcSCmXuqeUt8ZyHPKDTIamk5p/eMeUUppYYAWPu6rrq4uTbu47/P5vDY3y+prpGmyeJA5nmUooABJy1t3dzeSyaSOL6LZn75hCu0y2p9xJbLSqYzrYYYDlQRZtZBZD0opbSktBxwOhw5+C4VC+thqFoGrqqrC2LFjDXuD40wFjW2m6Z/9l5UOARiyuMoNu92OSCSCaDSq3SOJRAItLS26XgLdsVwTtJ6nUimd8UZrEfkPFTmeLgtAW3k/U7M/FyD9KUxfoPmb0iIZkcPh0D40ltBlMFZPT49eUGT+jFKW1bIkwRwO5CEylG4pxJgJLSEtDmQgbJ+scCU1Z5qm+DcJvOwDCUs5NX+6W9xut5aeGUBSUVGByspKvcDIJGOxmJaYqcnIYLFoNIpYLGaolgWUN9qXVhKpDctYDDn2ci3wd6mUPW62UvMniZ/sUzkZj2yHORLbzJTlujb/XYpZcD2ZfefSGsL7yulWOtD+M7dVulP2h1JCzUiBSgVdXKRVtNjxb8lQpLuFmjf3CYUJrkVpOZP1BEoJeIMFGTeZfzweN1jEEomEFtTZTnMAs9wb3DuyGBavUUBin/keMlEWoCkHnE6nplfU+On3dzqdiEajOpNF7mW6bGVAs7Sysowxze7APmsIA2bLCa4Rul8oPJFXFItFXeyNsXF2+76CeFu3btUKMkv/tra2or29HePHj0dbWxsAY8Anhc+hrqUhMX+atrq6ugzSB4MoWI/d5XLpakY0Q7W2thqqaMliDuFwGB0dHWhpaUFPT4+uIx2Px3UJ3XIwf5pbEomEboeUHqXJnpIktWlqnolEAi6XS0f+sv/c4EyBZCqgjJDl5hquD1WCbaVUSabPn0AgoPN06aphISVG+NrtvZUXE4mENu9FIhFEIhFDmUlKo+VilrJID/+m0Aj0Bvpxw1Lil9q0NAdKawJNnjKbgSDBl0Gl8vdwIN9vZvz9Mfv+niMhNX4ZeEvhUjJ7af4fDkhQpYDF6/Jd/Y2bWQjg71JCjPm55QL7wDGTgrL0x1Ozpi+W9M7lcmH37t1acWHgLAOWpYuJsSVMTytHvBLHh3uEigwZM+MSeG4EfeB0Y0pXJsdBMiwp3JHm0arB4kZKKQPjKcfa4njRp19ZWamLLvEQI2ZRVVZWaqskFTibzaatNlS2/H6/ttaywBznNhAI6EyHclteldoXB9La2opIJKJjbhhrRa1+zJgxOjZHKYWOjg7U1NSgo6MDFRUVSKfT2LlzJ9rb23HSSSdhy5YtaG5uRltbmy4S5nA4EIvFhizcD5n5c0Ext7W6uloHZNH8xAFnYAajTIvFos7bZyRtdXW19m90dXVpC4B8noz6Hiq4ceLxuPbzyc1Lcz9jFKghyiIzfE4sFjMwdhIs+qW48fj9fD6vDwGSm6+cIEFisB+DZaqrqxEKhQx1yamVsORye3u7foZMEWxubgbQ6+NkbYByMX+uFc6vFLqoaZBhUtIlwQOMDI7fYTsJzo+ZWaVSqbLVJy8FrjepdQ3VR0dIJkvmSUGABFkKo+VeY2bzfn/v6M/035/PX85PfxaP4UC69WQAGAVyMkUG0tFdyb1K37c0f9NyyYJK3d3d+tnU0KRAWmodDrYPpEukST09PTo9mnSGQr3NZtOZM9I1mc/n9f6QVkrJSGixoo+adIx7kllQ5QBdI2SSzOdnrBLHjKcR2mw2HZyZSCQMSmWxWEQkEjFYK3i/jL8YCc0/n8+ju7sb4XBY0zMKgaNHj0YikUBzc7P21ScSCeRyOVRUVGiFuampSc9xRUUF3nnnHbz66qs6fT6Xy2HMmDHYu3evju8ZCoZs9qcm09bWhmAwiGw2q/1kAPRmYI4rFz1TrJiiQZPbjh07dHQpzTRkwjITYLjggpD+OZbBVEoZ0vIAaPMdYDxyWJq8panV7XYjFotBKaWZJRckhSBaF2SMwHDB59Jf6fP5MHbsWB1AE4lEoJRCMBhEW1ubFlAKhX2HSsTjcW1WY3GSjo4OvcGj0aiuqMVyk9LMNhwizXgDEieOL4mxLEQkhSav16uL2EiNhcycBIuRsUDvkb8SZg2a41kulPLzDxfmZ5hdHuWGNKVK5sl3mxmH/F4pBi+Zu3lv87kjkYYl/6bfl77WUCiky3hns1ns3r1bB/+RtnHf0t+dz+f1SZ0dHR0G/zjnm4qOtJwMB7Qm9fT0oKOjQ7vkmN1B+saYJACGynAURGj6lm4vWkKlNk0BgNUC5TPLEe0vlUD6tqPRqKZd0WgUxeK+8thbt27VlkwKI8w6kyfExmIxfZ6BrEdDYT+RSJQlANMMjlcymURLS4vOWigWi9i2bRu2bduGmpoafSYCT98MBoMYO3Zsn8I+27ZtQyKRQEdHh67tQHcPXbJD5R/DYv6pVEovIi4gmvhZT5qBDfQp0xTF57CzQC9jZi10mjFlZPdwN450NdDkVyj0nn5F7Z/SMDcZfXpsF9M3ZHAiAMTjcZ3TKatLyZQ6MlcKA+Ui1mwDfZm0VNAXyLFmugxjBOS5Clx01Fj4XFps6MYIBAKGbIbhgBYEMmUyfQol0gfJv9k3EisyV86b1Owk0ZWMhtfpwpABXuWC1DbLxfhLvUO6AkbCfM6xlO/js6UFy6y5y++bXWPSxyy/258roBwgcSYDpfuIigbHj/56SRMA6AA7fodCPYVompOpZcojqffnFhlM+2UcCcdJ1ieRrjIZpEs6yvmiUiU1YcZt8fvAvnmhD1umqnZ2dpaFdkklioITx4xWYlpcI5GIQXDxer3YuXOnjk0g3eLR2R6PR5/RQteBFMbKzfypPNHFQIGMFQe5Hig8MjvA7Xbj7bff1iV++bu5uVmnw9PNTusTM+E+c82fEq8k2KyhTLM6Td/Uvpj7brfbDcwFgEEzoytBEoNyFJMxv4v9oGZPQYDtYnAFQeYjTW5SUOCmIfOVFgL6r6QJuBzEgCBxZnCRPAGOY866BKNHj9YRr3QLsC9cuDR51tTUwOPxGA4Hkb7Ocmj+9L2SyMqiRDKbgmMpKxhKpi/HkkRNRi1zjGReM8eKDKccVhgzyiG0HghmM/lIvE8KRmbGzt+lTP1mrX9/AgDfY35HuUDFhSl4oVCoj+86Ho/raHEqKGTqpA1S6KRJmf5ds3WwVKzEcMBnUxNk2Wia/Wlp4h6XFiEKAVQ6+BnXPgVr9lVGm9OtRDpYDq1frp1isaizI6R7Q8b5UOkAoJVJ0g4ekMPMs1AopIUcoNf6wXK7IxHtn8/n0dHRoU/xI69gECDjJzjOALRAQmu52+1GS0uLoXw0LZq5XE5XoOSzhmohG3IUSqFQ0JGWQG/OJxcItTKaiJxOp05fsNl6i5RwgTGIhFKb3GTl1Pxl0RhZU4CSIDcGN6y5OhcJlwxQkwuYEbJmDTKfz+vgMrmpykngmLNPM6W0uEg3hmSG3DShUEj/Tymbi4/9oQlU+tzLsYHk+LFtJAAMkuH7KSCQYcuAPz6Dc8mCRKxPzvUp38PPzUypXJDr9bMWAMr1To4pT0ksFTshtXXzu7lGSu0js9VCzgOZZ7n9/tQsGQAqmSLpg1zfpBMs3iLpENspo/25RrmPZMrwcPvCcaKWy9x+MnrSXtJR83ulW4jjLeNGuO+k9YwCP12gZFqSTg8HUskjQ5duOCmccWylNVPWUOBelvMh1yTvLUWjywG2jWb6YrE3TZy1IFj+XsY0yRgnmXJJBZp8VGa/MWvrM9X82UkWTJGmU5kWI01KNptNR8gyPkCaeyhFyjxtPoP/l8MHSFMM3yMXlgzOAnor5sl6/AC0+UuWV+Skc/GZFxkZGJ9Tbm2Q75QBM/I4ZZr/AoGAwYrCFEfe19PToxcdCRglTxnDQGm6HAyTQZEy+piaFJm/3NB0T1CilvMm15xk7gzWIqHj55yTkSAExEiZ+/t7V7nBtcW1Ld1BpZhJf8zc/Eyz20AK27QOltPvL7VfVmCjeZ+pc5JJSiYuDxkjuBZ5kBfv5zuAXlcm12c51hjbls1mDSdFkpHIdpOhmC0skjHKNnEP8bcUANgfaYkrZyYJYKxTQUbIH7vdrtOzGVjHfUwXDdcQgzHl2NNK0NbWZgiKLSdIp1paWrTWzjgyaWUmvwSgq80yuwSAIU2T7gHSXPJEaW0eCobM/ClZSr+vTNECoDVOs6+QPjVekwtJTorUKPjO4YIbQpp5uUFo7iPToEmfZiXpI+ZRsWQsQG8wGQmlGRQUpC++XJoZNxDbms/nDXX6yQRZ0ISEjq6OaDSqg2OYrkkTVDweN6RDUcCjNDrcPjAgRxIqCgOUijlPDLpinzmX5k3AqoUUwOhCkOcpyHGTZy2UG58V4x8pmAV5oDeIEYDhOu+XAg/HutQ4cA/yfs4ZPys3yFSoBHR2duqMImr3XCtAr2XP6XTq0uU9PT1a6Ewmk4bTGSWTZSS++f3lAGmmTPkz16rnPXyv+QfoK7yT0dMaKuNgyLyk9aGcbksAaGtrg8vl0kHTuVxOl11myiQZrM1m0yWte3p6dBp3PB7XrhDyKL6DSqvZ7VwuFAoFHRfC5/N9TDmUdVXIyKnhsz+MQeH3GZwq3WXd3d36nIChYFjMnxHy5o1PYiqr/PEzaWJiJ0jMqeGbF6kUBoYLSus0WZGZcGNzocvStowklWYaMr9wOAybzaaD/1hfnvm9nETWCeDphiNF4KSPrL29HblcDlVVVaiqqoLX60VdXR1yuZzOp1VK6YhhpgdS02dQo8fjMZwiJmvuk/APZyPJbAlaIBhMxDMVmF1AgUUGmsq2mIupyMOKyMDIcNhfRnnLeg3lxGfJ/EfqXSS4MmWNAhfdZQC0W8AcCyIZPLUzQt5LeiIFtHL0ycz0HA6H1rhsNpuuLMpCKywby5gTusc6Ojr0ONhsNgSDQR2BzefRikChgVp5OQI/+V3SokQigfb29j4ZJUBv2qt5b0rLnrSEce6ktk/BmvfRClduf7kM1qOGL5XC0aNHa5cx97rP50N3d7duE2Assw70ZiSQsTL7jPNabhQK+44TloGWXAfsIwOZZTZGMpnU64dQSulgR6WUVqZl+qJ00w4WwzL7S3M50Dd4Q14jSvkkpe9JXiPKlSLDZ9Hsx1oCDMDgYJK4AUA0GtWMXzIPpZQhGNDv96Oqqkq7L3if1+vVJh8ZqCbNcuXqF4PXeFYBa5OzX5WVlaipqUEwGNSVwdiW5uZmzViZutnV1QWbzaZT5yh92u12XTNAamrDabtk3LLuAt9Dt4P009L0Lwkc15E8wAiAjoEAeg8okrUOGKtRzrVGfJ41fzJyWk+oTUkmwXGj+dxsUpZ+VzkW0m0mYz24R5niWS4NjdZKFoeR65a1+xnX0N3drdvHuJdcLqfz/5n9IgOu6NOVMUrSKlBOFwYAnRotzf1m5g/0dZdKM74cG2mZpRAmXXGkg9xj5e4Ttebm5mZUV1frMef+577lNa615uZmHflPyyGLuNHKSoFM+to5FuVEsVjURXikxZsMmnyAbiTOBRUtoJdHca3yGl1OnF+ZwjwUDKvslJmoSVOS3PCDeZb5NwCDUDBcUJvkkZg099LEBPTmnTOPnNonTXnc5CR8ZCT0zUizovQrM0BDltwsF6ORJi2bzabTDaU5kH4jeehST0+PPt2Km4Sbij53FqIAehcmMzvKkS5DrYVMRJrkzW4jKbFL/x6JlZwXGXfB5/I6GT/fxb9HwhRYLu31YECa/JkWx2BLggSNFi3OB8dYxpjIgCbuG3Pdez6Lx5iWa/yky7GjowOhUEgzAgo2DFRmvAyD6ex2Ozo6OrR1j4SYe4Fj1NPTo/tHV6JMpZXtGA4k3WC7Oe6ShpYSuvr7Xwps7Bv3Fds+EvuDz6UyIusHUAjkcfC0dlAj7ujo0O5WCmKMgeAzGRRJ5i8Fh5EA6QhpKsc6n8/rIkVAX6u3jLfg+uFzzO4bugmYmj0UlJX5mz8bDvM3o1wSGk1vZMI0dTENTm5QCgqyjVJCNvtgSNhk4A8ZiyxHS4IyEmAgovTLU+iIxWIGhpfL5bQJn4VOJLHlonQ4HDptRfaxXMILNW+Z4sX4BJl2JP37sm0cZ/ZJMisZ2CePNmYaJIMk5b0j4Wv+vILjSiYtA744VtK0Kc35vEYNh3NGjZEmT3moFNeTzM4oF7gnmQNODZ4CDeuTeL1eJBIJnVpFOkH/vYw7AXoDtkgvpDuKed3SIlKOfrAv8jRBs2sDMKaZmjV7oPThUOZ38T7zvYOl8fvrDxUmVrGTJm0yUJZlp8WFcUnmwEQyf36HPnf5N62jckzKAc4F0Mtr2D6uCbPVgZYBCtFAr5As3eRcY7Ktw6FXwy84/b8oJWUOZHEcaNEB5dWc5MRI1wUJv0yV4b1kMFz4MjJdmpuphUozNJmQjAUopwZgBomo1NRpsmNlPy4yRpTyc2pgFIhIuGWevzTDms3tQ+0LCy5x/HiNJlhZJpMWDPaNIHFiehbHgZuOAhi1SgbcSI1V+vzLKQB8lpp/Oa0XHAdaTEKhkF6/0ufPvjEIjpCESwaHkvnTLQb0CoAUEKRAWI7x4zPIHGTAK03YnPNgMGhYFzIlWNIFaZ0iQwJgMMOzLLk0kZdLAGBfSjF9s3Zpvj7Q//f3jHLtE9JRMnlq+RTUZDpjV1eXLqpEf7900xYKBcNxxzJOiSWQea1cwpgZdIHJGAruFdJ+WQCO7eC+Yt+ltUXuAan9H5Ro/1IYzkCW04pwIHCQaQKU5WOlBYD3MTCD7aBvyWazaeYotUtZfQnolQBZ5IhM9kD9Hiwcjn1nYsv+0GTPg3tolqSAwPRL1tFmeynk0G0gfZfSZ1gOs6wUlKSUWygUEIlEtMmU0rCM/Oemlz5BAAZLAok8AF06k8KF3+/XzxopjX8k4gj6A+e1XO+iUOv1elFZWYlIJIJ4PK4DmGhylmVwyVxlLA1jXwDoA014pgO1I5/PZ/hMZpiUCzTzU0iUawPozcmnG0CWniajMdchIR2RKcTcQ3QtSvNvuYRBsyVSaob9rbf+NN3+3ANS25cZHuUUkKVFRlbkkwyR1gBaMlk0h8XkZLYQBQBW1ZMlj5mBIddVuWkwT0alMCgZOYtLSVezDJym8EvBgXSQ/EYKAKwaO1SMmNnffE9/i6uc7xoozBoLA5W4SanpANBmZLnRenp6tGYstWBKY263G5FIRE+O9NfQ/0xhoVyEgAuHJkgpxNhsNn1eQmVlJXK5nC4tnM1m0drainA4jM7OTtjtdl1iuaurC4FAQEfeUwtqb2/XOfec1+H0gzUJZFlMtp2FkejXY940hTYSPPptZY6/ZOj0P1Prl8IB75V1KsrJPKVWMpICAF1MktEMFySsrLWeTqcRDoe1YEi3UTgcRrFY1OObz+fR2dmpD19iAKe0uFVVVSGfz+v65DL2IxAIIBaL6YDc4VozuH+5VsisWZJXrgdZkwPoXR/0IZuzAJjGJY8el6VdKSjtjykPBdL1aGbE+6O3+xMKzD/m50kLmRQGhgsZPEm/P10mVKpaWlq0VYaCAeeKZcA5t3Rx0sdPawD/l+b3coP7gGNGYZw8g+2UMUishMv7zO4zBkFL5SgUCgEwWkAHg7Jq/hJmZlAus91wIRe5x+PRqXokWDJojDnuZDL8jMwJMOaTk1DKTckDJbiQ4/G4rv5UTmYgFxLrWAO9VbgCgQD8fj+6u7t1fWyllDZ/dnV16Sh5tjuXy6Gjo0ObyWQBkXg8rk8HHK4GwPeR8dLdQAGDUGpfFC+P66SJm4KJdFlQCJPmZnlqGJmN3KSSMJdLq5GCmAyGKxcTIKGgNgHAMA4kpEOFw+FANBrFEUccgcrKSgSDQb1fKNy2tLQgl8tpHz2j5Kk1m10vZBxdXV2amFPwk6ecxeNxtLW16ayTcrr+SPgZ9U+NklYlrjHA6ErhvMmCQDTvM0hN+mtlxH+5A8xIx8wCK5mLXMP8TAajmS2qkjZKoUIyI/5mX4YbkyHfyf9ZnIenk1KbzuVyuqQ83U+5XA5+v1/Po6QJDGZmhgotALQelhu0TFRXV2v6wjoQjDEjbZN9J51iu+kS4BinUimEw2FttZQCfigUQktLy5ACGEeM+ZdbwynX81paWhCLxbB9+3bNDGgSlz4WuZnIXPg32yO1SsDIMGT9eIKbLhaLobu7W6fblUOryWQy2Lt3L15//XVd4Y9t5uZiXrvf7zf4m8g4+TfNZpKo0XTFTZTNZuF0OnUtgeHMT1NTE9LptC7mAUAzE1m2lJYVmvpkcCXNsSQA1LykSwboLZghtbx8Po/m5mbEYjHDxiwHGA0uCXM5QQ1IEnvz2h3OOz0eD6qrqzF27Fj4/X6EQiEdsczg1Uwmg5qaGvh8Pr1WSLDHjBkDwHiyIfPoZSoW2y2tbvSXl9O8TK1w69atAHqFJzI77gV+JiEDTTnGcu9K+sEf0gnmdZdTAOCeLJXmx/6af5vN/qUss5xbXpcBntLNVy7tmb78jz/+WO9fGcTHNSFLDnPsaRUwz4l0E0qLD8fJbrcbMjDKASonH374oYGWynZJYak/F4t0tQC9VhFpReTnTqfTUFBoMBgx5n+ogsTKbA4G+m4SToQ0bxNmqRkofc4575UWBZmaUy7tn4x67969Wvsya7LcPPLwHrnRgL6BkDLalhuIm4vpJsMlaE1NTejq6tInWUkfuYwu5/gxTkFWNJOEiSBhAGCwhhB0w+TzeTQ2NmLv3r1D3kj7Q7mfVwr9WRKGs7aoyVRUVGDChAmYOHGiDs7kaZe0JNXU1CCZTGLs2LFaYLPb7bqMd6Gwr9yqUkpX0QuFQoZUJUbUt7W16SIuIxntL/sp3Vdcb+ZsHhlRzmsSUqM205By1vSQMAcS7s/aOhDXq2RAZtO/7JMUboYLWlPpTuWPpF1cB2bmKYUBs/Vjf/8DI3PgVrG47xRCttW890u5SWU/zYxf8iBzWynMDpW+HHbMv5SfilJVuReCeQH3J3WXA2SUDDKhCZILSRIyMldzWwEjozITEvPGMd8/VGzatEkfcUyTPM3VDMaTbaDmLhe+1BQIukDoR6RZWhIwmtvef/997NmzR1djK/da+LyCAlQkEsGkSZN0Aaienh6EQiFEo1EAQG1tLbq6uhCNRrUAFQwGDZopC9LwnAX6+0kks9msrlbn8XgQjUa1G6pc4LxLP2x/e0H+bd7Hg3mf/G3+eygwKxaEXNv99Y3f7++ZpZi/dAPI/pRTqDVbG/Y3J4N97sHC/oSLUrTVLPSUug8wjsVw+nfYMf+BTMZIvGskGH6pd5nNWGap0ixZEvvTCuS1UhaQ4fbpzTff1EReWiGkxs93s38MjmEbpBVDQmpx5n5SsFBqX8wD64NbjH8fSJBTqRRisZius04fo9Pp1My7pqYGo0aN0hklwL6z14F9ZaaVUqioqNBBXePGjdNlr5k1wDzuyspKg7+XbSlnv/oTcs0oxeAGIgCUItDl6INZMKG/H+hNSZZuSyno97ePpTYKwGD14A+FaN5XTouMGeW2YH3WkP56oH/BcaD9lMKBvEdeGwoOO+b/Rcb+pHGpCezPhVFKupT3jcQmbGtr6xMfMRDTZKl7++tHKWIsx4PujM/CRP95gVIKra2taGxsxKhRo1BdXY1//etfhhQ+u90Ov9+PjRs3YsqUKfD5fFBqn++zqakJRx11FOLxuK6mR607kUigq6tLCxZMQXW5XGhsbMQRRxyBxsZG7Nmzx1CrfST6OJBrg/l8oPcMB1JQlmmUFAikq9KsgcpaGWYtn1k1MpCXEf7mPSfrcljoRX8a//6sMfy8FErRO7NLZiiwqc+TSGXBggULFixYGDZGznZjwYIFCxYsWDgkYTF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dgwYIFCxYOM1jM34IFCxYsWDjMYDF/CxYsWLBg4TCDxfwtWLBgwYKFwwwW87dwSGPcuHFYtmzZAe+z2Wy44447Rrw9hzoaGxsxb948RCIR2Gw2/PGPfzzYTTpksWzZMowbN+5gN8OChYMCi/mPELZt24aVK1fimGOOgd/vh9/vx5QpU3DNNdfgX//618FuXlnx/PPPW4z3EMHSpUvx3nvv4cc//jEef/xxnHjiiQe7SRZGGOvXr8fXv/51jB8/Hn6/H5MmTcINN9yArq6ug900C4cwbEopdbAb8UXDc889h69//etwOp245JJLMG3aNNjtdmzevBnr16/H9u3bsW3bNjQ0NBzsppYFK1euxEMPPYSRWErjxo3DnDlz8Oijj+73vnQ6DafTCafTWfY2fF6QSqXg9/vxH//xH7jrrrsOdnMOeeRyORSLRXg8noPdlGGhuroao0ePxqJFi3DkkUfivffew9q1azF+/Hi8/fbb8Pl8B7uJFg5BHL6UcoTQ1NSEiy++GA0NDfif//kf1NfXGz6/9957sWbNGtjth67RJZFIIBAIHOxmDAper/dgN+Ggo7W1FQAQjUbL9szP41o4ENgnl8t1sJtSFjz11FOYM2eO4dqMGTOwdOlS/O53v8O3vvWtg9MwC4c2lIWyYsWKFQqA+sc//jGo73344YfqwgsvVBUVFcrj8agZM2aoZ555xnDPI488ogCoV155RV1//fWqurpa+f1+tWjRItXS0tLnmc8//7yaPXu28vv9KhgMqgULFqhNmzYZ7lm6dKkKBAJqy5Yt6txzz1XBYFCdf/75Siml/v73v6uLLrpIHXHEEcrtdquxY8eq6667TiWTScP3AfT5IQqFgnrwwQfVlClTlMfjUbW1tWrFihWqo6PD0I5isajuvPNONWbMGOXz+dScOXPUpk2bVENDg1q6dOkBxw+Auv322/X/t99+uwKgPvroI3XJJZeocDisqqur1Q9+8ANVLBbVjh071Fe/+lUVCoVUXV2d+tnPfmZ4XiaTUbfeequaPn26CofDyu/3q9mzZ6uXXnqpz7vb2trUN7/5TRUKhVQkElGXXXaZevfddxUA9cgjjxjuHcg8Z7NZdccdd6iJEycqj8ejKisr1axZs9QLL7zQb//ZX/nT0NCgP3/77bfVOeeco0KhkAoEAmru3Lnq9ddfNzyD6+v//t//q66++mpVU1OjotHofsc9nU6r2267TU2YMEGvkZtuukml02l9z2WXXaY8Ho/64IMPDN+dN2+eikajateuXYb3/+1vf1MrVqxQlZWVKhQKqUsvvbTPelFq+Ot76dKlhjFSauDrtaGhQS1cuFC9/PLLaubMmcrj8aijjjpKPfbYY33a2dnZqa677jrV0NCg3G63GjNmjLr00ktVa2vroMZxMOju7lYA1Pe+970hfd/CFx8W8y8zRo8erSZOnDio72zatElFIhE1ZcoUde+996rVq1er0047TdlsNrV+/Xp9H4njCSecoObOnatWrVqlbrjhBuVwONTixYsNz/zNb36jbDabOuecc9SqVavUvffeq8aNG6ei0ajatm2bvm/p0qXK4/GoCRMmqKVLl6q1a9eq3/zmN0oppa699lq1YMECdffdd6t169apK6+8UjkcDnXRRRfp77/22mvq7LPPVgDU448/rn+Ib33rW8rpdKrly5ertWvXqptvvlkFAgE1c+ZMlc1m9X0/+MEPFAC1YMECtXr1anXFFVeo0aNHq+rq6mEx/y9/+ctqyZIlas2aNWrhwoUKgHrggQfUpEmT1NVXX63WrFmjZs2apZkO0draqurr69X3vvc99fDDD6v77rtPTZo0SblcLvXOO+/o+wqFgvrKV76iHA6HWrlypVq9erU6++yz1bRp0/ow/4HO8y233KJsNptavny5+tWvfqXuv/9+tWTJEvWTn/yk3/5v3LhRPfjggwqAWrJkiXr88cfVH/7wB/3eQCCg6uvr1Z133ql+8pOfqKOOOkp5PB6DkMr1NWXKFHX66aerVatW7fedhUJBzZs3T/n9fnXdddepdevWqZUrVyqn06kZrFL7mN/YsWPVzJkzVT6fV0optXbtWr1mzO+fOnWqOvXUU9V//ud/qmuuuUbZ7XZ12mmnqWKxqO8tx/ouxfwHul4bGhrUpEmTVF1dnbrlllvU6tWr1fTp05XNZjMIID09Per4449XDodDLV++XD388MPqzjvvVDNnztTraKDjOBh8/PHHCoC6++67h/R9C198WMy/jIjFYgqAWrRoUZ/POjs7VWtrq/6R2vOZZ56ppk6dapDyi8WiOuWUU9TRRx+tr5E4nnXWWQZCeP311yuHw6G6urqUUvsITjQaVcuXLze0Ye/evSoSiRiuU3P/93//9z5tlm0k7rnnHmWz2dT27dv1tWuuucag7RMvv/yyAqB+97vfGa7/+c9/NlxvaWlRbrdbLVy40NCvW265RQEYFvNfsWKFvpbP59XYsWOVzWYzMLXOzk7l8/kM78nn8yqTyRje0dnZqerq6tQVV1yhrz399NMKgPr5z3+urxUKBTV37tw+zH+g8zxt2jS1cOHCA/bZjG3btikA6qc//anh+qJFi5Tb7VZNTU362u7du1UoFFKnnXaavsb1NXv2bM2k94fHH39c2e129fLLLxuuk7G/+uqr+tpf/vIXBUDdddddauvWrSoYDPbZJ3z/jBkzDIz2vvvuUwC0haRc69vM/Ae6XpXax/wBqL///e/6WktLi/J4POqGG27Q12677TYFwCDcEVzrgxnHgYKC+scffzzo71o4PHDoOp4/h+ju7gYABIPBPp/NmTMHNTU1+uehhx4CAHR0dOCll17C4sWL0dPTg7a2NrS1taG9vR3z589HY2Mjdu3aZXjWihUrYLPZ9P+nnnoqCoUCtm/fDgB48cUX0dXVhSVLlujntbW1weFw4OSTT8aGDRv6tO/qq6/uc00GCiUSCbS1teGUU06BUgrvvPPOAcfjySefRCQSwdlnn21ox4wZMxAMBnU7/vrXvyKbzeLaa6819Ou666474DsOBOnvdDgcOPHEE6GUwpVXXqmvR6NRTJo0CVu3bjXc63a7AQDFYhEdHR3I5/M48cQT8fbbb+v7/vznP8PlcmH58uX6mt1uxzXXXGNox2DmORqN4v3330djY+Ow+18oFPDCCy9g0aJFGD9+vL5eX1+Pb3zjG3jllVf0uiWWL18Oh8NxwGc/+eSTOPbYYzF58mTD/M6dOxcADOts3rx5uOqqq/CjH/0I//Zv/wav14t169aVfO6KFSsM/virr74aTqcTzz//PIDyre9S/RnIeiWmTJmCU089Vf9fU1PTZx09/fTTmDZtGi644II+7+NaH8w4DgRPPPEE/s//+T+44YYbcPTRRw/quxYOH1gBf2VEKBQCAMTj8T6frVu3Dj09PWhubsY3v/lNfX3Lli1QSuHWW2/FrbfeWvK5LS0tGDNmjP7/yCOPNHxeUVEBAOjs7AQAzTRIPMwIh8OG/51OJ8aOHdvnvh07duC2227Ds88+q59NxGKxks+WaGxsRCwWQ21tbcnPW1paAEALLWZCVVNTo/s2VJjHKhKJwOv1orq6us/19vZ2w7XHHnsM999/PzZv3oxcLqevH3XUUfrv7du3o76+Hn6/3/DdiRMnGv4fzDz/6Ec/wvnnn49jjjkGxx9/PM455xxceuml+NKXvjTwjv8vWltbkUwmMWnSpD6fHXvssSgWi9i5cyeOO+64kv3bHxobG/Hhhx+ipqam3/5I/OxnP8MzzzyDd999F0888US/68K8DoLBIOrr6/HJJ5/o9wLDX9+l+jOQ9UqY1xawby/KvdLU1IQLL7zwgO8dzDjuDy+//DKuvPJKzJ8/Hz/+8Y8H/D0Lhx8s5l9GRCIR1NfXY9OmTX0+O/nkkwFAEzCiWCwCAG688UbMnz+/5HPNjKQ/rUz9b6odn/n4449j1KhRfe4zp8N5PJ4+2QeFQgFnn302Ojo6cPPNN2Py5MkIBALYtWsXli1bpt+xPxSLRdTW1uJ3v/tdyc/7I3blRKmxOtD4AcBvf/tbLFu2DIsWLcJNN92E2tpaOBwO3HPPPWhqahp0OwYzz6eddhqamprwzDPP4IUXXsCvf/1rPPjgg1i7du1nErk90NSwYrGIqVOn4oEHHij5+RFHHGH4/5133tGM7L333sOSJUuG1L5yrO/+njuY9TqQdTQQDHYc+8PGjRvx1a9+Fccffzyeeuqpwzrt1cKBYa2OMmPhwoX49a9/jX/+85846aSTDng/TbEulwtnnXVWWdowYcIEAEBtbe2Qn/nee+/h448/xmOPPYbLLrtMX3/xxRf73CtN9eZ2/PWvf8WsWbP2y1BY76CxsdFgmm5tbe1jcfis8NRTT2H8+PFYv369oX+333674b6GhgZs2LAByWTSoP1v2bLFcN9g57myshKXX345Lr/8csTjcZx22mm44447Bs38a2pq4Pf78dFHH/X5bPPmzbDb7QNmLmZMmDABGzduxJlnntnvGiASiQQuv/xyTJkyBaeccgruu+8+XHDBBZg5c2afexsbG3HGGWfo/+PxOPbs2YMFCxbo9wLDW9/99Wcg63WwzyylDJjvGeg49oempiacc845qK2txfPPP1/S9WjBgoTl8y8zvv/978Pv9+OKK65Ac3Nzn8/NWkFtbS3mzJmDdevWYc+ePX3uZ+72YDB//nyEw2HcfffdBnP1YJ5JrUa2VymFX/ziF33uZR64uaLY4sWLUSgUcOedd/b5Tj6f1/efddZZcLlcWLVqleF9P//5zw/YzpFCqf6/8cYbeP311w33zZ8/H7lcDr/61a/0tWKxqGM6iMHMs9n9EAwGMXHiRGQymSH1Y968eXjmmWcMVqfm5mY88cQTmD17dh8z+UCxePFi7Nq1y9B3IpVKIZFI6P9vvvlm7NixA4899hgeeOABjBs3DkuXLi3Zp1/+8peGdfvwww8jn8/j3HPPBVCe9d1ffwayXgeDCy+8EBs3bsQf/vCHPp9xbQ1mHEth7969mDdvHux2O/7yl798JhY1C59/WJp/mXH00UfjiSeewJIlSzBp0iRd4U8phW3btuGJJ56A3W43+CAfeughzJ49G1OnTsXy5csxfvx4NDc34/XXX8enn36KjRs3DqoN4XAYDz/8MC699FJMnz4dF198MWpqarBjxw7893//N2bNmoXVq1fv9xmTJ0/GhAkTcOONN2LXrl0Ih8N4+umnS2riM2bMAAB897vfxfz58+FwOHDxxRfj9NNPx1VXXYV77rkH7777LubNmweXy4XGxkY8+eST+MUvfoGLLroINTU1uPHGG3HPPffgvPPOw4IFC/DOO+/gT3/6Ux/f/GeF8847D+vXr8cFF1yAhQsXYtu2bVi7di2mTJliiOlYtGgRTjrpJNxwww3YsmULJk+ejGeffRYdHR0AjFaRgc7zlClTMGfOHMyYMQOVlZV466238NRTT2HlypVD6stdd92FF198EbNnz8Z3vvMdOJ1OrFu3DplMBvfdd9+Qx+jSSy/F73//e3z729/Ghg0bMGvWLBQKBWzevBm///3v8Ze//AUnnngiXnrpJaxZswa33347pk+fDgB45JFHMGfOHNx666192pDNZnHmmWdi8eLF+Oijj7BmzRrMnj0bX/3qVwGUZ32XwkDX62Bw00034amnnsLXvvY1XHHFFZgxYwY6Ojrw7LPPYu3atZg2bdqAx7E/nHPOOdi6dSu+//3v45VXXsErr7yiP6urq8PZZ5896LGwcBjgYKQYHA7YsmWLuvrqq9XEiROV1+tVPp9PTZ48WX37299W7777bp/7m5qa1GWXXaZGjRqlXC6XGjNmjDrvvPPUU089pe9hKtSbb75p+O6GDRsUALVhw4Y+1+fPn68ikYjyer1qwoQJatmyZeqtt97S97AISil88MEH6qyzzlLBYFBVV1er5cuXq40bN/ZJYcvn8+raa69VNTU1ymaz9Un7++Uvf6lmzJihfD6fCoVCaurUqer73/++2r17t76nUCioH/7wh6q+vr6sRX5kIZX99ff0009Xxx13nP6/WCyqu+++WzU0NCiPx6NOOOEE9dxzz5XMDW9tbVXf+MY3dJGfZcuWqVdffVUBUP/1X/9luHcg83zXXXepk046SUWjUb1ufvzjHxvS30qhv1Q/pfYV+Zk/f74KBoPK7/erM844Q7322muGe/pbX/tDNptV9957rzruuOOUx+NRFRUVasaMGeqHP/yhisViqru7WzU0NKjp06erXC5n+O7111+v7Ha7LjZkLvJTUVGhgsGguuSSS1R7e3ufdw93fZeaS6UGtl5Z5MeM008/XZ1++umGa+3t7WrlypVqzJgxuoDP0qVLVVtb24DHcX9AiSJb/DG3xYIFwqrtb8HCCOCPf/wjLrjgArzyyiuYNWvWwW7O5wKPPvooLr/8crz55pvWgUQWLIwwLJ+/BQvDRCqVMvxfKBSwatUqhMNhbea2YMGChUMJls/fgoVh4tprr0UqlcJXvvIVZDIZrF+/Hq+99hruvvtu60Q1CxYsHJKwmL8FC8PE3Llzcf/99+O5555DOp3GxIkTsWrVqiEH6FmwYMHCSMPy+VuwYMGCBQuHGSyfvwULFixYsHCYwWL+FixYsGDBwmGGAfv8KysrUVtbixNOOAFz587FGWecgbFjxyKZTKJQKOhDbYrFIjwej65KlU6ndY3pZDKJcDiMVCoFm80Gn88Hh8OBYrEIt9uNdDqNYrGIYDCIYrGIbDYLu92O7u5ueL1efPTRR3jllVfwxhtv4P3338fevXv7VEM7ECoqKlBdXY0TTjgBZ555JubOnYsjjzwS8XgcxWJR90MpBbfbjZ6eHtjtdt2PYrGIdDqNcDiMdDqt+2G321EsFuH1epFKpVAoFBAMBqGUQj6fh81mQywWQyAQQGNjI15//XW88cYb2LRpE3bu3DmowzuIoZYCHWkM1pPk8/mglILNZtM12NW+46b7/A/sOzWPf9tsNsM48DmyHTabDcViUT9D3l8sFmGz2ZDL5fqcVzAUj9gXZU6+KP0Avjh9+aL0A/ji9MXhcMDhcCAcDuOkk07CBRdcoItDFQoFOJ1OFAoFTWf27t0Ln8+HTz75BE6nE0opxONx+Hw+BAIBOJ1O+P1+uN1uTbdCoRBaWlpw7LHH/v/sfWeUZWWV9nNzDpW7moZukg2NyEADjmRJrcAaYUQGVGhAG0TAJcZZzhBUBGEGw4AE9ftQGJlZShCWY1aWiuAon4CghKZpaOhQ8eYc3u9HzbNrn1O3uqvqnqJx+jxr1aqqc88957xph2fv/R4YY1Aul5FIJFCv1xGLxeDxePCXv/wFTzzxBJ588kk88sgj+H//7//t8NnnrPxbrRZqtRqKxSImJycxPj6OdDqNTCYDn8+HWq2GVquFZrMJYwxarRaAqb3M2+22dAB3R2u322i32/D7/QiHwwiHwyiVSohEImg0GqjVaqjX62i322g2m2g2m3j11VeRzWZRq9XkPvNFq9VCvV6XdkxMTKC3t9fSDt6Tv9kOKnK2g+00xsDn88kAcjCbzSbq9TpqtRqMMWg0GpicnMSmTZswOTmJarWKer2+oHb8b8Juu+2GeDyORCKB3t5e9PX1oa+vDwAsBkGr1UKr1YLP50MgEEC1WpXxoAL3+/2Ix+NijNXrdZTLZfT09KBYLKJUKqFarcIYg0AgIPP2kUcewcTEhIz3rg6v1wuv1wu/349gMIhIJCKVCxRaXOPAlBCksOKa0EZYMBiUvvV6vSIYuba14UXZkMvl0Gg0dvn14eKNCzoUrVYL5XIZk5OTyOVyomNCoRAajYbInUKhgGazKWuEOiIYDIruiUajiMfjiMfjCIfDAIBwOIy//OUvFgfUGIOBgQHk83ls3rwZY2NjyOfzc3qJFTAP5c8H5cNWKhXU63VEIhF5QO6z3W630Wg04PF4RFhTEPt8PpRKJQQCAXg8HrlmrVZDIBBAvV63KMR2u41arQaPx4N6vY5qtSqGwUIENYVTq9VCo9FAtVpFo9FANBqVdtTrdWlPs9kU640CrtFowOfzoVgsSjv0NdkOvW8526/bQeW/qyucY445Bul0GsuXL8duu+2Gvr4+RKNRpFIp6RutVIAptoDKAZj27qm02Nc+n8/CONFwBKbmdCaTQSAQQD6fx1NPPYWJiQmLUttVMTQ0hFQqhf333x977703dt99d/T39yOZTMLv94thDkAM+2QyiVwu19EoqFQqqFar8Pl8CAaDaDQaiMViFkHm9/sRCAQwMTGBUCiExx9/HE8++SReeuklZDIZd1xcvCFhjEG73UapVMLExIQYrP39/SgUCshms5iYmJDPw+GwODXNZhPVahXRaBRbt25FIBBAMBhEKBRCOBxGIBDAkiVLsG3bNvj9fiQSCUSjUbRaLVSrVaRSKWSzWfmZmJjo+Er5TpiX50/vn0KUwpa0drPZFIWprRl+XyvVVqtloX78fr94FvSk9bW1V0FhM5fXytrBa2hDgl4KDRYyD7VaTZSLtvCoWNhWAGJtlctledENmQ16obwPGRK2ZVcXaul0GoODgxgaGsLg4KAomXQ6LfOH49ZsNhEMBkXJs99pwJER4sY7oVBIDK54PG4xFlqtFiKRiHzG63Y7HnZK0+PxWLzXTv/bYQ9PdPrc/l19zW695WAwiFQqhaGhIey9997Yb7/9sHTpUiSTSQm7cDw4Rslk0vJSHY6Jx+NBuVxGtVoFADGYeR8aEoFAAKFQCCMjI/B4PBgfH8fmzZsxMjKCfD6/y68TF288UC+0223x/GmottttVCoVjIyMYGRkBMViEblcDvF4HM1mU/RCrVZDMBhELpeD3+8Xw4AhhUwmI8fi8ThisRi8Xi88Hg9SqRRGRkYwMTGBbDaLTCYj62xHmLPyp/CtVCqi/L1eL2q1GkqlEnw+nzACFMDhcFgUaLvdhs/nQ6PRQDAYRKVSsShEv9+PYrEojafyZxydFPyOhOJcBotWU6lUQrlcBgDUajUUCgVpR7lcFmOFCoIGD8+h4KJQ4oDpdvC3MUYUkaYynaQ0SdPqZ2FfcbKwXzspDz6PNnSoDGloabpXh0G6wdjYGEKhEMbHx6W/wuEwJiYmhPUhm1Sr1RCLxWS8QqEQ2u02CoUCBgcHUS6XhXlpNpsSjpmYmBDKjO0mUzM6OopSqeSIcvF6vQgEAvD5fOLJ0tKnscy+I2jc6mP6XA3mQWjjmWuC4Q962VSqC5lj1WoVlUoFmUwG4+PjyGQySCQSyOfz8Hg8QuOXSiVUKhUEg0GMjIwgk8lIWKBSqSCVSkm/0ugHpmjMbDYrgozjwjybUqmE0dFRlMtlad/rHSfudD89TjszHMH+4BqncuAzawWiv6Oh20EFBsCy1u0/Wha4mEaz2RTlv3nzZpTLZbz88ssIh8PI5/MYGxtDsVgU56VSqVj6naEx9i/nfCAQwIYNG7B06VL5n/Klt7cXzWYT27ZtQz6fRzabRbFY7Pimy06YF+2vLX0KmEajgUKhgFqthnK5LEYBPVtOFFoxPp9PXo1JjyEQCCASiaBWq4nA1HFeTuRCoSD/L1QYaM+fr8ukoGSsRnspbAM9fCp0GjLAdLiDlA0NHJ7XqR3aA+1WqFEIRCIR9PX1wev1Cm3Oe0ajUfj9fqTTacRiMQmthEIhEQI+n0/i6PV6XRItC4WCHGf8iuGaiYkJSXBcqDBsNBrIZrNYsmSJxJe9Xi9yuRyi0agkuTCJlF5gNBoVowCYYl0qlYoYm8YY1Ot1TExMSEIpE2nYlkgkgqGhITHMnPCYBwYGkEwm0dPTgyVLlmDfffcVg4T314K32WzKOLBfdQIklTq/5/P50Gq1EAqFhKGiMvZ6vXj22Wexfv16bN26FaVSaUHCmjFMHerTlDzXOwUaQ2PMuzDGiOFWKBREsAFTBtLY2JiED0KhkCRIZTIZxGIxSWQiQ/d6KRytPGko6+PMU6DQ1omkr5cxQBkUCoWQSqXkb65xAEIbp9PpGYaBNugppykPvV6vOHAcT4bKuE6ZJ7MzjB8tK+2Jvfa/X0/QMc5kMhgdHcXo6Ci2bduGer2OUqmEYrFoyWOj08ix1PKA64QhMgCyxjmWgUAAY2Nj2LJli4xTNpud11qZs/KnwKTHnM1msW3bNrlRuVxGuVwWQZzL5WZk8TOmXq1WJRECmFpQk5OTEtNglr+m/ulBVCoV8coXmmVKA6ZcLiOfz2Pbtm2yGCjQ6PXn83mh79mOUCgk7WCCIjA1WBTO6XRajvGn1WohlUqh0WiIMmPYwQlwIlEYhMNhRCIRi2AIh8MSM+K9aUFWKhXEYjER5vF4XBQ92Q9Wasw1rjQXsA8LhQJGR0cl1NPT04Nt27ZJcl+xWJRx4vjpPA2dTKqNLhoDrLbw+XwylxuNhoRvnBgHKmCOA5+D/5NNoXKMx+MSruCco+Kh8aKTTsPhsBgtFOhUknquEdqrng+47pgYu23bNjFoWJnSaDSECSSbxvAdE2S1jOAxOg/hcBj1eh09PT1ivHB+sT/ILC22ULcr/VAoJH3JfqYBox0hzh3On9fTCPB6vQiFQrJWGboKhUISekwmk8KOca6Hw2H4/X6LER8MBiUvJhgMSi4GK5qq1arFgNgZsDNh1BGzsRGvpyHAhO5sNosXXngBrVYL+XwehUJBnCey29Rd2oDShr42/JmYzGNkFMmGc41Ql2lnaEeYl+dvjEG1WkUul8Pk5CQmJydlQdRqNaEKSY/TS6SwrlQqSCaTIpC15cZO6OnpkQzjUCgknjRLIuiBdrPIdDsmJiYwPj4u92EeAFkMLnBOMDIDiUQCxhgpNbRTsOVyWdoRDofl+q1Wy+JJOyksSJf7/X4kk0mpPmBJZSKRgMfjkTgsBRgwpZyGhobEwKpWq5KRHYlELAmSnIBsY7cCIZfLIRwOi6JptVpIp9NibORyOVQqFRSLRZTLZVkU4XDYwlpQCTIMRWFBr5uLSwttJpraEwoXCgojbYiRJdLUNue2z+eTcBMXNw0ZJvwwYVaHceh1krUKh8Ni1ADWKomFgEq3Xq+jUChgZGQEPT09Mm+51unVkJXweDyYmJiA1+u1xPM5b3QSMI1MXYFRr9exZcsWhEIh5HI5mYeLCU2RM++A60YbHpxvXq/XovQpK+gRazZgMeH1emWORKNRRKNRScDmj9frlVwqrvdQKIRWqyUGF717OjnAlGFH1oXrSY/h6wUd0qBRq8NAOmysGTI6EK/HOJAFqtVqQr8zpMzEeDp8Olyuq2K0bNJKXjsA1Ce6Som6t1QqIZ/PCxM3F8x7b39a5I1GQ6gMxrGp+OkJ6GQ/LhbG8PiAejJRkQQCARGawWBQDAy94BYqqPkdTnoKN1pj2puhYKUA4zO0Wi2USiVRNkw800lM/M120GvTyX6dypwWCk6YcDiMRCIhv9PpNOLxOIApL4BsjD1WSG+NrAqTVbLZrCgxKiVNAzshDOhlcv5oupHPQ8ZHG1f0RjimXq9XQkpUMLSQSS1zrOiBckwY83dCUNBj5GLlgqY3yftrpojnMNbPWDi/TwVI5cJkWhqXvAaVQbdGGZ+R3iIACamwv8ic6NAAYPWiOa7Mv+CcYdiCjGAwGBSjPBKJoFAoWKozFkuAc92wH8mUpdNpS6kjhXMsFhNDhcYwDVS/3y/9pUNPi/HMVIbBYBCxWAyJRALJZFKMfmMMksmkZY1TSdHAYV4G5Q/jxXzuUqkkck2X2PLY62Hc8Nk1Na77wBgjskk/Fz/TBsBiP692eOnxc/5Shvl8PkuYVD8jAEuelc6V4/UZoqFM5rk0EOaTkzGvhD/+ULFTeWoPmZYiPWQKNJ2hz1Is/s1GkMLVWdm0akk96USmhYALgMqXhgyZCz1QZBpIRWqrnt4dWQmdbBeLxWCMEQEOQIQbADEuummHHVqIRaNRJBIJpFIpJJNJRKNReL1eJBIJEbg+nw+xWEw2KyK91NPTI+ObzWZFsOt8AL/fLzFZjl03woCUNceC/Tw6OioLikYYGSPSZzyXCofGVLVaRSAQkOdlG6iUeV9diurEWGijijkgFJh6ETMEAEzng2iamUIagGWRU9hxDDX1yXFg+7oRdtrY1TkINPh1yISCh8KN60MLIq4T9glZBQBiSHI9sVx2MRUoMK1AGBaLxWKSTZ1MJmU9cY8DyjIdt2X4jgKZcXO2C1gc+pnjHA6HEY/HkUql0NPTg3g8jlAoJAakLlMm49RoNMTgpqwiE1Aul2Xs7Ya9Lm1ebOiwL9trr8Sx58EA032tnQLKfP2509DJe1wbuiRdhxe3F8rSukX3hdYznLN0fvQ6nY8cmxftzwvrOn/SxJomyufzqFarkklvv4bX65X4Oa1JLbA46ZiQBkAspm49Ad0OepZUOPybi5r0fKlUssRmeA2Px2OpAKBXYxfGgDXhj/kRTm7wQ2FA2i+ZTCIWiwn9x+M6pyKdTmN4eBj5fF6SFCmYOXZ64nI8aKRRmHdDLwMQipvUKfs/k8nMiK/yuUhB0tqllxmNRsVQoJKkgOMYcXFo9skpI4zKjx4jlYeOzes5QSHMNaAteYaK6PXQAGW7dOUAvwtA5mE30AlfNPDp8TP3QjNnAET502CjscLYPp+d1Q80yDi+NHparZYof+0hOQmdOBUOhxGLxZBOp5FKpUShUllSufr9fkk2pbBljDyfz8t1KSNoAC2m8qfXT88/EolYwkp6pzkygaSjuX61saz3WgFgMQRotHa73ufSNspReziVn9tlK9edrubR80aHCBbTANBzA4AlzKhpfbsRw+/r5wWmjRjOIxpFzEGjDKReXBTlz4cj3Z/JZGQhMJZBuoOWD40CHb/gguDk4uLT1AwFARkCNpydyv+7EdhUJNlsFrlczhK7KxaLEl/mAqcy0YlkHFS2g/RyqVRCNBpFLpeTSUpvgYKRE6HbdhCkiJPJpHj43LgoEomI8AIgyoiCNxaLIRqNSmyaCqfdntpqOZPJyIY64XAYAwMDspmFE7Q/FTr7rVgsYuvWrWg2m8jn88LG6CoMe9iIBkCpVBLPhklxTJAjHUqrm8aCZqW6BRc1FT/7nwuT8VYdm9deiz0fRhsmOplPZ2t7vV6kUim0220R/nquLmR8NDNGA3hkZEQUh06aLRaLkiWu78c+5W6YDH1QiPE5+R22ncm9ZHqcMszsYIVMJBIRBc/QGOcOGbRoNAoAGBgYsNCsZK24zbluu32PEKegDRfujEnjnuEthn/IQGkjJx6PC5sJTCdu0uhhqSWNsJ6eHkxMTCCZTC66529X/FrB0+AlI8C1rUNcmh3gPKOjZmcDnALnNseca0PrM84Xrch1+3bEBNgdFDpjesc/OqJzbdu8lT8FTrValWQ3JhqQluePzuYHYKEPdexdZ/fHYjHxJoPBIOLxuCwq+w5tC7VAO7XDGINcLid1y6T7SXUDmKH4aW3qdujkGHpgjBkWi0X5TF/XCUtaewJM6uvr65NkP4YlhoaGUC6X0dvbK5n9/f392LJli8Q5ybbQSNi0aROWLl0qNazj4+OIxWJoNBpCMXYDhpBYiUBlqa1o9hnDEYx7cwExBpbP5+U4DU0m2OgkOj4zS0+dSizTcUoaYFT42pui18XnA6aZAOZkcGHrTG22mxuFRCIRy14SusxUC5f5gtcirc0aZh7T8W4aAQyx2CnLcrkswlyHdYBpI0nn+LRa0/twUMg5DS1v+vr6ZOc0yp9UKoVYLIaBgQHJmeF8Hx4exuTkJLLZLOr1OoaHhxEKhTA2NjZjx0/G1J1OWmQ+y+DgIDyeqcoYKmf2o9/vR09PDxqNhiQwejweKQEGpksXme/T398v7zlhQjRLrMlyLJbnr/MTNKjkAFjWLdcxdYq9yoVGp2YN7Nd1Gq3WVJY/dYG9YkUng9qfy57TMBt7wbUJTDOz+vpzHZ950f5sHKn9yclJeL1e8fYpDOih6QQmQmdkUrBp6l9TmIyT06tmOIECZCELSsdmuFFMJpMBABQKBXl2hi3YDip7TenR+tS5DFx0pJnZNv5vjEE+nxdWRCdzdQMKg97eXvFktNL3+/1YunSpePmkBpPJJGq1GlasWCE112RcjDEYHx9Hf3+/lKqQSuzt7ZVYrRO0P7O+c7kcPB6PsEE09hgqYbhIe86aYtcGFb/H6zF/hGPk9/uxZcsWoTqdiC8bM7VZB6lYrdj4o+k/0tvValUqNdj33POCQoLGApMYfT6fGBf1eh3RaBS1Wk2OcW4uBDqUwhAMFTGfl6wAaX8d49YGGddGq9VCsVgUr1MnyGnKmUwN18hieM4sjyPd39vbKwp/yZIlKBaL2HvvvSXM1dvbK3KJayqdTqPRaOC1116DMUbeKcG4LmDNlXI6xBeLxdDf3y/rnAwA+3/JkiXo7e1FPp+H3z/1whgaJ8yrIsPB8msmYDabTXkxGRmSrVu3Ih6PSy6K09CMhj6mlR6NasodzhmG9jRbREfLrjwBK0PgxHMD1nwDyqlOP8C0Hpzteto40MymnVnSeQXzTSCfl+fPh9eeWLvdnqH8eVxnwvP77Bz7/zr+SaHBmCLflKeT5LqJ+VP56wqFZrMpgkkrf61o9HMz/tWpXbo0gwk3pHzpOTkZ72e7PB6P1PUODg5KyRIVHz2cWq0mxkIoFMK2bdukBIheJzDlkff19YkBxEVHJcR7dRtfZqyYyiSbzUpeASe0NsZogALTHoD29lnaRKHIeURBoWnQWq2GVCol4aVuwWfQ8TdS2YzP2XMN6M0DkNi6NgJ020gjAlPzrVQqoVQqyVyjcNc/CwH7gvk9VPCkGJkUSu+G653zUCfA0oDnM3OdcL2z3JI167rCQ9P+Tq0Xr3d6Eyx69jQAgsEg+vr6sHTpUqTTaUvSZrPZRDKZlBeBsSKht7cXK1aswPj4uOzBznXEEIbTDAY9XRqz6XRaQhjsx0QiIUwGAGGTuN60F08Hi6wAx5EykCwJv+M09e/xeGYwVpxHnCfGGNmng59zvlNe0JimzCCzoWX09hTvQqA9eJ3IqpNetc7S97fPCTrF2uih8WwPWdDrtyt8x2l/Kk3Sl4z78U1pXLBUfHaLi9egYNMPSY9Yx6C46Nh59BqcoGe18iflzBg/N95hp86Wka+NAkK3g16Tpm45GZipzgnthFCgMOCCYaJbT08PYrEYQqEQ+vr6JJFMW/RMktOZ8eVyGX19fbKvNPtMT2hjjHir3SwmGonlcllCDjT+SP3qbH8tTGk4cgF4PB7LXgS6RIiLhcKRIRoyBk6OAw0MvR0nPSqWx5IRYD4JYI0fslRWK3F+j3FAPjeFg753N0aZfY3UajXZ6IlvJtPrXc8LPi+pSRpgOkQDTIcD9Rjq6h+GxpyO+VNZMP7d29srO18CU+uY68aeP8FNljhv2u02hoeH0WhMbVKVTCaFKeH4OLEXhh1kGUOhkDB9bBMp/oGBAXlTKhU4WSIaXGxDs9kUA5XOFvvd7/fL+NMBWAzlP1u1il7D7HeOBw0tKn9gSjbzhV1cS3ZPejEof/3MOrylFb/+baf87c+ldYM+TjlMHaOTYuczLguK+ZP2054+a0R1cl6nDqfnQ2FFwcVFosMLtHho/dPA6FZp0gjRgo3MgqaWdXIeYDVidFKiNnK0oACmJy6FPjOmacQ4SQXqOB49dQoGUn6cLPrZfT6feI/aY6WHEwwGJX5GxcJ9DvRCXCgoTEn/e71TZZ+klHVJGceOvylggelKEc4bCgYaYNx0hnONFDoNDadof03z+/1+2TqYVCWNV3rq3KZYeyecg/YSHx3zJLPBdlN46ryGhQo6HVvUJbb2/S+0cc4xsXs12ijWLJ+WD3rd0ADkenEapI7JdDEUxioEVmjoZFYadTp+q/s4Ho9bwmIcW4YLnYZmvJgnw3aw1JeVPQyhsZ/tY8D1QuOOyl8bSXQaWD64GLCHDzlf9Dyn4c6fZrNpqVLS3jWPzVYJ4DT0fNZydHvJfPa4/vbOIbjeqDf1GpmPXpy38tclPvT+da28bjQVJL8LQGKd+poAZghK7d2RktIb0CzUG9AMhk5a0v+zPZwwc20HvR0d59QMAReNLpN0ksqkANWJS3w2v98vCW9cMB6PR7y4drttEVbxeBztdlsodHqrsVgM5XIZ4+PjFoXTDdg/NChIy+r3Cegd1Oz9zvEEpo0tj8cjip7bB9MI0x4Ps7SdomU57jrTXjMLOqbJeH4qlZKtOXUui17cFHZMXuR2zbovuE6oeDhnFzI+7Fe9jTKVgI4vamZMC1j+D8AyZlwTDB3pEAjbR/myWHX+WglqxcBEv3g8Lu8a4Xpgf5ZKJaTTaTk/EokIg6RDNZFIxLI9rpOeMp9bl5JS6etk0Xq9jnQ6LW3kPKdipJyl0cL5yXvo913kcjlh+hbL8+eaoWzVuTw0vLhDLA0uvgyMeUpkNYwxshGWNpoXE1oWcU7x2Gz6ym4A6PCBHXZDQa87bXDPdWzmnfCnrZlmsyllIVoY6LinfeHys07X53WpUDgBaL3Z6/y78fz14DQaDeTzedmKmAqHz2pvCzuX7dAxMt0/OvObi1VnrTsp3BhryuVyEounBUoBzjIr1o8zvAIAqVRqBoUETFHyo6Oj2LJlixh8W7ZsQTAYxPj4uCjNboSB9qYYW2Rc3+5l6g1K7P3G4xQi9BbotejXN1OZ0oN2ivanl0XFQIMKmDKg6G3y3gyr2DcB0WOjS5tYCkm2hHNTb2jEJEfmESwU2vhlvzMvQyerch1oYce+1MqE55DR4DNzTDSbwbF0Ot6vwXwY9pPH48HAwADa7Tb6+vrQarWQy+XE8E0mk2IUM7Sk2Rwa9cxfILvnpJFPcL0x54AGLUs9KYtY0UMjJBqNSvUFmTYqV2OMvFuDGes09P1+vzgK+v5OQTN5NC5oKKfTaUtCLOWp3++XtutXf3s8HiQSCdmkTPc/y5kXC7rCQ8u12dqsf9v/tp9r1z88pg1ozYTuCAv2/HW5Gn840fXufVoh8mEpnHV8kH/zPAoAKkjGnXTcdyHQ3ojOlqQQ1cwFlYUWXNpw0PXZACyeFs9jO9g2KiEdK3UCXCxU7MB0Il06ncaSJUsklq/3hmZYgP3LJJlwOIyxsTHZ+8AYI7kdrAUGnNlQRhtMvCaFlGZidH/ZrV1NK1OhcDEYY6RdPE4hQi/ZKQFNr4TCmLXTTJ7kfTkfdGyb3lq9Xkdvb69Q6lrJUKDRC6eHxtABk43YFwuFXid6Dw+yb9pQmU1Ba0qZ3px+LvsxnUmvQwpOK04KzEwmg97eXtnIh2+Q9Pv9GB0dRTAYlA2+BgcH8Za3vAUvv/wyJiYmhBFjpRAT4/S7KHSCr5Og8RqNRtHb2yvKkHOPiYxU3sxlYOIm5wrLqJk7MDIyAo/HI+udMiqVSqFQKEgSIY2LxWgTDWEyTaFQCJVKBcPDw/J2SBpVzGGgIaMNSw0alNRPWv84Nbe0POI8tsf67cqbx3Uf2P/vdA4wLWcoR3jefPTJvDx/Ppymx6kwOgkE/R1NfWlr3z6JKBAooPU9tRHR7eSjACCboH+0otHGiFbydgbD/j8Hh+3ghNN5EU60g6ClSUWSzWbR39+PdnuqRPKll16Sfez5tj5jjNDrpJwzmYwoFSZ08mU6ZBI0RedEXFZPXlZg6FdG63nFMeH5wMzXIutYpmZn9NzR+QBsvxOg4aSTjbgRDEMu9AwbjYbsCc8wBGv4SR3T8+Q5LOEjI0awn1iaRo+2W7qTAoWsj91wnU1B2ylMbexow1jH1HXoSofFFkP5U5bwXevcAlvnnQwPD0v2eDAYxJ///GfstttuiEaj2LZtG7LZLCqVirwZVCfJAdPZ3ovl9VOG0XNn6SIATE5OyrnZbFbCkT09PaLYyeLQSaDsI+vJ62umzL7mFoOR0YwTDXju9qk9W26lXCgUJM+CmzGNj4+j1Zp67XelUpF1SX3ltPGioeWOZsK0IaD7rpOSt/9vP1/3v/7N+88FC8rcoEBjR9oZAN7c/hB2S6XTBNLeMxcOPbPZMigXClqJTPizv6jEblHZB00zF3YhpUMXmhbtxDA4tYDIVuRyOSn70YlnbC8tYyocPhe9F3oM9Fq4k6Mu46Sw7ib/QkMLG52AaVc0Wvnbv9+JRdKfa0rZPg5OKRmPxzND+epyKgpRYHpPe76ghwqPiWf0QhkyovEQCoVEMGr2gmtFt9cJIcd5QxZIr0Md3+R97UJNj4ndQNahMR6zJ/8uBmgo836FQgH5fF5i+LFYDJlMRuYGNzRjiShDd9VqFSMjI9i0aZOEYpiXwfj/Yih/Okasvkgmk7K22Xd8QRKZKFLepNMZmmJYkEY+ZTuNANb/c08AJ/J8ZoPO2WGulcfjkYRk7mHBfuDLczh/dEiN64xOD2UJ5ZbT0EbljuTKXKj+HZ3PtWbXt3OdbwtW/qQD9VuL7F6AnerQxzsNwGyKVWcSd7r2QsF26JI/u4FB6Pt2ag9/60VhV5L2dnDgnBAOvBY3Lurp6ZFd7chC6KQYXWERCoVkrwY+NzPtdY6CLr3iuDhViqXHnd6/Nip1aMDeX3Z2qROjwuNaGXs8HgkHOCUM7NQfhZeOYwLTZYfaI+b3qMBpCDDsRcXC+zAUoHNK9LswulX+up+Zg6F3LOsU49+eoNueJ2Nfz6zaWAxwrWhWqVQqIZPJIJFIiEepY+dU+gx/ULkXCgWMj49LnoXOiVissIVdxmhGhTlX+jXcmv3xer3SDnrSpNqZx8B72HNOtEx2GjRoOP/1OrWzZzQQKN8SiYTICb6zwL7nhJbprPSZa2x8vtCy3r4+nIJmoe3HF035a6Wllb6e6PzcTkvYrRftLdivr2OBpN2c7ED9nDoL1q7MdDv4rLp9vJaGbi8nHBeY3SBysj30ZkibcgMW/UrVdns6CYhKL5lMYmxsDAAk3koGgSyB3q4ZgIR5nNgZz248UdFwr+pOcWX73NLftysZYLqW3F5mpj0lJ0CPBZgWmmQDaHxwXmjFzWfk9ygMAescZE6H3uyE96UBoPcXcEpYUwDbyy01dkRj2s+1s4A8n1TzYghNgsKfLBPHgrH8UqkkSqXVaiGdTovHn8vlAEzRznzHCdcAE4cZ2nQqkdQOXpNzjLktendIu3yj98/KH85T7ZTwGNknzmeulcXy+GlsMCymHSftoHEtAZC9ZJgQyDex0rBh2aKutCFTRkNtseaXnt9z9eztenBHfc1x7iQL54IFef5acdODsXtlO6I6dPmPFm52z55CkpnqTtHM+h5cpLqMcLZ2dPJ0tLDTg243AjiJ2WYnJ54WztFoFJOTkygWi/Lij0qlgkAgIIqfVn+tVsOmTZsswoSx/mw2i2AwKDvu6ck1Pj7uqGem+5MKXzMLsyka+/+dDDV+rg03jgcpWifnlN8/vXWsLitkTF9vxENmhc9JQUwPiFSyrm02xlhKNvW2xvSQKOidKHHSY2KPZ852/lyvaxdcXO9O74hnvy8NVwBi5HLN9vX1IRaL4cUXXxRjSr/hMxKJyAuN+L4OxpjZR2QSF2M/D90OzqFMJiOUOJUjN/ShEUiWlnk6eky1ocq8By0TqtWqJAYvhgFA40PT5vxhQmY2mxXFzuejoUBjhmsamF5LXNtsH42IxWgD7zebgczz7ONo/0zrlNnOta/F+TIz88721wrbXnevrXg7hc/j+jr6uKau+JveKherkxQ5n4WxblqB+h52D6bT8U7ei32wOAnsiUz6HCfapBcQvSduQcqSGY/HI8YAY/zcvINZybSaA4GAxPu3bNki8X7WO3P3PSfHhb+58LWxpeee9t7t19BGV6cwjDbwPB7PjEStbkDFz/v5/X5JwgJm5oLUajUMDQ1JqEUnUJJuZjKaFnaMY1KJJRIJCfHYQwROwZ7AttAx1+vEbiTr9bRYtD8w/ezj4+OS9KqzyPP5PPr6+lAoFNBuT2XGb968GX19fZITUCqVsG3bNtkrolarIZPJyJsPdQa608/NOVSv1zEwMGB5fW8ul0MgEMDg4KCEghiyoSJPpVIYHx+3rA+vd+rNjLFYzBIG5HF7cq+TxhnLWEnb690f/X6/bDrE+c55wkRAtoPGcLFYRDQahcfjmfFiLV1Rshjg2rZn/OvP7eMIzJ4IaIdurz15fj7e/4K3aqKA7gRN0eqGaKqcx/T1OhkLNAZ0kkknod9NOzSd3closd/PrlRma4f9mvY4sNMMBj32drstr+jkqz51e/gWO9J4tVoNIyMjsnkMvYmRkRGk02kp6wMg4QJdAtZt7KyTArfHlHU7dVvm2jedqGgqZ6fDLwCkxC+dTstrYsm00GDmS1jo4XM7We7JkMvl0Nvba3n2er0uW7kaY4Q1YI13IpGQkihNCTrRLvtYbK/9wPaF1/aMX6eNlk7359bRvDeZlnw+LyV0VHik+vVaoXIql8vYvHmzrD17SSoNcScVpfbI2+02SqXSjG2HPR6PeOuamWXlyCuvvIJ6vY6enh5JOuX6Z1kfc4S4ZbCuJnLac+b1aMCwGoayZXBwEGNjYyIbaIjE43FR8GQ1dOWZDhczl8Au851uA9f6XGRUp/Wyo76lkmepo55jOldiR+hK+WuqTgsHbYnMJizmIjz0fTp5mE4tKHaWvQ2d2rGj553tuI6fdVJs3UCPg65n1xtccCHbt8ttNBpCXTLWzm0zjTEYGxtDOByW9xFQAdkzv7uFvR9mC73MpsjZD52O2++h+4tGjFNziYKItD4VMBkZxme5EyOpWYa1GPNkrTPP18ZiOByWPAGyAnxJE3M+ON+c3IrVnncxW/8TnQTbbOtb/7+YHr++B8eeSa9cL9lsFsYYeeET50ckEsHmzZstjNHY2JiwBgBkXekQyWK0R69vGgCcc8xd4Ct8meDr9Xpl7wzOu4mJCZkj3NeAG+QA0/v6M0xLpWr3Up2Az+dDuVy2bLcNQJg5rifAyh41m015xbVWgHrus5+Y58T8DSdklwb7nnkhGp30SSe2eD73mgtTMBsWHPPnzey7o9kX8mzxCnuMf3vnz9Vw6LYdOs7oZDvm+hwLBe/PGCMAy5a2tHZ1Jq8x0/Xb3FZX7+2vk3x0BjPvpd9/4KQA0O3h350+79S/nY5v7/tOGV8aVPQ6r4JCiEpZ7/pHz4QvsWKGP2uXWQaot6FlCSeZG10G6PF4pMyQP055aTsyvLfXl9s7fy5sgdMgC8lcH64BAGLUkl7mWNKrZE4C98CgRwxY9/HgfZyeZ1T8zFWpVqti3EciEaHJWR7Hecg2k/4HIAYE1wOdAM417RgBsLTNSVD+0DDW+THc1Ipt1ufocr52u20ZN1YHsJ1cH61Wy/J2QifbQ+M/FAptN7dgNuZYYy7PpTcUms/3gC48f96Y2cd269Ypj9bjmd65rlKpdH3NTuD1ddyfcNIj5MRg/Epbgt2CClsnj+lSGeY1ANP0FzAdx9VZtroMzefzoVAoSGkgLeXFLGUiOi1Mu9K2n7M9ZkBDn+ck9U9Di32jvW9u0KP3WjDGiLLW/cns7FKpJPFcZj7HYjGhdan8eS7DPBRALP3rFos1xrNhMY0ArnHOHZaWcu7TK65Wq9Lv9OK5RvSmR1Q4XEfb2/zIqefnWmeITytpzjEqTSpLYLo6QFP3mqHQ++Hrd5TQQNCy0UnFSdnI7Ym5nS+TWZlkyXdaUNHTKIhEIlLDD0BCk9wBkEYeK8d4T6dBFo67J+p1bpdL25Nv9uez/02dlU6nLUnR89nDYMHKnx4MJyIFnrbmtWLbnrfcqRM0dRMMBpFIJCwlNPYO6aYdFJC6TnQ+7dje/xwo1gmnUilJlJtrjGeu4ILgdpcUYtlsFqFQCMViEbFYzBIX0kqKwoTCkXQ0rW2dhas3SOnWs+mkvKlE2a7tMQHbu579ugTHhsrZqTHQG5Hosj7GH2lQccexyclJpFIpoTopoOixpNNpGGNkIx/GYL1eL2KxmLAvNMrYJuYAOKX8ee25GlcLvX6nvxcDOgNcs2CVSgWpVEoUu95ISSeh8nwa1HoPDL1OnDYA2C9UZswPyefzEievVqtIJpPI5/NYunSpJDHqendg+t0k2uDXNDgVKDfcWswxIV3earUwODgoiXyUm0xiXLFiBYyZetFQNpuVZ0qn0yiVSvB6vUilUggGg8hkMmKw6TLanp4e2bRpMUIXfPET80rI8lFO2h2+HTHFWk9QfoRCIfT29mL//ffH008/bdkca66Yl/LXD8jtJIvFogyajqVyotm/b2+4bhitFg6W3+8XARaPx8U70lTcQqDv6fP5kEgkAEBeKEN6m4kbOqGN39VJFbS4ZmsHX1ZDI4bxRS1MugUFErN0uW0tvUJSZNzqUjMc9DK1EuHfzB7nMe3x8LtOxDTtioVjM5uhN5sxMNti5nGdbU8l7PRbyvTrYlmep1/yQ/q/VqtJ/J4Ll0KaO81xznM9xONxS5IfaVq+eY9/c145Vcusx8U+Jt1efzajzGnBrKGdFZ2Eq0MzpM3p8fI7+vtUpqR4qfydzuvRz62T9yYnJ5FMJmUe0NOtVCry8q1oNCqJi5TN3MBH5/9Q2Xo80y+aqlarmJycFCOHe4c4adRwnIvFIoCpUNiyZctkPTCUxbLc3t5e+Hw+bNu2DWNjY1KC2NfXh56eHimt5bsIuC64xjwejzhCACxvpuwWgUAAAwMDGBoagt/vx9atWy2sEnUX283fei3Z1xrHlrKCHn9vby+Gh4fx2muvSfiHOSpzwbxL/YBpr5wlFPptQozLkBHQniUbRS9SU1VUmpy89Fx0Nie3ouyWLtcdTCtKC19awRSyOq9BKxAqeR070u0gaxGLxZBIJIQS4h7TnAxOKR5NZ3ZKZKGlrCsnNJXHuKbuH7tXoOuEnRLO9utoylErge2FZLbHomh6H5je/Y7zzEnhTKOJnj3DYnzTItvBezOXQpcFMdTCNy1Go1FhpXQCIMeRCYZcT319fdi8ebOFDXACmskgumEC7MJPM2WvF+xGAADxILWhqJ/TbrDbk3iBxYn129Fut2UrbzpblLfMCaGxznHj71QqZXlOlgByvpVKJcvbR2u1mjBPXJdOwev1Ih6PY//995dcpWXLlmHlypVYunQpyuWy9OPzzz+PiYkJeZvhwMAAjjrqKDzyyCOyEVMwGJSNl2KxGA488ED09/cjm83i0UcfRaPRsGwMBHTPAHBuhEIhLF26VAyWvffeG8ViERMTE7ImtQzVOpXsEtc311YgEEB/fz+8Xi+SySR233137LPPPqjVakin0xgcHLQY+cw/2REWvL1vuVzGn//8Z8uEAjDjb/2bnTRbhqXH45FkDe2dsXPsm/B0SzXT2nzqqacs7eBndvq/k7KZrR30BCjMdMxNb7LhlIAgzVQoFFAsFi3Ci3/rZ+Bz6kmmPRwKRT1e2uvQ3ke3SUD2edJqtaQMa3t0f6dwgabW7OfpJC+2nwK/23JFgvFEGi+VSgX9/f3yOel8npNIJIR50cliS5cuFQaKz5xIJGSvCO0JVSoVYQdIB/NZuDlTtzDGWh7lFFtlv1ancVsM2O+t5/uODEn7c9nlnf1vp9FqtVAsFrFlyxYEAgF5aRez/eko6aoSOhra0eGz08AvFouSW8VKCDopNFI3btwob5Z0AuzvRqOBbdu2YXx8HHvuuSdGRkbw5z//Gb29vViyZAm8Xi/Gx8eFdSwWi8jlcojFYpiYmIDH45EtwfVbSHfbbTf8/ve/F6M8m83Kmw6pMDux1PMFx3t8fBzf+973AEyHVLUDZTcOCT6fnV0CYHkZkc/nw4YNG/DYY48Ju8EwMo2/ubZlwTF/0ovzneTdUPWLsaC0opkPFurlLOS7cwWVMe9np1N1aML+TBp2ZWkXalopO13DzHssxKCYi/Cdi+B2AmSEWCrF3f60N04hrF8AQ0ufwoKGGgU7vTR64WQYtOGj31HhZD3zYiq01/Me27vvzrr/fMAxzufz2LRpk7BIeh8R/UZH0uA618eeGMaQHp0THtM7bVJ5OrkjJjf3GRoawr777os999wTy5cvl5wiyrSVK1eKU6P3sGg0Gshms1ixYoXky3g8U3k8yWQSBx98MF5++WUkEgn09/cjk8ng2WefxR577IFSqWR5gVG3Y89x4Vbp8/3ubMcpK+ZixM+nDV1l+7+eC+X18AIWE6/XPbbHqjh9r8WOyS42nO4TYJpB0NumaiOK46NDL8xS5nle7/RrSmndc8teHSLQewbobaPJ1nAXx78GheZi7uA8qtVqllAeYM1J6pSfQdB4nM1g1sakNsR1vN+JecX8g8HBQZx00klIJBIIBAIol8vIZDLIZDJoNBrYfffdMTExIQwwveHXXnsN/f39GBwcBDCV+BeNRmW30uXLlyMWi2GPPfbA8PAwnn32WeTzeRx00EF44YUXsG3bthlt7xaL4QwtxnWd2wHExRsCc/V4F/NeTlzHLricZIwWQ+kTjJWyzjoej6Ovr088cZ1cyGRAJh7qncmq1Sqi0ahlS1L+0Asj9U9qUb/ql3XoTKJyAotp7Ol7EK7RMjsYguP8sPdbp1wibbDviPWb7Xt25q9b8LqhUAhHHnkkYrEYJicnMTIygomJCbRaLaxcuVKM356eHlkn7fbUnv5vfvObZQvzeDyOVCqFrVu3ApjaIOhNb3oTli1bBmOMVELsscceMxLrdjW4yt/FGxJOxU+3lyuwGIs+m81i69at2LZtm1TBcO94ekysBqDnzj35mbSnBbpOsmPCX6VSweTkpCTHGjOVqPnaa6+hVCrJ/ScnJx2LzQKvnzLennJyMQ3OCzu2N687zf1OfW1nARYrPNZqtZBMJpFKpXDfffdhy5YtOPzww2X+tlotbN68GSeddBJ+//vf4xe/+AWi0Sh8Ph/GxsaknO7AAw/ExMQEnnzySRQKBey9997427/9W2G+fv/732PTpk0Ih8NiQBQKBYmX74rwmF3R5HHhwoULFy52Ybx+NTUuXLhw4cKFizcEXOXvwoULFy5c7GJwlb8LFy5cuHCxi8FV/i5cuHDhwsUuBlf5u3DhwoULF7sYXOXvwoULFy5c7GJwlb8LFy5cuHCxi8FV/i5cuHDhwsUuBlf5u3DhwoULF7sYXOXvwoULFy5c7GJwlb8LFy5cuHCxi8FV/i5cuHDhwsUuBlf5u3DhwoULF7sYXOXvwoULFy5c7GJwlb8LFy5cuHCxi8FV/i5cuHDhwsUuBlf5u3DhwoULF7sYXOXvwoULFy5c7GJwlb8LFy5cuHCxi8FV/i5cuHDhwsUuBlf5u3DhwoULF7sYXOXvwoULFy5c7GJwlb8LFy5cuHCxi8FV/i7e0FixYgXOP//8HZ7n8XhwzTXXLPrzvNGxfv16nHzyyUilUvB4PPj+97+/sx/pDYvzzz8fK1as2NmP4cLFToGr/BcJGzduxGWXXYY3velNiEajiEajWLVqFS699FL86U9/2tmP5yh++MMfuor3DYK1a9fi6aefxhe+8AXcfffdOPTQQ3f2I7lYZDzwwANYs2YNli5dilAohGXLluHMM8/EM888s7MfzcUbGB5jjNnZD/G/DT/4wQ/wD//wD/D7/Xjf+96Hgw46CF6vF8899xzuv/9+vPLKK9i4cSOWL1++sx/VEVx22WX42te+hsWYSitWrMBxxx2Hb33rW9s9r1qtwu/3w+/3O/4Mfy2oVCqIRqP4p3/6J1x77bU7+3He8Gg0Gmi32wiFQjv7UbrC5z73OfzlL3/BwQcfjP7+fmzbtg3/9//+X2zduhWPPfYYDjrooJ39iC7egNh1JeUiYcOGDTj77LOxfPly/OIXv8Dw8LDl8xtuuAG33norvN43LulSKpUQi8V29mPMC+FweGc/wk7H2NgYACCdTjt2zb/GubAjsE2BQGBnP4ojuOqqq2Yc++AHP4hly5bhtttuw+23374TnsrFGx1vXA30V4obb7wRpVIJd9555wzFDwB+vx8f+chHsPvuu1uOP/fcczjzzDPR29uLcDiMQw89FA899JDlnG9961vweDz47W9/i4997GMYGBhALBbDGWecIYJf40c/+hGOPvpoxGIxJBIJnHrqqfjzn/9sOef8889HPB7Hhg0bcMoppyCRSOB973sfAOA3v/kN3vOe92CPPfZAKBTC7rvvjiuuuAKVSsXy/a997WsApuLu/CHa7Ta+8pWv4IADDkA4HMbQ0BAuvvhiZDIZy3MYY3Dttddi2bJliEajePvb3z7jWbcHe8z/mmuugcfjwQsvvID3v//9SKVSGBgYwJVXXgljDF599VW8613vQjKZxJIlS3DTTTdZrlev13HVVVdh9erVSKVSiMViOProo/Hwww/PuPfExATOPfdcJJNJpNNprF27Fk899RQ8Hs8MxmIu49xoNPDZz34W++67L8LhMPr6+nDUUUfhZz/72aztv+aaa4RJ+uQnPwmPx2OJZz/xxBN45zvfiWQyiXg8jhNOOAG/+93vLNfg/PrVr36FD3/4wxgcHMSyZcu21+2o1Wq4+uqrsc8++8gc+dSnPoVarSbnrF27FuFwGM8++6zlu2vWrEFPTw+2bNliuf+vf/1rXHzxxejr60MymcR55503Y74A3c/vTjH/uc7XFStW4LTTTsMjjzyCww8/HOFwGHvttRfuuuuuGc+ZzWZxxRVXYMWKFULLn3feeRgfH59XP84Hg4ODiEajyGazC/q+i10AxoWjWLp0qdlnn33m9Z1nnnnGpFIps2rVKnPDDTeYW265xRxzzDHG4/GY+++/X8678847DQBz8MEHm+OPP97cfPPN5uMf/7jx+XzmrLPOslzzrrvuMh6Px7zjHe8wN998s7nhhhvMihUrTDqdNhs3bpTz1q5da0KhkNl7773N2rVrze23327uuusuY4wxl19+uTnllFPMddddZ+644w7zgQ98wPh8PnPmmWfK9x999FFz0kknGQDm7rvvlh/igx/8oPH7/WbdunXm9ttvN5/+9KdNLBYzhx12mKnX63LeP//zPxsA5pRTTjG33HKLufDCC83SpUtNf3+/Wbt27Q77EIC5+uqr5f+rr77aADB/8zd/Y8455xxz6623mlNPPdUAMF/60pfMypUrzSWXXGJuvfVWc+SRRxoA5le/+pV8f2xszAwPD5uPfexj5rbbbjM33nijWblypQkEAuaJJ56Q81qtlnnb295mfD6fueyyy8wtt9xiTjrpJHPQQQcZAObOO++c9zh/5jOfMR6Px6xbt8584xvfMDfddJM555xzzBe/+MVZ2//UU0+ZL3/5ywaAOeecc8zdd99tHnjgAblvLBYzw8PD5vOf/7z54he/aPbcc08TCoXM7373O7kG59eqVavMsccea26++ebt3rPVapmTTz7ZRKNR89GPftTccccd5rLLLjN+v9+8613vkvMymYxZtmyZOeyww0yz2TTGGHP77bfLnLHf/8ADDzRHH320+bd/+zdz6aWXGq/Xa4455hjTbrflXCfm99q1a83y5cstbZrrfF2+fLlZuXKlGRoaMp/5zGfMLbfcYg455BDj8XjMM888I+cVCgXz5je/2fh8PrNu3Tpz2223mc9//vPmsMMOk3k0137cETKZjBkdHTV/+tOfzIUXXmgAmK9//etz/r6LXQuu8ncQuVzOADCnn376jM8ymYwZGxuTn3K5LJ+dcMIJ5sADDzTValWOtdttc8QRR5h9991XjlE4nnjiiRZBeMUVVxifz2ey2awxZkrgpNNps27dOsszbNu2zaRSKcvxtWvXGgDmH//xH2c8s35G4vrrrzcej8e88sorcuzSSy81nezI3/zmNwaA+c53vmM5/uMf/9hyfHR01ASDQXPqqada2vWZz3zGAOhK+V900UVyrNlsmmXLlhmPx2NRaplMxkQiEct9ms2mqdVqlntkMhkzNDRkLrzwQjl23333GQDmK1/5ihxrtVrm+OOPn6H85zrOBx10kDn11FN32GY7Nm7caACYf/mXf7EcP/30000wGDQbNmyQY1u2bDGJRMIcc8wxcozz66ijjhIlvT3cfffdxuv1mt/85jeW41Tsv/3tb+XYT37yEwPAXHvtteall14y8Xh8xjrh/VevXm1RtDfeeKMBYB588EFjjHPz26785zpfjZlS/gDMr3/9azk2OjpqQqGQ+fjHPy7HrrrqKgPAYtwRnOvz6cftYeXKlQaAAWDi8bj553/+Z9Nqteb0XRe7Hlza30Hk83kAQDwen/HZcccdh4GBAfkhVT45OYlf/vKXOOuss1AoFDA+Po7x8XFMTExgzZo1WL9+PTZv3my51kUXXWSh1o8++mi0Wi288sorAICf/exnyGazOOecc+R64+Pj8Pl8eOtb39qRur7kkktmHItEIvJ3qVTC+Pg4jjjiCBhj8MQTT+ywP773ve8hlUrhpJNOsjzH6tWrEY/H5Tl+/vOfo16v4/LLL7e066Mf/egO77EjfPCDH5S/fT4fDj30UBhj8IEPfECOp9NprFy5Ei+99JLl3GAwCGCKCp6cnESz2cShhx6KP/7xj3Lej3/8YwQCAaxbt06Oeb1eXHrppZbnmM84p9Np/PnPf8b69eu7bn+r1cJPf/pTnH766dhrr73k+PDwMN773vfikUcekXlLrFu3Dj6fb4fX/t73vof9998f++23n2V8jz/+eACwzLOTTz4ZF198MT73uc/h7//+7xEOh3HHHXd0vO5FF11kicdfcskl8Pv9+OEPfwjAufndqT1zma/EqlWrcPTRR8v/AwMDM+bRfffdh4MOOghnnHHGjPtxrs+nH7eHO++8Ez/+8Y9x6623Yv/990elUkGr1ZrTd13senAT/hxEIpEAABSLxRmf3XHHHSgUChgZGcH73/9+Of7iiy/CGIMrr7wSV155Zcfrjo6OYrfddpP/99hjD8vnPT09ACBxSSoNCg87ksmk5X+/398xtrtp0yZcddVVeOihh2bEPHO5XMdra6xfvx65XA6Dg4MdPx8dHQUAMVr23Xdfy+cDAwPStoXC3lepVArhcBj9/f0zjk9MTFiOffvb38ZNN92E5557Do1GQ47vueee8vcrr7yC4eFhRKNRy3f32Wcfy//zGefPfe5zeNe73oU3velNePOb34x3vOMdOPfcc/GWt7xl7g3/H4yNjaFcLmPlypUzPtt///3Rbrfx6quv4oADDujYvu1h/fr1ePbZZzEwMDBrezT+9V//FQ8++CCefPJJ3HPPPbPOC/s8iMfjGB4exssvvyz3Bbqf353aM5f5StjnFjC1FvVa2bBhA9797nfv8L7z6cfZ8La3vU3+Pvvss7H//vsDmOp3Fy7scJW/g0ilUhgeHu5YX/vWt74VAESAEe12GwDwiU98AmvWrOl4Xbsimc0rM/9Tasdr3n333ViyZMmM8+zlcKFQaEb1QavVwkknnYTJyUl8+tOfxn777YdYLIbNmzfj/PPPl3tsD+12G4ODg/jOd77T8fPZhJ2T6NRXO+o/APj3f/93nH/++Tj99NPxyU9+EoODg/D5fLj++uuxYcOGeT/HfMb5mGOOwYYNG/Dggw/ipz/9Kb75zW/iy1/+Mm6//XYLk7FY0IzP9tBut3HggQfiS1/6UsfP7UmtTzzxhCiyp59+Guecc86Cns+J+T3bdeczX+cyj+aC+fbjXNDT04Pjjz8e3/nOd1zl76IjXOXvME499VR885vfxO9//3scfvjhOzyfVGwgEMCJJ57oyDPsvffeAKYyfhd6zaeffhovvPACvv3tb+O8886T450yzjVVb3+On//85zjyyCO3q1CYpb5+/XoLNT02NtYxy/v1wL333ou99toL999/v6V9V199teW85cuX4+GHH0a5XLZ4/y+++KLlvPmOc29vLy644AJccMEFKBaLOOaYY3DNNdfMW/kPDAwgGo3i+eefn/HZc889B6/XuyDlAkyN71NPPYUTTjhh1jlAlEolXHDBBVi1ahWOOOII3HjjjTjjjDNw2GGHzTh3/fr1ePvb3y7/F4tFbN26FaeccorcF+hufs/WnrnM1/lec0eb7cynH+eDSqUyJ4bOxa4JN+bvMD71qU8hGo3iwgsvxMjIyIzP7V7B4OAgjjvuONxxxx3YunXrjPM7lfDtCGvWrEEymcR1111noavnc016Nfp5jTH46le/OuNc1oHby4rOOusstFotfP7zn5/xnWazKeefeOKJCAQCuPnmmy33+8pXvrLD51wsdGr/f//3f+Oxxx6znLdmzRo0Gg184xvfkGPtdltyOoj5jLM9/BCPx7HPPvssqOzL5/Ph5JNPxoMPPmhhnUZGRnDPPffgqKOOmkGTzxVnnXUWNm/ebGk7UalUUCqV5P9Pf/rT2LRpE7797W/jS1/6ElasWIG1a9d2bNPXv/51y7y97bbb0Gw28c53vhOAM/N7tvbMZb7OB+9+97vx1FNP4YEHHpjxGefWfPqxEzqFBV5++WX84he/cHd4dDErXM/fYey777645557cM4552DlypWyw58xBhs3bsQ999wDr9driUF+7Wtfw1FHHYUDDzwQ69atw1577YWRkRE89thjeO211/DUU0/N6xmSySRuu+02nHvuuTjkkENw9tlnY2BgAJs2bcJ//dd/4cgjj8Qtt9yy3Wvst99+2HvvvfGJT3wCmzdvRjKZxH333dfRE1+9ejUA4CMf+QjWrFkDn8+Hs88+G8ceeywuvvhiXH/99XjyySdx8sknIxAIYP369fje976Hr371qzjzzDMxMDCAT3ziE7j++utx2mmn4ZRTTsETTzyBH/3oRzNi868XTjvtNNx///0444wzcOqpp2Ljxo24/fbbsWrVKktOx+mnn47DDz8cH//4x/Hiiy9iv/32w0MPPYTJyUkAVlZkruO8atUqHHfccVi9ejV6e3vx+OOP495778Vll122oLZce+21+NnPfoajjjoKH/7wh+H3+3HHHXegVqvhxhtvXHAfnXvuufjud7+LD33oQ3j44Ydx5JFHotVq4bnnnsN3v/td/OQnP8Ghhx6KX/7yl7j11ltx9dVX45BDDgEwlZx23HHH4corr5zxDPV6HSeccALOOussPP/887j11ltx1FFH4e/+7u8AODO/O2Gu83U++OQnP4l7770X73nPe3DhhRdi9erVmJycxEMPPYTbb78dBx100Jz7cTYceOCBOOGEE/A3f/M36Onpwfr16/F//s//QaPRwBe/+MV594OLXQQ7o8RgV8CLL75oLrnkErPPPvuYcDhsIpGI2W+//cyHPvQh8+STT844f8OGDea8884zS5YsMYFAwOy2227mtNNOM/fee6+cw1KoP/zhD5bvPvzwwwaAefjhh2ccX7NmjUmlUiYcDpu9997bnH/++ebxxx+Xc9auXWtisVjHNvzlL38xJ554oonH46a/v9+sW7fOPPXUUzNK2JrNprn88svNwMCA8Xg8M8r+vv71r5vVq1ebSCRiEomEOfDAA82nPvUps2XLFjmn1WqZz372s2Z4eNhEIhFz3HHHmWeeecYsX768q1K/sbExy3mztffYY481BxxwgPzfbrfNddddZ5YvX25CoZA5+OCDzQ9+8IOOteFjY2Pmve99r0kkEiaVSpnzzz/f/Pa3vzUAzH/+539azp3LOF977bXm8MMPN+l0WubNF77wBUv5WyfMVupnjDF//OMfzZo1a0w8HjfRaNS8/e1vN48++qjlnNnm1/ZQr9fNDTfcYA444AATCoVMT0+PWb16tfnsZz9rcrmcyefzZvny5eaQQw4xjUbD8t0rrrjCeL1e89hjj1nu/6tf/cpcdNFFpqenx8TjcfO+973PTExMzLh3t/O701gaM7f5unz58o7lmMcee6w59thjLccmJibMZZddZnbbbTcTDAbNsmXLzNq1a834+Pic+3F7uPrqq82hhx5qenp6jN/vN0uXLjVnn322+dOf/rTd77nYteHu7e/CxSLg+9//Ps444ww88sgjOPLII3f24/xV4Fvf+hYuuOAC/OEPf3DpahcuFhluzN+Fiy6htzsGpiolbr75ZiSTSaG5Xbhw4eKNBDfm78JFl7j88stRqVTwtre9DbVaDffffz8effRRXHfddY5ljbtw4cKFk3CVvwsXXeL444/HTTfdhB/84AeoVqvYZ599cPPNNy84Qc+FCxcuFhtuzN+FCxcuXLjYxeDG/F24cOHChYtdDK7yd+HChQsXLnYxzDnm7+S2k05ivlGL/y3tAKba4vP5MDQ0hPe85z246KKL0NPTg2AwiEqlgnA4jHA4DL/fj3a7Da/XKzuVhUIhxONxhEIhTE5OolQqoV6vI5lMIhaLIRQKodVqIZ/Po7e3Fx6PBx6PB61WC8ViEa1WC7FYDOVyGZVKBYVCARMTE8hmszjttNPm3Y43IhY6JnNpD6+9GG3v9Ny7+jp5I2JXHxOfz4fh4WGcccYZ+MAHPoChoSHUajV4PB4EAgGEw2H4fD40Gg0Eg0GUy2UUi0WEQiGEQiF4PB4UCgXU63V4vV6Ew2EEAgF4PB54vV6Uy2UsWbIE7XYbfr8ffr8fzWYT+XwesVgM4+PjMMag3W6jVCrhtddew8knnzzvdrwRMZcxcRP+/sphjEGj0UA2m8XmzZtRKpVgjEFPTw/y+Ty8Xi/8fj88Ho8YAJlMBoFAQF54UqlUUK/XUSqVMDY2Jq9TrdVqSKfTspBarRba7TbK5TICgYC8ejQQCMDr9aLRaKBarc67DVSY/PF6vfB4PBYFqf/nMWOMLD5jjPw/28Tv9BmPNZvNOb2saC5tcfI8wt72Tp8vliDaWQLOTUf63w1jDCqVCrZt2yZvvSwUCkilUiiVSvD5fAiFQmg2m6jVagiHwygWi/B6vfB6vajX6ygUCjDGyKuL+SruQCCAeDyOarWKRqMh23U3Gg00m02RXzQYaFjsSnCV//8SlMtlTExMIBKJIBwOI5/Pi0WslX+9XketVpuh6BqNBkqlElqtlhgGwNQb0vieeSrJarWKSCQiLEC9XhfluxAFGo/HkUql0N/fj2XLlmHvvffG/vvvL0YGn8Pn84kiqtfrAKb20edPo9GQ9rbbbYtA8Hg8CIfDwl6wH8LhMNrtNgqFgngAGzdunLGH/1zxeiis2e7h5L3pmZEhGhgYwJ577olqtQq/3y8C2Ov1iuHRbDalf/UxCmr9HY6jx+MRlomC2e/3o9VqoVKpoNlsotFooFKpyDx08b8HxhjUajVks1lxVshCGmNQKpVkXgSDQeRyuRnrnQqeDEE0GhUvn7KO847HjTHI5/PIZrMyZxfy7oy/ZrjKfw6YzZu0e0TaU309vRZjDOr1OsrlMoLBIICpF5HU63X4fD5RyqTUuFiazSZarRaCwaB47pVKBT6fD61WS6zuQqEgCtQYg2AwKAsoEAjIvWgYzBfBYBDpdBq777473vzmN+Nv//Zvcfjhh8tiBqaVP9tLQ4WKBpjabCcYDIpCpzcfDAZhjLG8da/RaKBcLiOZTKJarWJyclJ+Dw0NLfjlMMDcPeUdeesLnV9OzD0q/3g8jj333BOHHnoojjjiCFSrVUSjURGkVP4U4o1GA8YYeL1e+Hw+FAoF+P1+OQeAfObz+RAIBCxeWaPRQDgcRqVSEW+sVCohl8vhiSee6Lpdun2d/uaYzIVdsfdzJ+bJZS+2D2MMqtUqCoWCGIpkGVutFprNJsrlsqxj0vzNZhPNZtPCDNRqNQSDQdTrdZEX5XJZ2EQaBpRdZE0pK1zl7yC0dW8/zkXxei8Uv98vlFA0GhXah5ahhtfrtXiy/JyWp/1zCg16npqS5vkAsHXrVuRyOVSrVUeoZlqttVpNFk84HJYFQqFaKBQQjUZlAZHGD4VCCIfDQp+1Wi0R0K1WC9VqFaFQCD6fT/qvVCohHA4jFotJjkEul0M+n5/387PPotEoent70dvbi1AohGQyCZ/PZxkbevQ0Zvg5lVU0GhVPUiv/druNQCAAY4wIhng8jkQigVKpBI/Hg1wuh0ajgaGhIey5554LGotoNCoGSCgUEuai07vfOd/nMwfYF5xfOvzBYxMTEzLGC11THJNEIoE3velNOProo3HsscfC4/HIuLDvaXxWq1ULXcsQk9frRSQSEaFtj+nSWPB6vWi1WohGoyiVSqL0C4UCJicnF/z2QTtIDbM/acQQgUBAYsTaEKDCaDabci5lAQCZl3qO0jilUfR6guuCbdPzhX1tl7/tdvt1fc5Wq4VyuSxrr1wuo9FoyFyp1WqSYxQKhVCtVlGtVkVRc6zq9bowAZVKReal1+tFKBSC3+8Xp4AGJg0CfZ9dCYui/DnhqCw01UchXK/XZaJppaM9hMVAX18fhoeH8bd/+7c4+OCDse+++2L33XdHNBpFNBq1KPBQKIR8Pi8Kg8KAEyUSiaBUKoliJ12eSqVgjBHBRuVMJXTdddfhv/7rv/DCCy+gUql0bQBo6mx0dBTtdhuVSgXFYhGFQgHVahVerxfFYhHlchk+n0+s31AohGg0imq1ikAgIM9SKpWQz+dRKBRQKpWwZMkSJBIJ1Go18YoHBgaErmUflMvleT+/ppgZbsjn8/B4PBLGIIXcaDSEyiNF3Gg0UCwWxYskpU/lR0XEcAWVfzAYRD6fF8EciUTQaDTEGFoI9ttvPyxbtgx77bUX9thjDyxZsgTxeFx2+qOC9vl8aLfbFkFGD5lGHM/lmPj9fvFeNCvC8+g5/cd//AceeeQRvPrqqws2AKigBwcHsdtuu6G/vx/FYhG9vb0Wpc95RDZJx2Pr9boY1n6/H9VqFa1WS+QCMMXWBAIBtFoteDwexGIxGGMQDodRq9XQ19eHZDKJQCCAvfbaa0FjotvExLDh4WEAQDgcRjKZtCiIZDKJSCSC/v5+JBIJMRqBqfDayMiIyALmuTB0ROXE9UelNjk5KaGqxYTOmwkGgzKX9Tg0m01xAjj3qRQrlYoYLp0cNKfB8E4mk8HY2JgwADT+SqWSzBs6MXyNM9tH+aP1Tb1ex8TEBEKhEHp6emQNZjIZ1Go1DA8Py3jQMer0xtLFwo7YwdfFEXbyYpx42lvT8T1aYc1mUwaKE4/Wm33iOY1WqyXCnxaf3+9HJBKxZLSTyqYQpgInVQ5AKG8AFoHI929HIhE5Ti9wdHTU0jfdQsfaa7UaRkZG0Nvbi9HRUQkFlEoleXbGU9lGYGoRUaFyYVFoUFkaYzA5OSmeQywWw8TEBHw+nyzSQqHQVVyWyrBYLIpX39vbi1qtJvvnh8NhNBoNjI2NIZVKoVaroVwuS8jD4/GIgUNBUC6XxTvm/OJYN5tNxGIxuT9/FkoBkmmgwqjVakgkEjLeVJLa649EIpYwBY0wVlNoFgkAqtWqGETA1Bwol8sIhUIWNqQb6LVQqVSQz+dl3tRqNelPrg+v14utW7cikUiIN0UvbnBwECMjI6J8mOhFhgmwhnWKxSJisZiEomgU5HK5rtqkQZnDaphoNIpkMolEIiHjQw9UG6YMf8ViMclEr1arkjlOpcpwWjQaRaVSWfSkSS1jadgGg0HpV+1UxeNxS78CEG8YmJpfnIuLqYS03Mrn8yIbJyYmpIIon8/L8wQCAckDoQwOBoPi3NCApKwl08ncIYaZUqkURkdHZX3SUH09lb8dnRKaicUaA8eUv/b2KehIeWprlIudAo6NpNDSAnoxWAAKWQAWYUMBTAuTHlM8HhcqiV4LlT69TWA67k5PjcYFY+tsh51i7Ba6/G58fBz9/f2oVCoolUrw+/2i/Nmu8fFxBINBNBoNEVC0gHV+gM/nE1o2HA5j27ZtiEQiUh7IEkCfzychB9J28wU9P447ME3HTkxMWOLKZDPC4TCy2awoIRqPY2NjIhCoXNjf9CbZb+12W2L+pK2ZF7GQdmjQS/f5fMKqUKnoxMlAIIBisWgJFXEcGK/ULATPo0DjuOo2OqH8AViMJL0W8vm8CFP+VKtVxGIxVKtV5HI5Yb7a7Ta2bNkiHicNBc6bVColSYR+vx/5fB7pdBq1Wk0YQj2/nADDQ+FwGIlEAul0Gul0GslkUpiBSCQirFgikRB2zD6nyBhMTk5icHBQjDWyF5xXiw3KV7KPVPpknOiEkdGkAcnxYN/zO6TRF9sZ41weGxsT5V8ul1Gr1YR15Njn83n4/X5xZHRVkJYbZD3o1FF2xWIxxONxFAoFxGIxMaBpBIyOji5KG+2YryG4WDlkjih/ncDDhpEWI92kS7ji8bjQfVReeiBpxS3WxGO9O7001rprIUvPjQocgFic9Cr1NTRjwPAFM+c5waPRqOM5DpqyK5VKGB0dFYHNGCwtZ3piuVzOYpDwXI4HAFH6TPBjbC2bzSKRSACYCg0wDlutVpHNZhckoNkGtqPRaFhoYlLE/Nzj8UhJI+eL3++XtlKoAdPzkO0s0lKKjwAAbcRJREFUFosIBoNSrdBoNCSHgUqmVqt19UIe3YeRSEQUP/ucRiaVvO4zKhWGLzgGbCfXA9cGhTkNCxo1Tq0ZLVhJx7KNOpOa48eYPuUBjTW2lTIhGAyKgcq8k1gshmaziS1btoh3SqaEiahOgd5+X18f4vE4gsGgyKGenh6Uy2UsX74cyWTSQpuzvJUKhuG0/v5+WTP0+Blmo1OwWKD8DYVCYnDS+AAg7AaNA4/Hg76+PmSzWUstPdcZABk/GgGLZQDQaSoWixgZGRGZq5U/54EO9+lQqXYSKfsokznXmIdDZiqZTCKVSomBmc1muzb454IdJfjqpFI7E+B0/3et/O0evxa0tObthgETyTSoJOnFcECdjjtpZoLPp5WKnkR8ZgpnTRVT4AIQKxSYVlDME9B9RGrWKcqfoDIhG0EhRvqc3lOlUhErV+dXsE30Wvh8sVgMtVoN8XjcEjMslUpiEFBoNJtN2S9goc9PcDECEEtfn0sDQT8/jQVd10sFpQ1Kjr/eOCQQCIihAcAyj+cLzZ5Q2FKI6mQxraR1gqW+t1aY2mjg9/VaY/vo9XWrbOwCtd1ui+cVj8dlDrG/mFyqn5N12MVicUZIEICwLBTUbDOpXRoSABzbh4HPG41GkU6nxaun8U5FGAqFMDAwgMHBQUnipHHLElF6jjQ2ueFVIBCQ/JFIJCJGwmIIcPYplZxmIo0xFuXHNcF1TFnEPuE5zDnRodnFCgPouUIFT2VfqVRQqVRkXes5NluiItunq5HIAvBaOpTJMDSN/8WAfS3uyADQfy+mAdC18udE6qT8eYxKVluWekLpxDh6NNoAcHLS2RW/Vu46+QWYjkPy/rpeHoBFOGk6n4qVOQxUThQM9lyIbqGTdSqVigjmSqUiHidrZ2kk6L4lmIQJQIQg+0YbceVyWTbiYGUBFepCKE497mxLLpcToaufi3Q428X5Q/aiWq0KW0EhAEznZyQSCRE2OvFU7wmgvzdfaPZKx1t11re+hzZ6dFKsjqdz3vGZNJPGdaSVJ4V4N9BKnN4Ww2PhcFj6mfdlP+pQF3eIpFGpnQDm2gBAKpWSXIJIJCLzlYyAZn6cgM/nQyKRQCqVEvqffc58hOHhYcRiMaRSKSQSCWG9yFAwgczj8SAajQpDxbwEuze+WJ6/pvI553U+CeWSzm/g50wcpfFJVoAGPNugQ7BOKh9eT++7wRJPhuK4+Rhll91p7KQjaAjr69OQIXvAa1J28RmcxlzGvZOnrz9bLAOgK+VPBa+FDQUChR47nZYyBRgboKl0nb2thRvPd6LROq6svQptAfM8Ul60HilkaS1SsXPR6MmmP2cfMDvb7gF1C2OmkgyZVEUvpN2e3tSnXq9L4pEeA72YqEx12CAUCiGbzYr3wB/GyEijAZBciYU8PwBZ/Hr8OVak6CkUyDJQQHk8Hsle1p60ziOJRCKy+NlOvRcCFa9dKc8XVAisXOA6YEkhjQDOEz4nlS3PoaGoBRnPp2Bn/+gqBjvT1g2YNMq502q1ZEMkzh966mSFaETTYNAlVHy2VquFeDxu2YWSz8xQms7P6ST45wstmzg+fB7uBcG5l0wmZX4Ui0VhtoLBIGKxmKViJBaLoVgsIpFISLyaioXMgpNMnwY9dl3iquUSxyUcDktpq93g5ViRPWPf63wAHZpzGjrbnv1N2aXZAO0AALD8b2eqdCiZsoAbBZFZZPiS7et2ftkx2/rTRrM+Rzu8c7lut/qwK+XPTuWDaE+HMWJazTr7lN6PrkPXlp0WXFqBLtQb09CCUVOR5XIZkUgExhjxIIHp7HIKBtLmtOa5IDSlFovFLOEBZqlSwAQCAcvmJt0IaU4AUqypVEoEGJUkFSZjWnrR02OhgqFQ59jS+OFiZKyU7dPJk9xVcL6wPw+fn33LPmdWfy6Xs7xXgG1g6IKLiLH9er0uFCfnYavVQi6Xk4SzQqEAr9eLWq0mezAsFHwWLbBoZACYQV8yN4P9SGOaeSfa+2YsN51Oo1qtWozkUCiEQqEAYO7vGJgN2qNi3zNUonft0yVZsVgMmUxGDDM+t47t62Qsevo0Mpkw2tfXh4mJCclDYZIh27ZQaKHJHJmenh7Zr4JMUE9Pj6wH5sd4vV7ZEyKdTstaonFMw7mvrw8AMDY2hpGREfh8PvT09Diar6DbQ8+e48T9E4wxUjExMDBgKfvj3OG2tjrh1V6yqQ1lJpg6Tf1TNtFY1Iqfz2NPAtchP2BmmErLMhqblNEsr+Y5eqMyp2Cn72f7nOvU7t13gr3fu2UBFqz8tfeqM8P5kPSQtZVN65NJV/RK+X09AFo5A1Yqpxvo2J72ZKksuQMUJzwTdxgHo9AzZir7mWVknEQ0LngNUvChUAiRSESMABpJTjAaOmZGr5WUK+9vz94ldI6CnkwUePQy9da5wNSCDQaD4hVRUS005s8kH5170W638dprryEajYpxw/mybds2CUmQ6aCw4LjRaGg0GpKJXqlUpKSLmfY0dqjMWG64EHDe6P0JuFZoJGqvmfOAnhfnOcdAezD8rsfjkXnHNUfhzmx1nby5UJACZyyUwpmGEY129vHo6KisFT47E97a7bZsfMTz6RQUCgUkEgkkEgmEQiFJWiXTwzAB80C6aQ8ASx/5/X4sXboUvb29MMZg69at8pz03jmXGDZKp9NoNpsYHx/HSy+9JOsnl8uJh1+v16XqwX5/p0DlT9DR0jlAvb29AKYo/lQqhXg8jqGhIWzZskUqA3K5HFqtFnp6elAqlWRN2MHwk9PUP5+XxjKNAcore6iS3+Nv+/PwGI0XzQRqhpZOD8MlTil/rbdmU+z23zTgO3n129MRmh2dL7pS/lScfDAuZlqJjI0lEgnZCa7RaGDJkiXYsmULCoWCpWyO19TKF4CllKlbcFKQ6uGAM7ubC5nUF0vlSLNqg4dZzJouYhY6vX96O61WS3bFY3KJHuxuwZgpPeFarWahzLQnpuObmkKbLb6kf1PYMPTBBCMKeHqw8wGvrxUJvfhWqyUlfXbKmTkOOi+BrEy5XIbf7xfWQvcJ9yTgTnWRSER2JuRCWugmP7qShIINgBgfdmOLHijbR4MgEolYtjWloOK1Q6GQzGWuQ26ly/7rFjRe6Rk2Gg1MTEzIs1IhsiSRBifnN/sgn89LeRmNY65BbuFbKBQQj8eRTCYlqVAbZqRsu4UOzfX19Um8nEYY32DJxDfW73u9XglTZDIZeWZm9Hu9XpETPN5utyWG7TSlDEy/F0HvE8GcBI9nKhExlUphYGAAAwMD6OnpkdDA2972Njz++ONot9tS688NdlgSS2OVjMhi5C3ocBbXB+c5c4603LJ/t9P/WrZpYxuArAvmE+h9T5xK+LPrqk4sgN255Rzj37oNszEH3eqPrmP+9Hh1Ih1LZxKJhFBqTN6ix9zf3y9CmtYmGQB6DjoZ0ClrUwsTvSCZCa/pVwpZfqZDEaxNpkBjHzABjoYBMJ2gxQHT8X72YbdtouVMIa1L/PSPvS+1guL/fC5Ce59cSBTGepvUhQo4KkR6erT6mZRDQUD6GYAYCpqmpNdAg4uGCXM1qKB0vJ9xefZbsVjE5OSkbCo0X+jxZYhEl4sSfBYqdj4zr0F2yc4SMH+EY8L+oxGrN3bpBtoj446WuVzO8iInnWgKTOds5HI5y4uXtIHGtUK5AUCUCz0+ZsqTteJccGoTFs5xMhhjY2Mif5ikx/c8sP8DgYDsBqkNbTIbXq9X2k6Zxrm7GHFyDYZjgOkwKV/NHY/HpfyQnj5DRQxR0IGhYUcDQe//sRhhC4LzTBvoOmlUh/9mo/o19Dmd8ru00Uw2o9swmYZ2ouzKfrZjfCbdHm3wdGJcun3errP9Kew0fRGJRJBMJmXXLCacxGIxtFotJBIJ+Hw+pFIpFAoFWXzMmtVWGq9PAe4k5UQLn8qcQpeGDAeEXi4Fnk5CYjhA7zEdDodllzkuOmaX6zI0J6EVaKlUkrgrhY/O3O6k/Hc0uewxQF6LpYW6JGi+4Pe42Em/U8DyN9vEcjB6pvqeWmDRO9bziGEFVl8wJ4OKh3vJd6P8OReYKOr1esUQ033J+ReLxWZsd81zdQKiDlFxPegSMp1Don8WumZodLDmOpvNSniJyppGmF5DpP5p4OhQnvYkybb5fD6L8meeDQAxAhZj+9VSqQSv14vR0VEx2PjODz4rx4UGCw0uJgDSUGUohn3EMBbHzmnKnzDGiPLnXCEjl0qlEA6H0dPTI6HGRCIh67q/v1+2NWfYiftfaIVPQ3Mx2Au2QYf+NPvXKc4/11CKNhY6KX8af1yzTsAuM/XfXK/287hGKV/tRsL2QhzdwJFsf/6tFzcn3NKlS4W67OvrQ6lUkl3oSJ0zDshyGp3drJWTE9DPyLgoKXid0ayzX3UCl05OY5IKQwKkD+20K9kL7cnwWZyA9sLo8TPjWCfy6R+N7fWvtkh5Hq10jk+tVpOSrIVQZ9rL5G++p5veOJP7+OIY9qFmPABYFCyNIQoQ0uzAzNp4LXQ4/guBnl96MZNt4jF6HjSGmZ+hLX16cWwnv6+Fms46p1HQiclZCDQdy1AJx35iYkIy+3UJqc7d0IyUNnbsVCwNDLKDulKF5yy0jLRTm/S8jcVikrBHqpweIV9YpeveyWbqF8yQ4mfpK8eEIRGnXuDVCXoe65ATvX+fz4dly5aJsTU0NIRGo2F530QymUStVsPk5CS8Xi/GxsbEmNfG82IYMDoMoxPAtdE0m+Ln99kP/H82g5djQEOZDgTzUZzaiVEb5QT/13u/6PP53JphsdP/dn1oD3PMF13F/EltUvExoa+vrw99fX2SxENFG4vF5I1p2WxWJhlLhOgxA9NCXGc8OwF6Ze329EtVksmkXJ/KnnWzWiHppDkaL81mU6g1KvnJyUmk02nxwPm2Ol6b8TO9/XG3oOWsqX4dI+bk6KT8edwOKiA9yfjDCUjBwP5baG6GMdOv9mTohYqEgpZeGHNFmH3MNlJB0BBhdQD3W+d4UiExETWbzQqrwKTAhY4Ja791mASACBcaH8x1aTabsn+5rq/m5kMMk9GwDIVC8h4DGqytVku2kk2n0zJeOsFpoWNC44uUP3NXMpmMzDWOEecDx0Nn++sNZYyZ3n1Oh/XIipGVoeEJTMdouwXZvfHxcfT09Mj/HG/S/7vvvrsoAz4Tk8L8fr+8NRGAeMqk/LXBTWNgMT1/Mkm6pDgej8Pn82FoaEgMTHr4Q0ND2GeffTA+Po4XX3xRkh65iRPlMo06rrPFglb+XJ+z5SfN1o/bYwPs3j/vxzY5EXrVsId1+ZssINvEe9Kg1yXH/B4dHbvi132yUHSl/JkxS8spmUwiGAxiYmICvb292H333dHT0yNx8XQ6jWAwiN133x25XA69vb1IJpMYHx8Xap1Cgf+ThnciexmYpn0YP+bObqQb+/v7ZdJx21d6ovRYJicnLR4XKUBSf1TEFHLGGNk3e3Jy0mLlOiUU9ISmkaJjZnOlzDpZk3pC6jHQ3h0rHXT28XyenT/1eh35fF7eQcC3o+l3fBtjZEMV3U5gWlDTayR7w3AMAEmKy+fziEajlmRPvsRmoVt9srJAL3IaNqlUCsC0YevzTe2JPzExYXmuYrEoAoEUNDBtFDSbTVHs3D+D7SMzoj23ha4bjm25XMbo6KhkjpPe5tqhgtexe82cUGjpfAwaERSSVK40cGhEAdOJh07Q/pzTfr9fKlVo8LECodWaelcG/49Go7LdcDgclu9R6bLEVede8Ln1PgFOgwqF84Zzwev14rXXXpN9BhhebbfbwromEgk8/vjjUm7JhFHKNrZPM6OLtVdBJ89Wyyp7qNL+3e2FLO3HaajZDQz2Y7cgo0fFznnNZ6Tjqdkv9qt2NrWC1xVmOi+An1MOzxddtZbKWpcrseSIwpmLmbHVQw89FL29vTj00EOxefNm2TWMpVvZbFY8BSbOZbNZR2l/AMI4sPNIm1LwMoFH7/muaWR2uC6/YkJNqVSS+mXGLDVVze9165lp6EWjjQt7skyn/tieEaD/ty9+fT9O1oXEynViGbO/KYCZCa+ZGva/pga1wUXFTRotHA5bPBcyNvSeqaxoxC10syIAQvfrZCK/3y+72OmySP06X/YD5xLnBtvC+m3uRkcBQ2+Ze1XQoyArt9D5RaHKWD4T28jMkNLWW/ECsCg5HYLQxhT7h6E1YDoRUHvJnBdco07tvd5oTL3gil48FTfvR1lAOUDmQ28SReOACY36DZ+8jjZeFgOcu7r8lmwFlfmrr74qSZR8E+FRRx2F8fFxrFixAq+++irGx8cBAD09PfK6bjpd3LiI1ViL1Q7Ot9li/LPJLn6/0zX1OTxmDw/ov53I9teOKnOhNK1vjBFHiXObTAHnv3YKqfj1uydoADActdBxceTFPlp4e71eJJNJGDNV98rYEgUXS2W4SxZLmhhP5JaTtMYZT2cyUbegoqA3obfD1R3PhVUsFkUh6DJADooeDHscWsd4OVisLWeM0Snodun62PnQZdu7NjDzLW88pu+xEHqQz05DiUlkLD2i5677lQtVhyWYe0AhrBcc5xAVK9vC14HqGuNuM7S5iIFpdoSLXj+bTp7TAoLGM5UjBQMNCmZsU+nzx5ipTG1NJ3YDjkutNvXK1cnJSct+ChwvbRQD1tAS16+eix7P9BaybB/ZAL3bmjYk6BE5gVarJaEWe1s5LjqfgvORFD49bc5V7oqnN6cCpunfhXpmcwFlL9kgGmPJZFJ2G6Si8Xg8yGazeP7559FsNiUcVigUkMvlMDo6KvkZ3IeFoR3myyxWO3hdXZLslOzSawuYNgjsiZjdsjOUjVT+uspL5/hwbukqH8oLyiodItN5Q7wmjVR+f3vsyGzoeoc/UmOaTtO5AMwy5c+2bdssO8bVajXxrknJaAFAZetknanOoKZHwZe7ANM7znFh0RPUiXFMbuMz25M7eD4FgD3hrhs6djZooak9Yv35QtDJwtbKnhN8oUpTPzczvguFgnjGepcvGpk610DH0Cg8CNZr63AB/9ZxOR0O0i+tWQh0H2jvXOdJUFny+XU1BdcPjUqt+PW+Ejpxld6EfqWvEzQtjdpSqSQlfNw1UpeQ2ulubRzqH8CaO0Jvhv3Dc2jgsR2aXegWmtbXykGzHRTMfE5WmVBwU4YwzEGjVHucPH8xlSavD0yXtOoKJholDL2GQiE8++yzCAQCiMfjsjvjxMSE5T0MZHLZLl0p43RbtCzplOHvxPXtDgvHkP87kU/CvqeSt+tFbmSn17vdINH7YNAQ5dq2y1ad97OQtdFVzJ8Tj9viMqmP9Dd3yqJQ4yYhS5YsQaVSweTkJIrFIvL5vEV5dBLgTr0cgx6GTi7RW/vq/bG1ENU0njZ4ODgcIBo2FASa+qMXoa1CJ8EFa0/y63YBdaLQKLT1wtLCe77gmOiacq/XK/v1U8AyTq7jdlqZ0zDQpUpUYLp8E5hONtNZ0lRuC1X+vBavr5PEqMyo9PUzUgHqvuYeE3YvQp/PMJv2NrQA6RZct5qdYw07DVwA0jY957Sxo5Wr3VDmc3PtUDiz7Rxr+14J3bSJCYX6ufTnACxzQAtrGpo6VKBLNYGZNdyL6TGT8WLuDeVVo9GQnQr1XKhUKhgaGkK5XMbExISEcljVobdz5rMvNJ9nruA8c1rxE3ZZTGgms1t5zLnKRG4qZxqMVP5cD1rJUw7pzcWoMzQjrZ0YOgM0yl83z590oH7VKxcHE6iYKNTT0wOvd6qeNpPJwJipDGbG/OnNMcar78G450Jojdmemx3IRdtsNpHNZiVRi2wFt70kXawHiQpeT1jGchlPJrPB+zKPgHDa+9cKmBPc6QXE35redIpm1mViehMfepnsQ35O40t7y9qL0BUI2oNjDT7HKRgMSvIaldpClT+TsHTmNb1J9htL2pjvwhcnaUOAbeG88/l8spNbNBqVPTO0h8+cC7uyXegc0J4wGRmyMFw3ei3pNaKVoP3++n8+uzbK9Z4Z2vt2SvkDsBjIdmNEGy76Rx/TbZktvLa9PnAClMEALEpf5x5kMhk0Gg3ZOnliYkKqYAKBADKZjIQHuDNhp4Rh7tuwmNDyazH6q9PYaEO827CSZrOi0ajFWKKyjkajksdkN/jtSe3tdtsSxtPyjetD6975Pr9jdf4AZP9tPgwzY+v1qbco0UKNRqOYnJxEJpNBoVAQr4LWv54EjPvbF103z6x3QGu329LpWgFQ6bMdOqOcCog1wdzDnQuPlBI9SRoGfKUmF6rToOGxGIpf30P/bb/HQmP+OvOWnrvucxpaAGRcqIC4AHic3ibnIV9iwsVI4UimgBnyOhS1UAQCASSTSdlgiMk6vK8OOXE+Dw4OihDS1KfX60UqlZJELSp+/fxMUuTmLZyv2gvvBtqYIn2s6X57eMnu/erf2vPX7ednevy1cWnPM3GiTdoY0/fRa1zD3hYNyifdD/pei6X89bN1Cq9w7jH3ipVHlHMALC/+4kuMtGKyz8fFZDCczOvY3n2AmRUElCfdgI5jPB4HAMv7bugUUwbpmD7nDfUS5Q+rNQqFgmVu8nustqNBN190zeM0m9Pv+QamhB+tSJY9TUxMCO1Rr9fxwgsvAIDs2U5qqlqtygSkEqaBwXKTbqEpPSYnDgwMSI25pvCj0Siy2azsA8A2ARCaDZj21JgIRGXDrWO14tevEdWUj1Nw0jvaEfSzawG6kOtQgOktfimUtLKjgND0mRZ61WpV9irXtHSpVJJETW0E0OPmPTjfFioIdEKPTnTVL7hhv7GUkbFhvZcBMB1eouFCZc9jFM5er1eMahoINEzZv92Agpn5EOz/TgqHa8JOe9PD0e23e9M63s7PNN3u5NzutO70/1rQ2hW/PQdGK3/79RZb8bMdOqwFQDYW0ptfsS/9fr+8/pshLjo0TGTUxpwO3yxmO3Ti62KCRjJgzUnRjuxCrsmcG741kZ46dQFf/wxMb6kMTMk1Vog1m00JnZOd5OZ4ZAK4a6wxRvalWIjcXbDyp5fJTtRUE/9nWVIsFhMvnh2kk3jIGNDropenE76cpP2B6XgsO5Q7CwLWhL9EIiH/x+NxeUZNO/N6/K3jr7SgPR5Px9IMp6k01lovNjot0oVQT4QWpFTq+remmgmdV6HnH9ki/Vz6PrwHwdfJAs5kldPQpQJm+ScFBJMXaRBSeEciEalWYKiJSVZ6HwXSfjrrn17dYsRMtYHFOLCmhDvRqbMp1tlocfu6IHvGc7oRzLO1qdNzEnZWwv68ndrX6VqLrciomNlX9NRpnFEW6fAG2TA6KxxfOlidjOrF9si9Xq9Q4osJbWTqY3QsurmuLlflFvZkA5jzwzfacgtrGl46VAhM71dCRhCAVAEBEEON79FZCJPsyN7+9Ha4QJk1T0qJe0wz3mmnZ3U5naZwKeydXEBcKMzU1Znjen9neh3a09FCSnszgHVXJ50VrDOyK5XKDCpoMeJo3U7k+UALwm4VjhZeen9v+w/RyROh0NKLgd4y5ym9S521rT+jQF0I9GY1mtrTxibP059pxa3nFf/XTBJjlBQ09Pr5fgzSi5yv3QpuPpsuw9Jxbt1fsynATspU0/n6Gjp3oNPnrwc6tcPexsVW7HOF7h+dn6DLjXX5mK4kYajJLmvZ73qcF7v/9QZdiw07M9UpZDNf0Ajv7+9Ho9GQ9Ul5T4XPsaITzGoehgZ06JaMTCwWk/1K6BQzv2inKH89QbSQoUdM5c+Hj0ajUlJHSrJSqQj9rzfb0BNTx+W6ha484EDo7HD7JM/lcpa2AtOJF9yohJOWVIwubeQAMRxC5a8rCZxeVGzjYgknPq+9PGuh0F6/ji3zb7uHqRPa9DWovO3JO9ob5lzVrJWO//L8hUJv6qGFMsebGdn09rkWGHrQ5wPTISUyCBTaNFSp/PkmunA4jEgkYnnTphPQXr/uT2JHbMP2KHb+T2NFX8cpwewE3ijKvhO00iZ0/J4GsTYO+D2dQNup718Pxc85T+ZrMeUX82IoY7TRtFDQ2eMba3XiKuUOw4mFQgEAhB1ktQ4ZQ21oc+zIHjA/idVprDZ73ZU/kxQ4qfjQ7FzSk0xKonCuVCro6+uTGH+lUhEvm5mnVMyMxTi1yY9WXPTI2cG00nSMkX9ze08m+vG98cD0xhQU0FT2ml5ieEE/h9OJTFrJLEY+Ae9BIc2KBvu9u722HbpGHpi5eQ+AGcyMhvaCtWLWXhFZKArJhSobvRA5dzkXaNlTsHHPdC5+XaHA+8diMYtxyp9EIiF9wbYwGZB95YRhafe+AXScW7q/tBFl9/jtcfPZ7qljzfxZzJjzXyuo3HV/2lkU7eXr7zEHy75Bk6b9Cfb/Yipkbvimn8lJ2ajlVm9vLzKZjGyCRI+7m+sztysSiaCnp2fGmLBMttWaetcC9QTlA/PBtHNAI4LJ83Q6yaK/+uqrFjZ5Puia9qeCBKY9qFAohHg8LjQthXc2m5XYJmsTNb3LHfe092+PV3ULGia6PpqVBlpoMQbl9Xol21J7uqzh5IYO/B73yqYxwVINZt7q9i2WdatLSOwU5ULvp8vJNLWt/wcW5jXbx9YeVtF5GgCkXI/MCwBRnjRCtRGiPWkaDJ28fz5/N14mLXy+4IrJPJxLTDLUmw3xOdhubjdNw5nGnN7Qh9dhbTy3X2X+Aq/NNncLrUy0UgamjQHC7oV28krt19SGsDYuthdOcDEF7dWzzzgXtEHLz6nwdBK1Zt/s40sspvfP52V+GJWkXv/znQNajlAG8GVeDJM5tX8B9cXQ0BD22msvaYfen4a5FnRw+S6ccrks3+/v75e3Q1arVeTzectLuxiuprOTSqUk7j9fR7KrTX7YqRRg9Jy5q5QufWMHcOvfTCYjxynkm82meMe61lpTM90KAXpj9oxvlvNxcyJ2JikaYDr+qtkOvoqYViWT09gXujbTnuioF5oToGHDdmkhqpPjOjECsxlZ2jNme6hI2YccH4Y2FgpN8drLvXRsXmeDa2EHTLMEhFb6urxTx8t0aSb7bqE5E36/H8lkUpQyMOW9k5ZnIhAwvScAkwHJHmm6kMY0n1tT+XqsfL6pF2ex5McednACdjqYf/O57DSxXZnbocdNC0h7uGIxKeC/dtiVtD3JmFnl2gCjp0nHTOemaIaS3qo9LLYY8Pl8SCaTACCbxTEXgXvB2ENOeu7Yn49t51suA4EAotGo/M/4O2l0VqUtFMFgEJFIBPF4HEuXLpUct0AggHQ6jUAggJGREdlrgSEOYErepNNpeQET92Twer3YunUrNm/ejP7+flH+fN9NtVrFbrvtZnkJ1nzQ1SY/zMykItSJTvYYuv5cD6L2gJnZzOt3SizqFrR8aT35fD6kUimLF6kVSyqVsnhpjEOzfdxtjsqJA0pah+8OoFXL0hoqY11m1i2azSbGx8dnxO7Y7h31S6fzdPa7XdBoQ4KfdTNG7EMmYbKmnGNGg1K31/63NghI32tKX1PXVMgs26SR1I3yp6evt0UdGhpCvV6XMh/NMiWTScv2xTrmT4OA7Wq325a3aNKIaLVaUh7E4zoXoNsSOc57nfDH43aGbjYDoRM6GSY0FPRvnuPS/lZQZgIz3w9vZ1M07H1uHyvNtnRyFBYD5XIZTzzxhIUV5TPYwxX2v2ebZ+321BtYgenwx5YtW+R/e4ism/llXwd77rmnUPVkGvha5Xq9jm3btkl1T6vVQiqVQm9vL8bHxyUMHgwG0dfXh1WrVqHZbMpLlljXn0wm8fzzz4usmS+6KvWze+aAlcrTFmUnGsk+ueyD5yRtSXDQuXMct7TkFr/aQ+YEZOYmlQIzMHVZDTCd5U/hbC9Py+fzslWqzmlwClReTmMxxsF+fb1wmNFKw8q+25juN7ugsifw6JCB3i9Az02OuX08FwIaHFTEnG/M1tfPoAWtNj7tGc92T47nM+lPJ0rqvf2BhW26NBu0gLN7452o/U4KxX6Oxmzf7ZRg6GIK21ub8/EGd3bfamfSKSyWPOyEdrstinnLli2y5vVLoigbUqmUVMRRyWcyGbz00ktotVqYnJyU3DnuoktnkqEAhvnGxsYwNjZmeUnVXNFVsGM+nuUbBcYY6cBcLodCoYB8Pi/xev3eZJ/PJzF6/TpPlu3prNROtLdmLhgiAGD57hshi/mNBK2YdXayLn+zJzTZ556mjDXFrq+nPUoqGG1cLJTiJE2qN/BgCIb3YBtoRNbrdcs2nsB0Lg3rse0VInbqk4YLhQ1ZlG6Fn92LtBtWsxnv21P4s8WTOzFLs4WpXOwYbp+9fmDezaZNm/DHP/5R9uCgU2HM9Ja8AwMD4ggYYyT0yLdGcjdcAPKbW+TTMaLDCgBjY2Ov797+f61oNqfeQ57JZDA+Po5UKoWhoSFJ7KPHxRgRFTX3fCeVWywWRbBz+1W7ccBYsmYA9B4GOha3q4P9wJwRWspkWuj52t+brnMCdGITr6W9YK38qVBno0UXWrXAd5+Pj49L4mskEkGxWJQEPuadMETERczNrBj68Hq9sikI8xwYC2QuhqbkAaBQKMhbCZ3aLlWH7HQcn+MDdKaONRtgV+qdDBhtlHWKMTtVtujChdPgDrAvv/yybKcMQAxwzmeW8wGwsAHUDXqHT2D6raR6PfB8hnxyudyC1vkup/y5RSm38x0ZGZE9lHWZCzAljGiNaYVEIZTNZi1xfwAWC4zbAnMDIx4vFAqzZtTuquiUF0IqnBQaPeVOyWCk+GgAsNpCb31pjJH6WGbl6120GFqwJw3OB+Pj43j55ZfR09ODWq2GWCyGyclJqe/X2//6/X7k83nUajXJQmayH3e99Hq9kjDE79JY0AKGlTI+nw+vvvqqsFlOgX2o81/Yjk4hAM3S8Ps6/KcVv05u7BSysYfhXLh4o0Gzho1GA6Ojo7PKdjolgLW6QhvTwMx3WtgZMDpB9lyoucJjXNfThQsXLly42KXg8mguXLhw4cLFLgZX+btw4cKFCxe7GFzl78KFCxcuXOxicJW/CxcuXLhwsYvBVf4uXLhw4cLFLgZX+btw4cKFCxe7GFzl78KFCxcuXOxicJW/CxcuXLhwsYvBVf4uXLhw4cLFLgZX+btw4cKFCxe7GFzl78KFCxcuXOxicJW/CxcuXLhwsYvBVf4uXLhw4cLFLgZX+btw4cKFCxe7GFzl78KFCxcuXOxicJW/CxcuXLhwsYvBVf4uXLhw4cLFLgZX+btw4cKFCxe7GFzl78KFCxcuXOxicJW/CxcuXLhwsYvBVf4uXLhw4cLFLgZX+btw4cKFCxe7GFzl78KFCxcuXOxicJW/izc0VqxYgfPPP3+H53k8HlxzzTWL/jxvdKxfvx4nn3wyUqkUPB4Pvv/97+/sR3rD4vzzz8eKFSt29mO4cLFT4Cr/RcLGjRtx2WWX4U1vehOi0Sii0ShWrVqFSy+9FH/605929uM5ih/+8Ieu4n2DYO3atXj66afxhS98AXfffTcOPfTQnf1ILl5nnHTSSfB4PLjssst29qO4eAPDv7Mf4H8jfvCDH+Af/uEf4Pf78b73vQ8HHXQQvF4vnnvuOdx///247bbbsHHjRixfvnxnP6oj+OEPf4ivfe1rO9UAqFQq8Pt37elcqVTw2GOP4Z/+6Z9cwT8HfOMb30C73d7Zj+Eo7r//fjz22GM7+zFc/BVg15aWi4ANGzbg7LPPxvLly/GLX/wCw8PDls9vuOEG3HrrrfB637ikS6lUQiwW29mPMS+Ew+Gd/Qg7HWNjYwCAdDrt2DX/GufCjsA2BQKBnf0ojqJareLjH/84Pv3pT+Oqq67a2Y/j4g2ON64G+ivFjTfeiFKphDvvvHOG4gcAv9+Pj3zkI9h9990tx5977jmceeaZ6O3tRTgcxqGHHoqHHnrIcs63vvUteDwe/Pa3v8XHPvYxDAwMIBaL4YwzzhDBr/GjH/0IRx99NGKxGBKJBE499VT8+c9/tpxz/vnnIx6PY8OGDTjllFOQSCTwvve9DwDwm9/8Bu95z3uwxx57IBQKYffdd8cVV1yBSqVi+f7XvvY1AFNxd/4Q7XYbX/nKV3DAAQcgHA5jaGgIF198MTKZjOU5jDG49tprsWzZMkSjUbz97W+f8azbgz3mf80118Dj8eCFF17A+9//fqRSKQwMDODKK6+EMQavvvoq3vWudyGZTGLJkiW46aabLNer1+u46qqrsHr1aqRSKcRiMRx99NF4+OGHZ9x7YmIC5557LpLJJNLpNNauXYunnnoKHo8H3/rWtyznzmWcG40GPvvZz2LfffdFOBxGX18fjjrqKPzsZz+btf3XXHONMEmf/OQn4fF4LPHsJ554Au985zuRTCYRj8dxwgkn4He/+53lGpxfv/rVr/DhD38Yg4ODWLZs2fa6HbVaDVdffTX22WcfmSOf+tSnUKvV5Jy1a9ciHA7j2WeftXx3zZo16OnpwZYtWyz3//Wvf42LL74YfX19SCaTOO+882bMF6D7+d0p5j/X+bpixQqcdtppeOSRR3D44YcjHA5jr732wl133TXjObPZLK644gqsWLECoVAIy5Ytw3nnnYfx8fF59eOOcOONN6LdbuMTn/jEnL/jYheGceEoli5davbZZ595feeZZ54xqVTKrFq1ytxwww3mlltuMcccc4zxeDzm/vvvl/PuvPNOA8AcfPDB5vjjjzc333yz+fjHP258Pp8566yzLNe86667jMfjMe94xzvMzTffbG644QazYsUKk06nzcaNG+W8tWvXmlAoZPbee2+zdu1ac/vtt5u77rrLGGPM5Zdfbk455RRz3XXXmTvuuMN84AMfMD6fz5x55pny/UcffdScdNJJBoC5++675Yf44Ac/aPx+v1m3bp25/fbbzac//WkTi8XMYYcdZur1upz3z//8zwaAOeWUU8wtt9xiLrzwQrN06VLT399v1q5du8M+BGCuvvpq+f/qq682AMzf/M3fmHPOOcfceuut5tRTTzUAzJe+9CWzcuVKc8kll5hbb73VHHnkkQaA+dWvfiXfHxsbM8PDw+ZjH/uYue2228yNN95oVq5caQKBgHniiSfkvFarZd72trcZn89nLrvsMnPLLbeYk046yRx00EEGgLnzzjvnPc6f+cxnjMfjMevWrTPf+MY3zE033WTOOecc88UvfnHW9j/11FPmy1/+sgFgzjnnHHP33XebBx54QO4bi8XM8PCw+fznP2+++MUvmj333NOEQiHzu9/9Tq7B+bVq1Spz7LHHmptvvnm792y1Wubkk0820WjUfPSjHzV33HGHueyyy4zf7zfvete75LxMJmOWLVtmDjvsMNNsNo0xxtx+++0yZ+z3P/DAA83RRx9t/u3f/s1ceumlxuv1mmOOOca0220514n5vXbtWrN8+XJLm+Y6X5cvX25WrlxphoaGzGc+8xlzyy23mEMOOcR4PB7zzDPPyHmFQsG8+c1vNj6fz6xbt87cdttt5vOf/7w57LDDZB7NtR+3h1deecVEIhHzH//xH8aYqfVw6aWXzum7LnZNuMrfQeRyOQPAnH766TM+y2QyZmxsTH7K5bJ8dsIJJ5gDDzzQVKtVOdZut80RRxxh9t13XzlG4XjiiSdaBOEVV1xhfD6fyWazxpgpgZNOp826dessz7Bt2zaTSqUsx9euXWsAmH/8x3+c8cz6GYnrr7/eeDwe88orr8ixSy+91HSyI3/zm98YAOY73/mO5fiPf/xjy/HR0VETDAbNqaeeamnXZz7zGQOgK+V/0UUXybFms2mWLVtmPB6PRallMhkTiUQs92k2m6ZWq1nukclkzNDQkLnwwgvl2H333WcAmK985StyrNVqmeOPP36G8p/rOB900EHm1FNP3WGb7di4caMBYP7lX/7Fcvz00083wWDQbNiwQY5t2bLFJBIJc8wxx8gxzq+jjjpKlPT2cPfddxuv12t+85vfWI5Tsf/2t7+VYz/5yU8MAHPttdeal156ycTj8RnrhPdfvXq1RdHeeOONBoB58MEHjTHOzW+78p/rfDVmSvkDML/+9a/l2OjoqAmFQubjH/+4HLvqqqsMAItxR3Cuz6cfZ8OZZ55pjjjiCPnfVf4udgSX9ncQ+XweABCPx2d8dtxxx2FgYEB+SJVPTk7il7/8Jc466ywUCgWMj49jfHwcExMTWLNmDdavX4/NmzdbrnXRRRdZqPWjjz4arVYLr7zyCgDgZz/7GbLZLM455xy53vj4OHw+H9761rd2pK4vueSSGccikYj8XSqVMD4+jiOOOALGGDzxxBM77I/vfe97SKVSOOmkkyzPsXr1asTjcXmOn//856jX67j88sst7froRz+6w3vsCB/84Aflb5/Ph0MPPRTGGHzgAx+Q4+l0GitXrsRLL71kOTcYDAKYooInJyfRbDZx6KGH4o9//KOc9+Mf/xiBQADr1q2TY16vF5deeqnlOeYzzul0Gn/+85+xfv36rtvfarXw05/+FKeffjr22msvOT48PIz3vve9eOSRR2TeEuvWrYPP59vhtb/3ve9h//33x3777WcZ3+OPPx4ALPPs5JNPxsUXX4zPfe5z+Pu//3uEw2HccccdHa970UUXWeLxl1xyCfx+P374wx8CcG5+d2rPXOYrsWrVKhx99NHy/8DAwIx5dN999+Gggw7CGWecMeN+nOvz6cdOePjhh3HffffhK1/5yg7b6MIF4Sb8OYhEIgEAKBaLMz674447UCgUMDIygve///1y/MUXX4QxBldeeSWuvPLKjtcdHR3FbrvtJv/vsccels97enoAQOKSVBoUHnYkk0nL/36/v2Nsd9OmTbjqqqvw0EMPzYh55nK5jtfWWL9+PXK5HAYHBzt+Pjo6CgBitOy7776WzwcGBqRtC4W9r1KpFMLhMPr7+2ccn5iYsBz79re/jZtuugnPPfccGo2GHN9zzz3l71deeQXDw8OIRqOW7+6zzz6W/+czzp/73Ofwrne9C29605vw5je/Ge94xztw7rnn4i1vecvcG/4/GBsbQ7lcxsqVK2d8tv/++6PdbuPVV1/FAQcc0LF928P69evx7LPPYmBgYNb2aPzrv/4rHnzwQTz55JO45557Zp0X9nkQj8cxPDyMl19+We4LdD+/O7VnLvOVsM8tYGot6rWyYcMGvPvd797hfefTjxrNZhMf+chHcO655+Kwww7b7n1cuNBwlb+DSKVSGB4exjPPPDPjs7e+9a0AIAKMYKnRJz7xCaxZs6bjde2KZDavzBhjuebdd9+NJUuWzDjPXhIXCoVmVB+0Wi2cdNJJmJycxKc//Wnst99+iMVi2Lx5M84///w5lUi1220MDg7iO9/5TsfPZxN2TqJTX+2o/wDg3//933H++efj9NNPxyc/+UkMDg7C5/Ph+uuvx4YNG+b9HPMZ52OOOQYbNmzAgw8+iJ/+9Kf45je/iS9/+cu4/fbbLUzGYkEzPttDu93GgQceiC996UsdP7cntT7xxBOiyJ5++mmcc845C3o+J+b3bNedz3ydyzyaC+bbjxp33XUXnn/+edxxxx0zZEuhUMDLL7+MwcHBGcapCxeu8ncYp556Kr75zW/i97//PQ4//PAdnk8qNhAI4MQTT3TkGfbee28AwODg4IKv+fTTT+OFF17At7/9bZx33nlyvFPGuabq7c/x85//HEceeeR2FQqz1NevX2+hpsfGxjpmeb8euPfee7HXXnvh/vvvt7Tv6quvtpy3fPlyPPzwwyiXyxYB++KLL1rOm+849/b24oILLsAFF1yAYrGIY445Btdcc828lf/AwACi0Sief/75GZ8999xz8Hq921Uu28Pee++Np556CieccMKsc4AolUq44IILsGrVKhxxxBG48cYbccYZZ3T0VtevX4+3v/3t8n+xWMTWrVtxyimnyH2B7ub3bO2Zy3yd7zU7OQP2c+baj3Zs2rQJjUYDRx555IzP7rrrLtx111144IEHcPrpp8/rui7+98ON+TuMT33qU4hGo7jwwgsxMjIy43O7VzA4OIjjjjsOd9xxB7Zu3Trj/E4lfDvCmjVrkEwmcd1111no6vlck16Nfl5jDL761a/OOJd14Nls1nL8rLPOQqvVwuc///kZ32k2m3L+iSeeiEAggJtvvtlyv50Zw+zU/v/+7/+esYHKmjVr0Gg08I1vfEOOtdttyekg5jPO9vBDPB7HPvvsM6+yL92Ok08+GQ8++KDFMxwZGcE999yDo446agZNPlecddZZ2Lx5s6XtRKVSQalUkv8//elPY9OmTfj2t7+NL33pS1ixYgXWrl3bsU1f//rXLfP2tttuQ7PZxDvf+U4Azszv2dozl/k6H7z73e/GU089hQceeGDGZ5xb8+lHO84++2w88MADM34A4JRTTsEDDzwgrKMLFxqu5+8w9t13X9xzzz0455xzsHLlStnhzxiDjRs34p577oHX67XEIL/2ta/hqKOOwoEHHoh169Zhr732wsjICB577DG89tpreOqpp+b1DMlkErfddhvOPfdcHHLIITj77LMxMDCATZs24b/+679w5JFH4pZbbtnuNfbbbz/svffe+MQnPoHNmzcjmUzivvvu6+iJr169GgDwkY98BGvWrIHP58PZZ5+NY489FhdffDGuv/56PPnkkzj55JMRCASwfv16fO9738NXv/pVnHnmmRgYGMAnPvEJXH/99TjttNNwyimn4IknnsCPfvSjGbH51wunnXYa7r//fpxxxhk49dRTsXHjRtx+++1YtWqVJafj9NNPx+GHH46Pf/zjePHFF7HffvvhoYcewuTkJAArKzLXcV61ahWOO+44rF69Gr29vXj88cdx7733LnjXvmuvvRY/+9nPcNRRR+HDH/4w/H4/7rjjDtRqNdx4440L7qNzzz0X3/3ud/GhD30IDz/8MI488ki0Wi0899xz+O53v4uf/OQnOPTQQ/HLX/4St956K66++moccsghAIA777wTxx13HK688soZz1Cv13HCCSfgrLPOwvPPP49bb70VRx11FP7u7/4OgDPzuxPmOl/ng09+8pO499578Z73vAcXXnghVq9ejcnJSTz00EO4/fbbcdBBB825Hzthv/32w3777dfxsz333NP1+F3Mjp1RYrAr4MUXXzSXXHKJ2WeffUw4HDaRSMTst99+5kMf+pB58sknZ5y/YcMGc95555klS5aYQCBgdtttN3PaaaeZe++9V85hKdQf/vAHy3cffvhhA8A8/PDDM46vWbPGpFIpEw6Hzd57723OP/988/jjj8s5a9euNbFYrGMb/vKXv5gTTzzRxONx09/fb9atW2eeeuqpGSVszWbTXH755WZgYMB4PJ4ZZX9f//rXzerVq00kEjGJRMIceOCB5lOf+pTZsmWLnNNqtcxnP/tZMzw8bCKRiDnuuOPMM888Y5YvX95Vqd/Y2JjlvNnae+yxx5oDDjhA/m+32+a6664zy5cvN6FQyBx88MHmBz/4Qcfa8LGxMfPe977XJBIJk0qlzPnnn29++9vfGgDmP//zPy3nzmWcr732WnP44YebdDot8+YLX/iCpfytE2Yr9TPGmD/+8Y9mzZo1Jh6Pm2g0at7+9rebRx991HLObPNre6jX6+aGG24wBxxwgAmFQqanp8esXr3afPaznzW5XM7k83mzfPlyc8ghh5hGo2H57hVXXGG8Xq957LHHLPf/1a9+ZS666CLT09Nj4vG4ed/73mcmJiZm3Lvb+d1pLI2Z23xdvnx5x3LMY4891hx77LGWYxMTE+ayyy4zu+22mwkGg2bZsmVm7dq1Znx8fM79OF/ALfVzsQN4jJlndooLFy52iO9///s444wz8Mgjj3SMx7qYiW9961u44IIL8Ic//MF9IZELF4sMN+bvwkWX0NsdA1OVEjfffDOSyaTQ3C5cuHDxRoIb83fhoktcfvnlqFQqeNvb3oZarYb7778fjz76KK677jrHssZduHDhwkm4yt+Fiy5x/PHH46abbsIPfvADVKtV7LPPPrj55pvd1+q6cOHiDQs35u/ChQsXLlzsYnBj/i5cuHDhwsUuBlf5u3DhwoULF7sY5hzzn++2k68X5hu18Hg8HdtijLEc53UXo92dnnkh0ZdAIACfz4fh4WG85z3vwcUXX4z+/n48+uij2H333VGpVGQHNWMMCoUCDj74YOTzeYyNjcHr9WJ4eBiFQgFvectbkMlkMDExgXa7jVAohFKphHq9jv7+ftTrdfj9fng8HhQKBTQaDbRaLTzwwAPYsGEDtm7dig0bNmBsbGxG9vuOwD4OBoM44ogjcPbZZ+OII45Aq9WCMWbGvuzBYBDNZhPhcBg+nw+BQAB+vx+FQkHODYVCct1IJIJCoYDBwUE0Gg34fD74/X7UajV4PB4kk0mMjo7C4/EgHA4jFArB7/fPaT/42dryRsNC1skbEQtZJ/9b2hKNRmfIqFarJcf4m9f1er3yHgQt9zweD9rt9qxysNOz8fxmswkz9Sr4BbdDP+sbDbvSOtnlEv5mGyy9cGYzEHYEuwGx2Gi32/B6vWg2m3jttdfw+OOPY6+99kI4HEapVEKpVMLk5CTy+Tw8Hg/i8Th++9vfolKpIBAIIJlMynfb7TZGRkZQKpUQDAYRj8dRq9UQiUQQiUTQbreRyWRQqVTg8/mwYcMG1Go1TExMoFqtolqtotlszulVsNtrT6VSQTabRbFYRKlUQjgcBjDdt6FQCK1WC7VaDZVKBaFQCMFgEB6PB6VSCYFAQF7B6/f7EQ6Hkc1mEQqFUCwW4ff70Wq1xDBqtVpyr0AgAGOMGAcuXLyRsHr1aoTDYcTjcQSDQXnttNfrFUO13W6j3W5b5nG73ZZ1qbdD9vl8YiA0m000Gg1EIhGUSiW02220Wi0AU0ZEpVKB3+/Ho48+iomJCTSbza7aQsOdz2g3tvXfNFb4rHYDSMtu/s/f+gVkdsMmn8+j0WjMMGZ2FeySEm5HA93NRHi9JxEnerPZRD6fx+bNmxGPx/Hqq6+i2Wwil8uJQh8dHUU0GkW5XAYwxRxEIhH09PTg5Zdfxvj4uAiKsbEx1Ot1DA0NYXx8HB6PR7xsn8+HWCwmipbKv16vdy0UqtUqMpkMisUiWq2W7GvOxUzhVa1WEQwGUSgULMLOGINGo4FmswmPx4NIJIJoNApjDNrtNvx+v5xHVqTRaIjhwe8ODAwsyPN34WKx8NGPfhRerxexWAzBYFCUZigUQr1eRzAYBDD91kOumVarJXO+Xq/D4/EgGAzKuuG5jUYDwWBQWL56vY5Go4FAIIBSqQSfz4dGo4HHH38c4+PjXa31d7/73dhjjz0wMDCAdDqNaDQKr9eLQCCAWq0Gv9+PQCAAr9cr8o0GiXbOGo0GwuGwtItrttFowO/3o9lsipzidxuNBjweD/L5PPL5PDZt2oSnn34aTz/9dDfD81eHBSt/r9c7g24iZvOAtUWm/+d3ZkMniqkbJauf3X4t+zNxonU6R09C++eabuvUBqeMBFJ/5XIZ+Xwe6XQaHo8H27Ztg8/nQ6FQQD6fh8/nQ7lcRiqVEtoemKbHPR4PisWiUPYUDoFAAOVyGX6/XxRpMBiU+nUKIS7Subzqd3ttqdVqKBaLaDabaLVaImDYZ9VqVQSVx+MRg8Pr9SIej6PRaMiP1+tFtVqVtno8HhGYFIbBYBDVahWBQADA1AtcyCrwmAsXbwSsWrUKoVAI4XBYQl00cKmkKZu04qfXTMbM5/MhFArB5/NZvHuuNV6rVquJIq5Wq/B6vRgaGkI4HO7aMN5nn31w0EEHYXh4GL29vfJGzHA4LOuRbWy1WqjX62IEANPylMqfbWVb2Ga2RSv/er0On8+HiYkJjI+PIxqNYtu2bbvcnhzzUv4ejwfRaBSpVArJZBLhcFioXm11seO3N0GoMGh9cpA1XaMnLZVXtVpFrVZDuVyed2wZAPbYYw9EIhGEw2Ghdqk87IqL/7MdOg+A9BPbrvvI5/OJ58nv6e9kMhlMTk6Kd9uNIdBut1Gr1ZDL5ZDNZrHXXnuhXq9jZGQEwWAQ+XxeqPlQKIRarYZsNisK0e/3o1QqIR6Po9lsYnJyEu12G4lEAsFgELVaDe12G5FIBNVqFZVKBfF4HMCU960pu25DHlzc1WoVwNQLXur1uixcLm6e12g0hLoPBoOi9Futlij/er0uHr3H4xGhEggERIhSWJIGpVew0LfdzQYaWfzhGtmeEWnvH/6moaVp3p0B+9y3H9se7Ib8rki9zgcMW3Htsr8ovzSFrUOClKH0nqnM4/G4rCmGBZrNpoTEuP5oUOh7dwsaFqVSSViGVqslilqvRToFbAeZOh0OiMVi4jAAkPAgFb02iHj9bdu2YXR0FKOjo8KGOgn7euea31HomdDPyzHVv7vFvBL+/H4/DjroIBx//PE48sgjsWzZMhSLRfh8PlEQoVBI6COv1ysKlgKcCiUej8sAGWMwODiISqWCarUKn88nHlskEkGlUkEsFsPGjRvx3HPP4S9/+Quefvpp/OUvf5l3gz/1qU9h1apV2GuvvRCNRtFoNIQy0wqG9FCpVEIoFLJ0PDAtgLUVzglLGorxNi44LsQf//jH+M///E889thjyOfzcs+FgM9ZrVZRLBaRzWYxNjaGV199Ffl8HqVSSegttpNCgDRbOByWBaaThcLhMMLhMFKpFKLRKOLxONLpNHp6ehAOh5FOp4VZKBaLYp13g0ajISwGMGUAlEol1Go1UfZU8gAkASkQCGBsbMwi+Ng/8XgcY2Nj0h7+ML45PDws48Ux3N5rVOcLLnzGaEOhkOQqxONxSTS0M0JkHtgmzh+GWGgAU1Bzjr4eSpSGC+O2FFT0Rtlu3QfAtEFNA5lyodlsylj+tWE2I81p+Hw+8dy1s8J8FY/Hg0qlIgqvUqmIR0zlGY/HhcZnYivHUCta/k35FQ6HUS6XRUl328ZarYaRkRFEIhGRvWQq7bLY6/VKiK5Sqci5OnSRzWalP8hSVqtVy1zknA0EAtJPhUIBuVwOlUql65AlQQXv9XoRDAYRCAQQDAYRDAbF6eyUU2R3iFutFrxeL8rlMhqNhqx16qxu1/u8aX8mSxUKBVSrVaRSKQBTg8LksMnJSbRaLWSzWdRqNWm4MQalUgk9PT2SLEbaJhgMolgsyiSmQAQgxkA6nUY4HJ41U3UuYLa3tsYYCyMNxglPr5eTiPcldRQOh2UhcEJqqpqWrM4s5+B20wZCW4bj4+N47rnnJLZfLpexZcsW5HI5mSytVkuUqvY2tQDX1+Ziee211xCPxxGPx9HT04MlS5YgHA5jeHgYExMTyGQyKJVKM8IjC2lPtVrF5OQkJicnEY1GkclkhPHh5G+32+KVMNHQ6/UiGo1KO5lIFAqFxCvg/IxGo4jFYojH40gmk4jFYjOeoxuDzA4q/kgkglgsJkKXgoGJiVogBAIBCyNFJcm8C9KxwWAQlUpFjDs+/2KCAlR7M7yv/h+AGMCcT3QU+DeNYs5Bsj5/TdCMoP7t9Dgw/MZ+p6yhR64rWcj2xWIx6WsmtyaTSVHk0WhUxoTXZsIfv0emjNdjbkE3oKKmEcvYPPuMio96hMo5EAhIqM/n8yGRSCCbzcpa5xzSsoFtCIVCiEQi4qRoZewkuAbC4TCi0ais8VAoZFnvGto51HkL/IyhELarUCh0vd7n3GptYdCjbzabqNfrlqQMelCkX6koqVxJL+XzeRnMQCCAyclJidkyO50JH/TUACCdTgsduxBLjfenkuciikQiolhILWmPxB7nJ6XMBDj2USAQEKuVC86euUrh74RwoJIqlUoYHR3FK6+8gm3btiGTyQjlTRZFU0Zsg8/nk8XA8dIxcT5jvV4XZiGTyWBgYACtVksmIWn4btFsNlEqlZDJZDA+Po5isSjty+fzEnscHx8HAIv1G41G5XN79jAFBTBVMpVMJtHT04O+vj54vV75jOd2U7WgwXmcSCRk8XM+U+gkEgk5Rs+LzBk9ZCYics61Wi2LF+HxeMTQ6ybvYkfgfO8UrtDMCcE28G8dwtGxWe2ZVSqVv0oGwB6y6dYYtoPrlGxYs9lELBZDLpeTsKndY2biG2UaMDXfKLe1zGMsn85CIBCQRLxqtYpIJCJGQ7fgWPN+jUYDsVgMHo9H7qGNXs4Phvl4XBvFWhmWy2WZd/wO5UQgEEA8Hsfo6ChKpZKwAE4Y/JSfiURCPH4aHlT80WhUdAAAMeCA6XAF1zvlNnUhEyGZo0W2diHzbEGePzCdIFIul5FIJMSrL5fLMqG0gmOiSi6Xk1gP2YBGo4FQKCSlW2QDqPBzuZxFKTPJZSFJJzq/QMflde26plkrlYrEiDR9W6/XZQA5SQHIIqEy1VmrOifC7iEtFBx4Gk2bN29GNptFLpcTZaEtZR3W0EwEn4vWtk4c0gJBZ/Sz/K/bSajRbDZRLBaxdetWi+FYLpflPtVqFeVyeYaSq1QqKJfLskjYxlAoBGDKgCAVxyqIfD6PdruNdDptqWBwKtmPxisVo0445N/BYBCJREKSnpikFIvFUC6XZXzZbrJOmp1i+IBrZTEMAHr8dg9f50to4cTv0Dmgh6kpS36mBTPDLottACxEOc+X4nfSAGBei04mZqikWCyKzNJePGUaM/c5R7Sy01n2lAeJRMLCZOiQp1NtoaHv9XoRiUSkPUzq1XKY8p9rgfJscnJS1gXnGtcV26cTkmkMFYtFi7x3qrLH6/WKXqC3z6Ro/Tsej4t+o/KnnGq320LzM8ctFosJCw1AGJ1cLif9NV/MW/lT6TOuz+xoLmpanjoewwnFh+TC1vSq3+8X5R+NRkWp0qpjcp+OKy5kMtJr0s9GhccFwklHA4Edq1kDAJJUpj0hAJZrA7AsHPafEwuJQpj9WKlUMD4+LrFgsha8n/2eOkOW1+M1+T/bw3PZd+wLbgSk+7Sb9rRaLVSrVWSzWUveBal/LgYuXA0mDtljzVxkWtmSEuReBhQypDSdFAaskOC96Q3QMIhEIpJAq5UhlSjnJ5OStPHF8ef3tHJ1EmQwtEKwx1O1gNN5AFT67A9gek3oeclz+T3Sz4uFuczVHYXmZlPumiVcqKyygzlQWmGxH8nu2TPeqSSpMGlY2WUQHSGyoGwDMD3PnB4L7bnrrHwqOHuiL59ZOzN0THRIlgY/DX1ei23UDIGex06A611vQMb17vP5JHcqlUoJu6dZZTqZlEX82y7rNNu80PU+b+WvlSJj2YVCQcIAHAhaqQQVKycsyzO0suHg6kxNUk8MBbCDdVLXvBr8P2wEJ7a2MEk/aaHEBaO9E2A6YYnGiKY8eT39NwWgU5mahDaimMBC5chJowUsn0kLLe3l83/9WwsBfrdQKEgMSlvQ3YLKn54M20SlT6VtN2b0PNJ9TOEAQARCKBSSvjHGIBKJiLHJBE6nYv68n06AJf3Hz5iLwI1bOLfokXGe0zhgu3XWN4VELBZDJpNx5Nk1OM/1/OFx/rBdOqGJwkzTt/xMU9F6XbXbbUSjUWHddhbsRiTQ2WDYnnfvpFdJ2l/3py5tpRNGWcbzKJv5N5NZNXuj82gYF6djQ2bWyTwYrmPKLiYyAhCFrx0Xeu2aAdD5DvZ+tjtsDDHrcJWeW07JZR2m5vrlj877icViFmeEBr1+NsoMPr89zM1QSSaTWVAIfN7Kv1qtSiJbs9mUTVao/ACIIqJ1xo6ld9rf3y9eHTDljZOO4W5sTF5Zvny5JbObE5SCZL7QlCUXiS4n0x4Jn1EnJvG+ui5cx/jtE1DnNXAzDk4EpyxO7fFxsehFo+PiWsHr++vJbxd6On7JhUplQ+XvVKY228HsXSYD6Y2EKNjsBpxOhLK3k8qduRo0JnQGsH4Gp0qaNFOl6X/G/nUyrGZUQqEQent7xUvzeDwiNGq1mmRsUwHQm3Hak9HQoS/dvzyu2Q0955mhrSsBmJjFEJqef5QnOxN2A7hTn+r57nR8f7ZnKpfLEp5qNBqSc0PFzMRYbTxq5UiqnU6QTnpjfg1LeHXeSyAQEIPcCeTzefT09EgIi44k54kOMzKkyHXPvmB1gC5XpAHKOUVZrfc10FU0vIdT4HrnXgpc31wTXPPUFdQXoVAIqVRK5JIxRhwDrn8y5tSVOrSxEMx7hdHCLJfLsvMbPScA4tVXKhVZ9NxhLZ/PIxwOy05zOg5dr9elpExvRbllyxbZxAKYjiFqOmheDf6fgaF1pZOptCLn//QSGUsFpiZZOBxGLBaTgaBiJLtB65ne0mwxd/69UFDpsQ95D23E2JkOewxPe5P6HPvftJqpHCcnJ4VlcMpypudPpU9qnj/2UiPdNv38+rjO8aAhx2tow5PGHhOcnIBWjnxvAD39UCiEnp4e+Hw+pFIpxONxMU76+vqEJSAVztDHbrvtJjkdTHDU91ss2PuZwpZKJh6Py7FoNCqltFwnwPRcY+mWTvzjHLaHo15v2A0oOgud1kWndWU/xymFOTk5iWXLlknolOV69NLpqbOclIwZ5RiZLypZjg89aCreQqGAZDIp84ryV49/t2udOwbqpDdS9LVazeJMUPHR8eC6ACDPz3XM8AHnVTAYFJ3C9lGZavbQCdnFeUK6XlcXMRTAPWZYCcDnYkKw3s6c+7csXboUuVzOsnZo3HTjRM5L+RtjLHHXkZER9Pb2WmLB7MRkMgljjCQkUKByS1bSPLRI4/E4MpmMWDbA9C5zk5OTYp2ReeBinC9oDVKR6cxKAGIMUPgwsYwMgI6/cjB0bgKpGl2mxUxaPSFp/TkBrew0hW9XjHaBpfuk0zXt37MnGnGR6rHvdhHpEEYnj18zGjvqB4Ieg6YxdW4H50KxWEQqlRKF3C00axKNRpFOpxGPxxGNRhGJRCSpz+/3SxULhTAzq5PJpGTx+/1+UaTsf+0dAFOJq4thANCzp8HE8AQNYdKd3L+Dnj+NHBqJus/JwOh1xLm12JjNU7eHM/TfOvynFbzdAJjrveaLYrGITCaDnp4ey34YukSZayeTyUj1CMNIZC1JKTOPivKK+69wh0t+pssIeZ9uQa+9t7dXlHWhUJD3kvCZK5UKisWiGC1Uivr5vF6vvHPE4/FYKn5o5OsXdlE22x0MJ9rF+0ajUfT09CAej0syLx2AcDiMZDIpuW1kYJrNqZeVce8XMhaJREL6nUaDMVOJ6zQKFjLH5u35c8G221MZoaTudOyZiX3cnIDelNfrlfpTlqdoYwGAKFG9yJgIUqvVkMlkpKZ5IUKOgwNYy8SomDnBdTxS7/7EdrA0ELAKAFJmNGooMEgxM6RBQecUKFRpMduFUicBZZ8s2xOImpLVxo1TwkC3g32v63VpkNEo0/e05yzMFr7gZ7o9ZEtIefKchewe2QlUitwVs6enRyhIJgUxCUjTg5VKRcoQAVgUJxmlZDIp/9PzcTKcpMF1qPMP9PPyWCKRELbL6/UKRZ1MJsVwb7fbEs+nUNf9RfmymCwG22RX2Frh2xkV/k8FyjlnZ83s13IK4XAYxWJRBD9DqnREmBPDsBwwXebG9er3+6WCBIAoGIbF6BUzdEDl29vbK7Flp8J7tVoNk5OTACC7hpZKJTFsyDIzzKXDmnwGKkwdXmXbqfi5XThlSjQalfvrl5J1C84RKveenh5J5NXhlUgkgng8LoYxwxT9/f2iJ2i00bBhjhzbzLHSobT5YkEJf6T90+m0bDmpExV0LI+Cm9QgrTdOMGA6ySeRSGByclLoHzaSQoYlgqVSSbbGnS+4WHWMWMd47YlrVDj6mM7w50LUZR1UVJyI9ti7rgxwQkDYlb39fp3On+06O7qPVpy6b5wQCLwHc0O08agX/Wz360T/E3Yvjteg98q3luksaSdABciMfwoBCgBmB/f19QlrRO+6t7dXFDtjk9wgZGJiQs7jsUqlYklocmpMAGsskwwX6VcqeG6epEtb+T+AGWwK1zbzGnTp7UKN+4W0S/9NBa/zG3T7Cfu81+ELDSfHoFwuSziRTAmNVvuWvFz/7FtNsbfbbWEM9O6lmhKnYc+wFV/4sz3mbb5t0cqXJaSM8ZPp00m+/EzPb53pzmfiOtZVWcZMJwhSBvN6unqmWzCpjwm8mu7Xtf+9vb0ShiEz0dvbK2OswzEcYxrGZHS4+dzr4vlzQtFzTyQSIjR1HJm12rTw2fn0sCg4uGBoFHC7VQ6QppkpQMrlsqWUbb6wJ7ZxklDYkDrTE4qeLp+J1yBDQSHIcynkNO3L57cbLE4JOK3sd0TB270dOxtgfybdX5qR0QLQKQNAs0c6tmVX/LOxFtujcinM7AYMy0w5/mQDuoVemDrLnwYAjYJIJILBwUFhuCi86RWQNierxJ0MaRiw5p8GwGJ5/lQgmtYnDcmdEvmiKBrEFHwUvsD0a2fJVjB5kcYNMDuFvljQa7XTJkb0mvm/TmTWjJMODfC6TiGXy0mfUU4xlKo9fDoyVJ5skzHTGfPckZXhVJ1LxefWoVHSy06VKXN9k3LXIVWd2K1/dOgCsFYFaBaZ4BzTcp0GGhNR9aZB3bbLvkZ0AixDYlzvAwMDEu7gGEQiETEeaJjoPACGA6lPySRoZ3I+WFDCX6FQwPj4uGW3LwDi1XMzHyp1HVehsaA3QqB3xx3+OBg0DEg/xeNxsRg71XnPBcwk1h3GiQFYFYWO5WvamRORHo4uG+ME0KWAjJvRsqYh4aR3NptSnKuXr/+fTXDZjYAdeeILBYUU+7sTu9Dp+XcUsuB5diMGgISqSCM6AQpUWugUCPQq/X4/UqkUEomEJPhRuJIi58YfFCQsu4rFYhIj5ZyKRCKyP4LT0EYsnyWRSEi4YnBwELFYTBQ9AMlR4BanXAfcfY0KH5j2nKk8X2/a326o6Uxs7fXrckcaqvxtD4FR6TiFSqUiZXraIaFRpfuOfc0ETBqVujKJIU7KL53HROeGSrVYLEqCoBNt0mE9zgHmeAHTZaA6GZsJblouUG5z7XDu0QDid7SM5z0YYtAKuBvQwCejZc9/oeHe39+Pvr4+0RGaTWFuGJM2S6WSJMdzYyJ6/TqJc0HPO98v8CEymYxkK5KKoOWWz+dRqVRkMxUeJy1Jj47w+XxIp9OSUU86h4ly4XAYjUZDdpPTk3jeDf6fRawVgM4DIKNABoOZtLokEIBYq7p0hIuvWCxKPgS/Q8GtS72cSvjT0IxFtwq5kxFgP+akcCMYhtH1/NtT/PZn7vS8nY5z7Dk3KQh1zXE34M59jPMx85dGLzN/Sf9TUMXjcaxYsUJyWyi46DVMTEyIh68FG5mBhdKAs4H0ML0Qbk/KdyP09fVhaGgIsVhM4ptkBZLJpOxQpuPQo6OjGBkZQSaTkbAg2bd8Pm/JL3Aa2su3h4P0nh30Gtl+GvM0uAgKY+0Z6/nm1BoJhUKW6g4yJVqe0jMmAxCJRJDL5SzrAJjyMvP5vCUpjh4q48w61KNzlZyApu35Thc6d3xREWU82+P1Wl+4RSeM23oDkHAz56dW+hxTjhcNEOZAdLteWK7HRFdm+WvGj3F+zo1QKIRkMimJltwzhzIpFothfHxcEnl11Ykuq9WszVyxINq/UqlgbGxMMo8Zt9Oeb7lclpIHTd3wIfU2qqFQCJlMBtls1jJQAKQzaBVms1lMTk6iXC4vyDMgjUUBrye0ph3tOQx6MxKWm5TLZYswB6Z3/SsUCjM8nmAwiHK5PKNUzUkshrekn1ErFR0qcBqzef1zudeOGAB7mEMvGgp4p7b35bPr0kHW6zcaDRSLRUkIZBIQ44SsrdahMwoAu5dMbw6YLsl0CkxOpODq7++3vBGOioIxzUQigf7+fgwMDIj32dvbK8K+XC6jt7dXFBff5MZ1wv0NFsM4tit+GoA63k9vjZU5NGoYkmS72R6ud2ala2ZMU+7drpOJiQkMDw8LS0VHSjtanGe6bE7vUcJQEdui1xmp5lgshnw+L06R1zv17gstu7ptCz1uneBWqVSQy+Xg8Xgs7xzQ99LGDtcqDSI9XxqNBrLZrLAVACyl1mSUNYvcrbGpWWMtR5jZr/fB0e/38Pv98rZFzQZ4PB7LnGO1jZ2lIJs4371JFuT5l8tl5HI52WBB35STiN4uJxuNANZzkvrzer2yv7pOgCDlRCHH2OD4+Lh4Pt1sxMKB0MklwHSikb0mn4OiaSmPxyMvIWHsmLQnS7joxXKB8ZimGZ2C0/H32e6x2HTsXCn9bq5pP67pQ3rT3UKHiAqFArLZrIXGDIVCGBgYQCgUEm+XNLqmAJlxTeaMBgLfZqbDFFw7C/EEZoMWrIFAQLLxU6mUKMZ0Oo3dd98dzWYT8XgcfX196OnpES+OpUx8/kgkgq1btyIajWJgYACJRAKlUglbtmyR63PtO80uaTqf/+skXtK2PMY5n06nJVuc8oHXYgKdNjApF5xiYprNpryamvOUBhlr+hkuIi2cyWQsBgifjSElyj4mcicSCcmOZ//QSOjEwnXTFuoA9i+ZMtLbWi6TGdKOh26TfZ7Q+6fBYjeMuWeGPa+oG1AXMtHSbgyGQiEMDQ3J7pX6rX9ct1wHpVIJhUJBWJdoNCr5colEQlgLvYHRfLHgbH++x12XsDH+xE7QLx/RnWPP2GTH8zwaDmQOSJlzs51uYv40LnStNL170na6vIolSbTmSM3yuTj52Aat1O0x8k4/i4HFum6n+yxmG3aUuNjt9Wf77YQXwGtx7tDjDYfDUg2jKTsKN5Zykepktrz2NAuFAgBIuSnXHQ0Np/uLHqBmxRiyiEajWLJkCfr6+sQgIG3MJLF8Pi9Z5ZQTo6OjSCQSWLJkCfL5PLLZrNRdE7r6wmnoNco1yzGh3OGz6pgwDTeyhPSqmYGtk9bYV/zdrQGgy1H1VspUBFSY2iPWG9oA04wavUr2BX/rnCsqFMo1KmMn5pfO5mdMnBUF+v0dOq/Bzt7xOMeI/a9ZMbIkemtfraPYVqfkjNYHbCNZb+bvaMOLMoHtiMViM+QGdRDzAPTeM93kKsxb+VNxlstlyzuFqQipkDUlRsVIakJb1Fpp6hIVvbsZPTGWGOpXNM4XpP3t2fvAdHKInkz23AKd0KeP6b91ZinP1S9p6fQ9p/B6KP7X6x5OeRk7uo/+re/txLW1UtYCj7HJQqEgtCrXE73eYDAoHj+VTrFYRKFQsNC4NAAWK5yk1y+ZBmYuc/MibqJCZoBrn3Ihn88Lm6E3n+np6RFPiU4EY7+6Ztsp2JP7tOLXMVSdEMc+oEKn8tRhTm0cAdNziEqIx7oZFzI/fAbKUypKnRXP+2l2A8AM54Zep5bPun18XruS7RZU8prhpcGivX4+g9YlhP7MPq52plYbQWSWdFjRqfWuZZZOpuQ8YpUFk/l0G8mI83i7PVXKSceU7eemZd1i3jF/TgAqYnYaE6Y44WgR6wXEY/Zrkg6nR63rUnV5jTFGyvy6Vf78m5Y66/NZSkPlrbNINT2oM7OB6XfAa+tZhzDsL8bg+YtF+y822B+Lef3FbstszIxTyXJU/jpGSaqu1WqhVCphdHRUspoZCySdy62wKQAqlQry+bzskElDgHFe7cU4CSo+GrHxeFxegczyPq/Xi2QyKW3UCiYSicg7QKi0otEoRkdHRdHSqODbzrhuFsNA1mEMyh2udb2PgWbydLa/Dg/Ya8d1fJ/Kn2PSbRiGjhYVBWWXVjJ2ap5KUSs5PpNOIOPz2Uv5dHhT74nfLThPtCNFb7xTeS/nDhW4rnDgcfs7Mjge1Cl0KgHrlt9OJTLyubRjqWUY1zzfmkgGgDk1AJDNZuX18jRUaLjoHAV73spCsKC3Z3DgGBvSCl6Xj+h6d8CaXKVjYbpsRW80wUWlY/CM9S+U3tTJXHrS0+ol+6BjUTqZgoKKtCC9OMZl2AZNM5G14HXsC9NJLAZFOhsWk/J3ysOYy73snhkFY7fQFSNU/oyrMmG0UCggEolgdHQUPt/UHv/tdhtLlizB1q1bxbPj95nklcvlZOtsegN6YyQn+47Kj4lFPT096O3tFe+fTACVE4VZT08PgKmk3Xg8jkqlIlQnhS8TyxhC0OG8xWJ+tGGhX6tK454Knm3RZVdkZMjG0PO0J2RqBpH37LYtTJ6kDNTsBGWuvewYmEoI0zQ3MF0Dr+Uw2ShNJVPWFQoFxGKxrp5fQ+dy6c1q9Ot8NS1PhaerALQxxf85bux7XXmhE2T1joE8r1vwOfUbC4Fpg7FarUqi7+joKAAgkUjA4/Ggv78f4+Pj8jzc14PPyYRSMud0hLtZ7wui/dmxehtf/RkwM8bFiUiLzu4581xWAWgGgefQk9ITfL6gl0LqkaUi2qLiYmBVAu9NJkJb0dy5jdnPeqtTtpmlkBSe9lez/rViMZXz60H5E9rj12yQE2Dsr1qtYnR0VJKyxsfHpUSpWq3Kfu2Tk5NoNpuYmJgAABGM9PS9Xq+skWq1KolBmUzGsmGJ07Q/110ymUQikQAwTXNmMhnJNl+2bJkI8ZGREaRSKWSzWcu1CoUC+vr60Nf3/9s7l6a2sS0Kb9t0UsI22LkmTapT9IxJ96Cr8v8zzCg/ILM8qIKGOH5Ag8HY0h24vu2lg0huJJlOLmdVUQZjSzrSOfu59j7/cRJvkiTe4Ww+n/tGJ2VYzF+DCmTqrlmH6ikShWGdYmQ9efLEhsNhzjFgfwWY9WbmJE9kWpizLgPkLGFyuipCYEORk0ZptVrWbrdzrZSbzVW5XLvdzsk3FKcSqRkLefnz8/M7kduyYE1wDq5DuQhZluXSZKSUAMYK16rRDBwuXdtaPoqS5jh1Rvo4Nj03bm5unBSLtw8fLk1X3Ra1LByDcjabOXGTFABkwOFw6EZnWeOllOevucxQSGoOn4FgPapSV+amQsPlZnYnxMHxCQN9L3gQWrdLhIGdrBDYnAfvhve0mx/hWc33IUDUo4C3oF4UE/ahlNzPgodKXSgQzJoSqgqNJJAiQ7GQvqIihm5epJ0wTs3MFT+ELzxn2l2Px+NcC9S6oyaq5JbLpY3HY/c42QGOPgDdbtc9xHa77YoIFvfl5aWv5dFolEu54Il3Oh0bjUa1eWQKZfUzBg3VNxoN76eQJEkuvE9OmvQGihDFT4QGBUM3NtZ91TmFLFGZiNeHQwMPhBC49vnnOrRFMPcEA4cN2UJOlm62U8cz0ciwkig1NI+M19QrIX10Ad0NuSca8SAdoKkaUmw8+7AdchVo6pCSRXVeKYk9OTnJpbe4B8gH0ntKbk+SxGXH5eWlN8/j+h9U+SMo9aYzkHBSqeWukQD1+nllIquVjMLUkjn93vcAr0nD+iwarYc1M+/IhgWKkYBVqX+bmZOFVFhqZQD5zZCcUifqylf/m1DCzkNBPf86nwmGpNlqXLD52dVvMpl4DhDjEwV7dXXlrGCt4c6yVSOpyWTiTa8IYW4imqRGDOOgiQ/e53A4tMPDwzstR0ejkV1fX3snwyRJfP10Oh1bLpfW6/VyfdtJD2zKMNbQPgxsNfxubm5sd3fXPS5++C4/Skgk+me2JnrxOVrJVgUKWgnEKHpCxUoCVc4EMojr02NiCC0WCy/NRD6TYqW6oM5nAsfKzO5EczW0z5h5BhreD9nuauhw3TiTapiRaq6zQoY5RKdElDjnQ/5TIk/azMy82yXPNDRorq6unONDygnDr+wzKaX8daBYcHoBeiGhMFLlX5QmwLpRAcxnQzJLWSgzl2tnAYXlfiGT1GxttWp7YzZxUIKQEoj4wbvje3WT5jZBkPo3oOzWTaPontUlDHSdaCkrihqeCeFW7c0Pt8Ys3w6Vv2ezmYcGEQabIv3hDVKSqOx8yrQajYZ9/vzZtre3PfR/c3PjAk5Lf9M0tXa77R7r+fl5rp2rpv/qBOsTgpVG6fjRhkNKptNdDLk+FFG328152zxPJXFWXZucS6MR5JLNzO+rOmEaCi8yppGrKEgMAyVFKi+grvUYKi3+1o6qmiIO50EY9VWlzyvH4Z7p+yFnQI9RZUw4xLe3t56+YJ4wXtJ1WvbO/deoBdEk5hEOAHNLO90+aM5flbFOCn2YGkrjJvBZDe3r91QZhsYAN6+KQMBrYWKj9GkhDKGPm6obY6gVTf4eYUD4n2sjTMMiUoKR1nbX6f1rvmvT3j/3ZBPEvJA0tcmx6MIL+Sl1gOMieJUEiELX0j8UJIYkHhehf8J9pBK0e6YyjesEx2PN3N6u9veA+U/ufDab2cXFhXW7Xc8tJ0livV7P0wIIRsixdKLTcl4N827i2dNRjZQkeXn4QCh2szz3BF4PhgNlaUT4UF50OzXLNxCqOq+KlDTyUdeipjI1vK4R1TDqyt9KIFQDANT1TNRAUR4XMpjzaMWVfk9D/FyrKni9xjBSXMVb/taYGI8a+krIpN4fHkiSJLZcLm13dzfHS7i+vraLiwvvfYEjgEGAwV+F/1ba89dQGAMPrTizvHBF+Yef11B1aBDogtEJUDZHoyU8LPgwXKoWLxabhrxQ+pT5aM6fFAI7NHEcM8sp+015/gihTRsAKiQ3cR6MsLLcjv8FGqVhAfFs6wKCOuTB8D9tAIIioYf7YrGwfr9vy+XS6/3x9HT7VoQNAmYTxph6jzpnNZpFbb6ZebdL8uQHBwduuLDu8F7G47ErzMVi1SFwOp36uesEz7fT6fjvKE9V6s1m09MwRGaI7g0GA/fCsiyz3d1d52OQhiEy2O12bTwe1zIWjBPkIEpSPVzmGutHiYBEIrVEm/dDY8VsLW+RbXUaYxrZQ/4uFguXx5rX5xq539r8SfUQTh3vMRfVsGk0GrnSOXVa6wz9o/zVScbwTZIk1xxKt7Bnc7uLiwuPrmmL7zDKxxgeVPmrt19keaiSV8tLjQIN/TOJ1UAoOhcoO2BuGufTSYY1RugvtKCV5a8RBPL5W1tb3hWM0KHZmomqE1PHURcwKrjeTYZNCX1qmUld5+Leag113V4gz1ZzoaGhWhfU+1ehpfeNihA2/ZjP5+5NI6hQlpTYal60qhfwLaiSQGgRrciyVfOeg4MDOzk5scFgYJ1Ox05PT+3o6MgGg4ET+DBO/vnnH/vy5YtNp1P78OGDj2mxWG8HXvf8ZV51u1178eKFb0728uVL9yA7nY6Zmbcmhsx3dHTk3AWqAHherHW21+33+9bpdGw4HFqapt60CLZ+WWgU0szckCJfz5rnvoUKUnPlWiaIMgzTm0Qpkd91EjBZY9rLBfmoTpdCoxKMBeNA0zThGtPPhMfT6EYdY1Njxmy9rTJpDC2Lh3zearXs5OTEjQJ9XrQJZk3A6aDErwo3prTyDwccevHkVVRoa4g7jAKggMNcPw9Oj61W6/eCshzCKyhsPHaUOFYjD4uyESYRlp1ucIJVrixOFpQuUq2SqFPJNJtN3+udEJougDLn4tp5RiHXQdMMdZENySVjLWtYPrTWv+eY2kNbeR+q1GBDVxXUCq6T4yuZMU3XLW81x09YP/SCtEsg0JxinfNJrz/LMu9lgaDVecZ2s3t7e9br9XxuJElip6endnp66n3Jnz59asfHx3Z8fGyfPn3y9QWxEY9nUxGldrtt+/v7dnh46PfxxYsXtr+/74bWzs6Oe/vz+dwGg4H9/fff1u/3XdHCdbi8vLTz83O7urqynZ0dm8/nNp1OncjZ7/ed/V0VKGuzdQ2+lutxDrghpJEYOwoTboUa8zQ6w3nJsixX9sear/O5hNEFIrMYBnymiPCHrA6jXRrN02MzFoy30GmpO92HMdhoNNxwWywW1uv1PFqHsa/7HGh6ZjabeTt9leM4A1UifaXZ/mqhFf2vSAiFEYBQWajnpe+FFhMKtYygUwIf18DWj3ojmQhwAdQISdPUFxVhKPJ+akAgAPndbB125D0WXB1YLBY2Ho8L+RdloQLAbG3JqhFXt5BeLFYbmBRxPMqeC8Vpli8fNctHqRqNhnejqwMIWj2Pelnqyek1cT3hePWehPdF86h1gnn19u3bXBvf7e1t63a7zuLf29vzCFqWZXZ5eWnT6dQrZczWKTWtVlDWMgbQYrHwDb/qAkIV8tTFxYX98ccfd+rNabRktmpQNBqN7Pj42BqNVfVCs9n0XUW3trZsNpvZcDh0IZ5lKw5Br9e70xCoioH85csXv0dmK6XGVskqc3WuY5xrBYbZ2ojgmrTDKkYChiqyi50N61jzKkMwhjHC1bDVv/kc10n/Ao0uq4evzZp0XETVtDIiJJmXAfddDT3ldikRHF13H0+BsWPUq25SHYt8eXDPn4kT5uyLwvZF3wv/p+8V3Yii1++F1l1q0x61atWTxVjQnL+mJ9RjNFuHksLIhr6q17wJxVk37nsWm0JocNR53KLfN4375izz41u9uu+71ocaAwKYLoTaZEbLW2kcA9I0dcGKV8P7RAw0VYESQ+BtolMhzYR2dnZcQbdaLdvf37dff/3Vms2mPX/+3L15CIxJkth4PLblcmk7OzseoWk0VhUOL1++tD///NNOTk48unR+fu7NnHRL17LAGNK0Jc2HzPJMd2QS91XZ+shsVXga7ldDIFSmer4qUHKf2bqaReUXyo/3UIAaNdVrUc4D/y8iWyLXdf7V5cQgu+7Tb0VOR6g/w+MVvd733vegkvJXJVeUzy8K7RehyFjghoTGBceqcs1Meprt6IQjdM9n8GKo1cXTxwrVyachNCzZcOKFEYRNkdkifnz8W8ZIGaRpmitDDHPEKCOzu708vmU8hsqkjohVETTN9+zZM+v3+9ZqtTwN2Gq1rNfreeSOKoXt7W3b3d219+/fu+ep30Gxv3r1yt69e+dr/+zszEma5HarAMWr90s5HhoVUo4RY0dxhs+sSEGpd6r/r6v/gl435wgdl6J5o9ET0hZct75yP8wsF73gfKStNsWN2tQcrhOVCH8of33PLB8RUHzL49fPqMVaZDh8zZj4GsJNgVjILCwWNLnmra0tZ/JihcIJ4FhPnjxx1maaprkyQM2xqeERhnIiIn50FKUhwH1rsSjUXRc3pAyur69tOp16tIJmSsfHx5Ykif311192dnZmV1dXNhgMco1xiHR8/PjRUx7tdtt+//13b8CSZevWrKQHtTyzytjhHZnlNyXj+sJ0EOfT8+r3UbhF6VblpyhRuc6GOKr8tS8KzhefA0rwUyfKbJ3X53N6HsanY2GMqguqhv1/NpRS/prvBaGXXuTN62RVFBkFOlmLwiNlH9Tnz589nAdhCUGgfaM1N7a1tZXb1IMwET2yNV2QpqlNJhMvg4OMQ/OK5XLVAYoaYcYfEfEz42tz+KHTRvcBQuFoNLLXr1/b7e2tdTodGwwGruzOzs5sPp/b6empZVnmrXAnk4l1u13vQ8BGRtfX1/bbb7/ZL7/8Ym/evHEyMOt9MpnYdDr1fR2qhMw1F4481XRkUaQllKMqg0O5qiRtnJTwMxrdrfocNcVqZr5Rmtk6PUsEg+tX7pf2ZtEoNM4ZhkoY9TDLGxxEgMNugf/vaGRR80RERERERDwqbG5D9oiIiIiIiIgfElH5R0REREREPDJE5R8REREREfHIEJV/RERERETEI0NU/hEREREREY8MUflHREREREQ8MkTlHxERERER8cgQlX9ERERERMQjQ1T+ERERERERjwz/BUFAmZGm8LimAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 50 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from avalanche.models import MlpVAE\n",
    "from avalanche.training.supervised import VAETraining\n",
    "from avalanche.training.plugins import GenerativeReplayPlugin\n",
    "\n",
    "def main(args):\n",
    "    # --- CONFIG\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "\n",
    "    # --- BENCHMARK CREATION\n",
    "    benchmark = SplitCIFAR110(n_experiences=5, seed=1234)\n",
    "    # ---------\n",
    "\n",
    "    # MODEL CREATION\n",
    "    model = MlpVAE((3, 32, 32), nhid=2, device=device)\n",
    "\n",
    "    # CREATE THE STRATEGY INSTANCE (GenerativeReplay)\n",
    "    cl_strategy = VAETraining(\n",
    "        model,\n",
    "        torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "        train_mb_size=100,\n",
    "        train_epochs=4,\n",
    "        device=device,\n",
    "        plugins=[GenerativeReplayPlugin()],\n",
    "    )\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    print(\"Starting experiment...\")\n",
    "    f, axarr = plt.subplots(benchmark.n_experiences, 10)\n",
    "    k = 0\n",
    "    for experience in benchmark.train_stream:\n",
    "        print(\"Start of experience \", experience.current_experience)\n",
    "        cl_strategy.train(experience)\n",
    "        print(\"Training completed\")\n",
    "\n",
    "        samples = model.generate(10)\n",
    "        samples = samples.detach().cpu().numpy()\n",
    "\n",
    "        for j in range(10):\n",
    "            axarr[k, j].imshow(samples[j, 0], cmap=\"gray\")\n",
    "            axarr[k, 4].set_title(\"Generated images for experience \" + str(k))\n",
    "        np.vectorize(lambda ax: ax.axis(\"off\"))(axarr)\n",
    "        k += 1\n",
    "\n",
    "    f.subplots_adjust(hspace=1.2)\n",
    "    plt.savefig(\"VAE_output_per_exp\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a3b13-9ca0-4e70-ac81-73bcce64c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images generated by the Variational Autoencoder (VAE) model represent synthetic data that the VAE has learned to create based on its training with the CIFAR-10 and CIFAR-100 datasets. Here's a breakdown of what the images mean and what you can expect to see:\n",
    "\n",
    "# What the Images Represent:\n",
    "# Synthetic Data Generation:\n",
    "\n",
    "# The VAE model learns to encode input images into a latent space and then decode from this latent space to reconstruct the original images.\n",
    "# During the generation phase, the model samples from the latent space and decodes these samples to create new images. These new images are not copies of the training data but rather new instances that follow the learned data distribution.\n",
    "# Visual Quality:\n",
    "\n",
    "# Early in the training process, the generated images may appear blurry or noisy. This is because the VAE is still learning the data distribution.\n",
    "# As training progresses, the quality of the generated images typically improves, showing more distinct and recognizable objects that resemble the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43508435-7e4d-48d7-82aa-34da32be1a55",
   "metadata": {},
   "source": [
    "# Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4ed24b0-52fc-43cf-8112-a93099180e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, List, Union\n",
    "import torch\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from avalanche.benchmarks.utils.utils import concat_datasets\n",
    "from avalanche.training.plugins.evaluation import default_evaluator\n",
    "from avalanche.training.plugins import SupervisedPlugin, EvaluationPlugin\n",
    "from avalanche.training.templates import SupervisedTemplate\n",
    "from avalanche.training.templates.strategy_mixin_protocol import CriterionType\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Cumulative(SupervisedTemplate):\n",
    "    \"\"\"Cumulative training strategy.\n",
    "\n",
    "    At each experience, train model with data from all previous experiences\n",
    "        and current experience.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model: Module,\n",
    "        optimizer: Optimizer,\n",
    "        criterion: CriterionType,\n",
    "        train_mb_size: int = 1,\n",
    "        train_epochs: int = 1,\n",
    "        eval_mb_size: Optional[int] = None,\n",
    "        device: Union[str, torch.device] = \"cpu\",\n",
    "        plugins: Optional[List[SupervisedPlugin]] = None,\n",
    "        evaluator: Union[\n",
    "            EvaluationPlugin, Callable[[], EvaluationPlugin]\n",
    "        ] = default_evaluator,\n",
    "        eval_every=-1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Init.\n",
    "\n",
    "        :param model: The model.\n",
    "        :param optimizer: The optimizer to use.\n",
    "        :param criterion: The loss criterion to use.\n",
    "        :param train_mb_size: The train minibatch size. Defaults to 1.\n",
    "        :param train_epochs: The number of training epochs. Defaults to 1.\n",
    "        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n",
    "        :param device: The device to use. Defaults to None (cpu).\n",
    "        :param plugins: Plugins to be added. Defaults to None.\n",
    "        :param evaluator: (optional) instance of EvaluationPlugin for logging\n",
    "            and metric computations.\n",
    "        :param eval_every: the frequency of the calls to `eval` inside the\n",
    "            training loop. -1 disables the evaluation. 0 means `eval` is called\n",
    "            only at the end of the learning experience. Values >0 mean that\n",
    "            `eval` is called every `eval_every` epochs and at the end of the\n",
    "            learning experience.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            train_mb_size=train_mb_size,\n",
    "            train_epochs=train_epochs,\n",
    "            eval_mb_size=eval_mb_size,\n",
    "            device=device,\n",
    "            plugins=plugins,\n",
    "            evaluator=evaluator,\n",
    "            eval_every=eval_every,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.dataset = None  # cumulative dataset\n",
    "\n",
    "\n",
    "    def train_dataset_adaptation(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Concatenates all the previous experiences.\n",
    "        \"\"\"\n",
    "        exp = self.experience\n",
    "        assert exp is not None\n",
    "        if self.dataset is None:\n",
    "            self.dataset = exp.dataset\n",
    "        else:\n",
    "            self.dataset = concat_datasets([self.dataset, exp.dataset])\n",
    "        self.adapted_dataset = self.dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a69ab-422f-4406-a8bb-42ae3d2963ef",
   "metadata": {},
   "source": [
    "# P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c216b8b-af53-4538-ada3-41596388a9a6",
   "metadata": {},
   "source": [
    "## p=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b70debab-b382-426d-9e86-a2ffffc60c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:28<00:00, 26.99it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2013\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7471\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1816\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.70it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8259\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6756\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2913\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 782/782 [00:08<00:00, 92.40it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6499\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7851\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3741\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 98.55it/s] \n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5224\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9647\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4350\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:07<00:00, 99.07it/s] \n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4246\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4766\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4793\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 99.75it/s] \n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3413\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3538\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5119\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 96.99it/s] \n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2781\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1237\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5363\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 98.72it/s] \n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0733\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5596\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 97.72it/s] \n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1953\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9389\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5751\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 98.88it/s] \n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6625\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5841\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 101.74it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1296\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5006\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5973\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 782/782 [00:07<00:00, 100.58it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1099\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4100\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6070\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.35it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0879\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6264\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6166\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.29it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0699\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7744\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6215\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.87it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0523\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1871\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6278\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 109.72it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0284\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6181\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6359\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.47it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0218\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2004\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6433\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.30it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0094\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6970\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6462\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.76it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9942\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0171\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6514\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.06it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9867\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2019\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6554\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 96.30it/s] \n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9832\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2924\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6563\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.68it/s] \n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9756\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3592\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6583\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 91.13it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9639\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8293\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6647\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:08<00:00, 97.59it/s] \n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9557\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7979\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6651\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.03it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9481\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4008\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6707\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 99.55it/s] \n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9409\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8454\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6710\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 101.18it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9310\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9692\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6766\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.41it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9349\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0849\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6754\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 100.97it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9196\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0530\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6813\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 98.65it/s] \n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3218\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6800\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.61it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8442\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7141\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.89it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.3935\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.2612\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.7693\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 13.1807\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.83it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 13.0794\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.8905\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3570\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.52it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7467\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8677\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5438\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4062\n",
      "100%|██████████| 938/938 [00:08<00:00, 109.63it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5342\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0426\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5606\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.96it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4989\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4755\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5657\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.95it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4723\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3922\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5700\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 109.87it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4543\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1217\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5749\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 109.42it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4382\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2936\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5757\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:08<00:00, 109.74it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4277\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4095\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.13it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4228\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1823\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5813\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:08<00:00, 109.06it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4159\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3664\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5808\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:09<00:00, 103.13it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4046\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2460\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5857\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 105.22it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3965\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1372\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5876\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.37it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3902\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4730\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5894\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:08<00:00, 107.60it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3920\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6784\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5861\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.95it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3852\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2617\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5896\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.09it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3816\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6430\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.44it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3701\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1196\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5942\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.84it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3728\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7223\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5921\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.57it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3673\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0403\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5938\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 108.40it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3655\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1818\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5951\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.16it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3568\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4798\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5956\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:08<00:00, 105.10it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3619\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8393\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5949\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 938/938 [00:09<00:00, 97.30it/s] \n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3619\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6057\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5958\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5312\n",
      "100%|██████████| 938/938 [00:09<00:00, 99.94it/s] \n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3466\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0547\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5997\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 938/938 [00:09<00:00, 99.64it/s] \n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3514\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9716\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5960\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 938/938 [00:09<00:00, 103.00it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3403\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2733\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6018\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:09<00:00, 100.25it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3484\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3439\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5999\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 938/938 [00:09<00:00, 100.06it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3412\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5437\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6022\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 938/938 [00:09<00:00, 102.38it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3355\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3836\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6028\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:09<00:00, 98.73it/s] \n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3368\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6899\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6050\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 938/938 [00:09<00:00, 101.20it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3314\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2009\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6021\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7812\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.30it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9704\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7202\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.3519\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2745\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.4481\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.0289\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.5080\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 12.4459\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 5.6635\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3876\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1094/1094 [00:30<00:00, 35.87it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0571\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4255\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 111.24it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8155\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4671\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5167\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 110.66it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7911\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8466\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5185\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5208\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 109.96it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7693\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6672\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5225\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 111.05it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7632\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7690\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5224\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4792\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 110.82it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3058\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5217\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 105.58it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7505\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7742\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5237\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5208\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 108.13it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7456\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7298\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5258\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4583\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 106.15it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7405\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8836\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5272\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4167\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 104.66it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7348\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1736\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5256\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5208\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 106.76it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7284\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7114\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5267\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 108.44it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7354\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7406\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5256\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 106.29it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7202\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7674\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5276\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5208\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 106.11it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7187\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2955\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5282\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 100.53it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7190\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3930\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5285\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 96.62it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7071\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3885\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5321\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6042\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 96.78it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7123\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5824\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5307\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 96.28it/s] \n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7049\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7296\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5312\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 96.87it/s] \n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7060\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3779\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5309\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 98.40it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7067\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9286\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5323\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4583\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 97.41it/s] \n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7014\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5316\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 98.06it/s] \n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6972\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5761\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5334\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5833\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 98.11it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6924\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8467\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5327\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4792\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 98.09it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6979\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5357\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 96.82it/s] \n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6987\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6484\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5330\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 93.43it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6933\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7110\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5347\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 97.52it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6884\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7098\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5372\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 95.96it/s] \n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6923\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4873\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5334\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 95.33it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6843\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5637\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5374\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 97.22it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6799\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5283\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5371\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.59it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.0305\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7217\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.6698\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2150\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.8286\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.63it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.3886\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.63it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.0637\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.76it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.9815\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 4.6085\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4023\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1250/1250 [00:31<00:00, 39.10it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2780\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9982\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4597\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 108.94it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0607\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1882\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4703\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 110.48it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0406\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0308\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4702\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4219\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 108.14it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0239\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9682\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4744\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 107.99it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0228\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2174\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4769\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4062\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 107.22it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0182\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8490\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4750\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 106.15it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0107\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4756\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4219\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 105.01it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0050\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1626\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4774\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 105.12it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0080\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3353\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4784\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 105.63it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0061\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0037\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4779\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4219\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 104.70it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0036\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2696\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4789\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 99.63it/s] \n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9992\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9111\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4782\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 98.03it/s] \n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9925\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8402\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4798\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 95.90it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9977\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3042\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4806\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3906\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 97.23it/s] \n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9961\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2725\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4793\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 95.60it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9973\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2143\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4799\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 92.82it/s] \n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9962\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1896\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4800\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 93.01it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9941\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1101\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4788\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 93.44it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9989\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0769\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4800\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4844\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 94.40it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9907\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7631\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4792\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5312\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 97.74it/s] \n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9894\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0978\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4808\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 96.26it/s] \n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9886\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4809\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 94.65it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9902\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8614\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4797\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5469\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 93.47it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9857\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5473\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4806\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 95.68it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9857\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7388\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4817\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 97.29it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9795\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7234\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4820\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 97.75it/s] \n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9806\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1967\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4820\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4062\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 92.04it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9791\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1692\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4531\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 96.26it/s] \n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9860\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2530\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4792\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 96.87it/s] \n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9766\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9599\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4809\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.75it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1751\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7055\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.62it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.9332\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1740\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.64it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.0604\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1805\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.0720\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1860\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.2986\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 12.1219\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.9361\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4068\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1407/1407 [00:35<00:00, 40.14it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4636\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1457\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4205\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:17<00:00, 78.63it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2346\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3969\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4321\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1407/1407 [00:15<00:00, 93.25it/s] \n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2361\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0882\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4335\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:14<00:00, 97.47it/s] \n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2369\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5988\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4328\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 101.84it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2304\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4630\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4316\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 107.71it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2293\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2775\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4354\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 108.26it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2231\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7868\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4335\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 105.03it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2274\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6491\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4345\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:14<00:00, 99.03it/s] \n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2229\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8738\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4344\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 104.92it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2296\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1577\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4348\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 108.59it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2245\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9719\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4344\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 108.28it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2242\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5195\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4353\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 107.72it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2265\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3921\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4341\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 107.37it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2219\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4408\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4355\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 1407/1407 [00:14<00:00, 99.24it/s] \n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2203\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6016\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4365\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:14<00:00, 95.60it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2103\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8626\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4383\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.68it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.2498\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7025\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.9403\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1945\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.8851\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2225\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.1536\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1995\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.9675\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1855\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.64it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 12.4864\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0682\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4315\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1563/1563 [00:37<00:00, 41.47it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6190\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1863\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3886\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 108.95it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4484\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3483\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3967\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 108.46it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4416\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3696\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3990\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3438\n",
      "100%|██████████| 1563/1563 [00:13<00:00, 111.93it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4413\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3241\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3980\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4062\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 111.10it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4316\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5408\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 110.10it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4352\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5152\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3987\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 1563/1563 [05:02<00:00,  5.16it/s] \n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4103\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0161\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4019\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 107.02it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4114\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8134\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4030\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4062\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 106.18it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4112\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8093\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4016\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3438\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 108.12it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4087\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5693\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4017\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3438\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 105.80it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4125\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2994\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4017\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 106.85it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4111\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7598\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4009\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1563/1563 [00:14<00:00, 106.14it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4053\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0742\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4037\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.46it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.2845\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6919\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.57it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.1489\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1745\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.2433\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1720\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.2022\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2175\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.2243\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1590\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.0590\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.2045\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.2300\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4387\n"
     ]
    }
   ],
   "source": [
    "# p=0.25\n",
    "\n",
    "#At each experience, train model with data from all previous experiences\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Cumulative\n",
    "    strategy = Cumulative(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Cumulative.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67759f50-0356-445f-bf72-bbbe71d1df08",
   "metadata": {},
   "source": [
    "## p=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f860054-e5b9-4a22-8678-d43ba0d4fddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:30<00:00, 25.26it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2032\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7523\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1867\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 782/782 [00:06<00:00, 121.73it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7518\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6880\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3346\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 782/782 [00:06<00:00, 118.02it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5019\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7215\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4483\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.57it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3439\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2912\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5128\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:06<00:00, 119.48it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2056\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2831\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5687\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:06<00:00, 116.81it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1122\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0292\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6014\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 118.75it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0341\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9573\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6351\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.48it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9898\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7752\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6515\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:06<00:00, 116.86it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9559\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5237\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6639\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 782/782 [00:06<00:00, 114.79it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9160\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9152\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6778\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 116.18it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8897\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0474\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6892\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 118.38it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8634\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6650\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6963\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 115.96it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8453\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7793\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7059\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 117.08it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8302\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5014\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7105\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:06<00:00, 114.60it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8119\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1240\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7156\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 116.79it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7861\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0385\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7254\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:06<00:00, 115.13it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7869\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9020\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7261\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 115.50it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8501\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7306\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 115.95it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7620\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8233\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7348\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:06<00:00, 113.28it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7528\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0623\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7374\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.68it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7529\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9553\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7400\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.03it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7403\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3932\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7424\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:06<00:00, 111.96it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7279\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4032\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:07<00:00, 108.10it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7344\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8358\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7447\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 99.51it/s] \n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7189\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2060\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7519\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:08<00:00, 95.76it/s] \n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7140\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2612\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7527\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 782/782 [00:08<00:00, 87.85it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4411\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7551\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 782/782 [00:09<00:00, 84.32it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7051\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0673\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7562\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:08<00:00, 89.76it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6985\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5441\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7572\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:08<00:00, 91.57it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6905\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1801\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7609\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.80it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6802\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7672\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.85it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 16.4419\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.75it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 16.2220\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.72it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 16.7397\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 17.8557\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.78it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 16.7596\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.7420\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3836\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 938/938 [00:28<00:00, 32.84it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3828\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4970\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6268\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:07<00:00, 120.41it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1922\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7774\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6506\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:07<00:00, 117.98it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1568\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1700\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6574\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:07<00:00, 120.15it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1345\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0212\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6649\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.99it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1092\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3027\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6688\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:07<00:00, 118.07it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0991\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8061\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6719\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7812\n",
      "100%|██████████| 938/938 [00:08<00:00, 109.84it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0842\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0867\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6750\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 116.60it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0743\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9697\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6763\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 938/938 [00:08<00:00, 112.59it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0665\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1161\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6780\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:08<00:00, 115.53it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0550\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8841\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6819\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 938/938 [00:08<00:00, 112.06it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0521\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0067\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6810\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:09<00:00, 102.17it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0465\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2038\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6854\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:08<00:00, 107.69it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0398\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0069\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6832\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 938/938 [00:08<00:00, 110.73it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0262\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2029\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6897\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 938/938 [00:08<00:00, 107.07it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0285\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2973\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6877\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 938/938 [00:09<00:00, 98.83it/s] \n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0216\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0012\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6888\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 938/938 [00:09<00:00, 100.36it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0194\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2028\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6923\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 938/938 [00:09<00:00, 100.69it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0146\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6555\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6911\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7812\n",
      "100%|██████████| 938/938 [00:09<00:00, 103.38it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0079\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8932\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6938\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:09<00:00, 99.09it/s] \n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9992\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1210\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6978\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:09<00:00, 100.89it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0052\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7537\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6932\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:09<00:00, 101.89it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0035\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3425\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6958\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 938/938 [00:09<00:00, 102.50it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9965\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0513\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6974\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:09<00:00, 104.03it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9930\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2197\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6975\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 938/938 [00:09<00:00, 101.52it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9907\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2351\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6977\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7812\n",
      "100%|██████████| 938/938 [00:09<00:00, 102.72it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9864\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9376\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7001\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:10<00:00, 93.60it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9856\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3427\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6984\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 938/938 [00:09<00:00, 99.46it/s] \n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9818\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8302\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7011\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 938/938 [00:09<00:00, 100.20it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9747\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0630\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7022\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 938/938 [00:09<00:00, 103.23it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9815\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8199\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7016\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.57it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7872\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7529\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.66it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.0718\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4260\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 15.2210\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.91it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 15.2960\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 16.6767\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 15.5364\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.8738\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4190\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1094/1094 [00:29<00:00, 36.71it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5809\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1570\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5942\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 114.26it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3884\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2443\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6119\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 115.88it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3702\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3082\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6152\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 115.76it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3540\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3481\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6191\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 115.60it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3478\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5083\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6205\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6042\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 111.17it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3371\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9715\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6231\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7292\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 110.20it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3360\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4054\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6234\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 108.22it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3258\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5697\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6261\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 111.79it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3212\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5875\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6260\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 110.79it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3183\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3553\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6237\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 109.75it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3205\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2245\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6269\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6042\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 113.55it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3078\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3215\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6281\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6042\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 109.22it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3065\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9850\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6295\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7083\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 100.93it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2992\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8701\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6303\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7708\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 99.66it/s] \n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2966\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1071\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6310\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 102.48it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2943\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6321\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 106.87it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2982\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5031\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6298\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6042\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 103.84it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2897\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3103\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6319\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 101.53it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2876\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1928\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6331\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 101.57it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2930\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4694\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6313\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6667\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 95.72it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2779\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6352\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7708\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 97.10it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2861\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3466\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6347\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 94.93it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2821\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7979\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6345\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5208\n",
      "100%|██████████| 1094/1094 [00:11<00:00, 92.43it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2769\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0550\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6358\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 102.67it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2712\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4305\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6376\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 110.35it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2760\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6674\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6364\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6042\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 109.59it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2659\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6138\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6369\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5833\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 109.28it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2668\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0774\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6390\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 1094/1094 [00:09<00:00, 109.67it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2644\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4601\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6395\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6458\n",
      "100%|██████████| 1094/1094 [00:10<00:00, 106.18it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2633\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2241\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6392\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.95it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9352\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7193\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.2829\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3990\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.56it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.4562\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3275\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.67it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 15.5587\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.69it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 16.4449\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 15.7953\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 5.7214\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4323\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1250/1250 [00:29<00:00, 41.67it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7530\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8530\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5560\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6094\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 120.52it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5955\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4761\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5706\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5781\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 117.10it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5854\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5522\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5716\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6406\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 119.97it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5722\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4592\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5741\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5312\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 119.49it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5693\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5968\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5748\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 119.28it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5661\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3217\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5752\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 119.40it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5606\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5379\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5773\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 117.82it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5723\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5756\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5781\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 117.25it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5500\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6583\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5795\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5781\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 118.07it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5534\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3064\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5767\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7188\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 115.93it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5494\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9409\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5786\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 116.48it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5522\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3673\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5781\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1250/1250 [00:10<00:00, 116.97it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5408\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2566\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7031\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 105.26it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5410\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7445\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5793\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 107.82it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5446\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8758\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5784\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 109.36it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5338\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6293\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5814\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6094\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 108.79it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5468\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6373\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5774\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6094\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 108.35it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5294\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4420\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 109.06it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5307\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7048\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5824\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5469\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 110.40it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5319\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2678\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5798\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6406\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 108.60it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5236\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4876\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5827\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5781\n",
      "100%|██████████| 1250/1250 [00:11<00:00, 109.19it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5281\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1787\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5837\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6719\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 101.21it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5230\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4711\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5850\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6406\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 96.29it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5236\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3312\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5839\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6562\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 96.34it/s] \n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5210\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4953\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5840\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5781\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 96.74it/s] \n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5176\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3929\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5849\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6719\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 97.08it/s] \n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5112\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9282\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5855\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 97.33it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5144\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6338\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5863\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5156\n",
      "100%|██████████| 1250/1250 [00:12<00:00, 98.06it/s] \n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5169\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4734\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5853\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 1250/1250 [00:13<00:00, 95.58it/s] \n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5113\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3402\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5872\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6094\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.27it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9523\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7355\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.59it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1433\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4245\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.62it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.2836\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3975\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.62it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.4287\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3185\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.60it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 16.2659\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.58it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 15.4715\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 4.3355\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4818\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1407/1407 [00:35<00:00, 39.26it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9429\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2182\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5185\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.20it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8218\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0909\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5253\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 108.09it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8131\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4775\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5280\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 108.90it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8077\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1934\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5287\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:11<00:00, 118.74it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8131\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8524\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5252\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1407/1407 [00:11<00:00, 118.12it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8046\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9153\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5282\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.79it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8022\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7726\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5290\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 104.10it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8021\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3292\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5294\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:13<00:00, 105.66it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8033\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5930\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5277\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.68it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7982\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2275\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5292\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 110.45it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7968\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4455\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5279\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 108.50it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7947\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6081\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5290\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 110.63it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7866\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1727\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5318\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.61it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7894\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9872\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5326\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 111.42it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7855\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5645\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5300\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 111.17it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7825\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7274\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5317\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.48it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7860\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6920\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5305\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 110.71it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7778\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8510\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5320\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.55it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7759\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1454\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5330\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 112.08it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7779\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0935\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5327\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 112.46it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7806\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8999\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5309\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.14it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7744\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4493\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5342\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 111.12it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7823\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4078\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5305\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 111.72it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7716\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4845\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5331\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 112.47it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7715\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8309\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5323\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 111.73it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7711\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2888\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5328\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.32it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7713\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4834\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5343\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 111.79it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7683\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8123\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5342\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 110.45it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7716\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4576\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5340\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1407/1407 [00:12<00:00, 109.67it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7673\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2826\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5343\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:19<00:00,  7.97it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.0237\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7357\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.70it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.3135\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3945\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.70it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.4162\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3585\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5911\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3065\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.72it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.9183\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1950\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.75it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 14.8901\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.0248\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4933\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 1563/1563 [00:34<00:00, 45.82it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1184\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6014\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5938\n",
      "100%|██████████| 1563/1563 [00:12<00:00, 122.56it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9937\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8450\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4884\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1563/1563 [00:12<00:00, 123.71it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9865\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4586\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5312\n",
      "100%|██████████| 1563/1563 [00:12<00:00, 121.96it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9839\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1072\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4920\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      "100%|██████████| 1563/1563 [00:12<00:00, 123.69it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9821\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7599\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4926\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 1563/1563 [00:12<00:00, 122.24it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9740\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3830\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4936\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 1563/1563 [00:12<00:00, 122.83it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9692\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2066\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4952\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4688\n",
      " 98%|█████████▊| 1536/1563 [00:12<00:00, 120.55it/s]"
     ]
    }
   ],
   "source": [
    "# p=0.05\n",
    "\n",
    "#At each experience, train model with data from all previous experiences\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN05(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Cumulative\n",
    "    strategy = Cumulative(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Cumulative.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    # strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eac454-0f7f-4a95-9396-7a36bb95f807",
   "metadata": {},
   "source": [
    "## p=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae3c0ea-9cd2-4414-95d4-649ccda728af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Parse known arguments and ignore the rest\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     args, _ \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args(sys\u001b[38;5;241m.\u001b[39margv)\n\u001b[1;32m--> 106\u001b[0m \u001b[43mmain_with_checkpointing\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 84\u001b[0m, in \u001b[0;36mmain_with_checkpointing\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# STEP 3: USE THE \"initial_exp\" to resume training\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_exp \u001b[38;5;129;01min\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mtrain_stream[initial_exp:]:\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersistent_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     strategy\u001b[38;5;241m.\u001b[39meval(benchmark\u001b[38;5;241m.\u001b[39mtest_stream, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# STEP 4: SAVE the checkpoint after training on each experience.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:211\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    205\u001b[0m     experiences: Union[TDatasetExperience, Iterable[TDatasetExperience]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    210\u001b[0m ):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mget_last_metrics()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base.py:163\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperience \u001b[38;5;129;01min\u001b[39;00m experiences_list:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:337\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[1;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_epoch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\update_type\\sgd_update.py:19\u001b[0m, in \u001b[0;36mSGDUpdate.training_epoch\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Training epoch.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    :param kwargs:\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_training:\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\benchmarks\\utils\\data_loader.py:197\u001b[0m, in \u001b[0;36mMultiDatasetDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loader()\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_loader\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loader()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:437\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_workers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\u001b[38;5;241m.\u001b[39m_reset(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\numpy\\core\\__init__.py:149\u001b[0m, in \u001b[0;36m_DType_reduce\u001b[1;34m(DType)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_DType_reduce\u001b[39m(DType):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# To pickle a DType without having to add top-level names, pickle the\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# scalar type for now (and assume that reconstruction will be possible).\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DType \u001b[38;5;129;01mis\u001b[39;00m \u001b[43mdtype\u001b[49m:\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# must pickle `np.dtype` as a singleton.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     scalar_type \u001b[38;5;241m=\u001b[39m DType\u001b[38;5;241m.\u001b[39mtype  \u001b[38;5;66;03m# pickle the scalar type for reconstruction\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#At each experience, train model with data from all previous experiences\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN01(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Cumulative\n",
    "    strategy = Cumulative(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Cumulative.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    # strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d207adf8-6537-4d0c-a963-b64438b41a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (0.17.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (2.32.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (2.11.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "323c1770-2f87-4556-b356-e5d5ad0084a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (0.17.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (3.1.37)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (2.32.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (2.11.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951df59-168e-4699-90db-c3d2017b1b63",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a701a11-b2be-4aca-a4c4-945401830080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "print(dir(wandb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d52bdaf3-b425-4993-9d57-c195a92a8259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ahmed\\Downloads\\wandb\\run-20240726_115414-02d73ps3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmedloumi456-ept/clcifar110/runs/02d73ps3' target=\"_blank\">graceful-snowball-11</a></strong> to <a href='https://wandb.ai/ahmedloumi456-ept/clcifar110' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmedloumi456-ept/clcifar110' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/clcifar110</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmedloumi456-ept/clcifar110/runs/02d73ps3' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/clcifar110/runs/02d73ps3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:02d73ps3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-snowball-11</strong> at: <a href='https://wandb.ai/ahmedloumi456-ept/clcifar110/runs/02d73ps3' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/clcifar110/runs/02d73ps3</a><br/> View project at: <a href='https://wandb.ai/ahmedloumi456-ept/clcifar110' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/clcifar110</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240726_115414-02d73ps3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:02d73ps3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d523e6b7ae104f979e2b67ae65b77a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ahmed\\Downloads\\wandb\\run-20240726_115422-sqxjs709</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmedloumi456-ept/Avalanche/runs/sqxjs709' target=\"_blank\">Test</a></strong> to <a href='https://wandb.ai/ahmedloumi456-ept/Avalanche' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmedloumi456-ept/Avalanche' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/Avalanche</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmedloumi456-ept/Avalanche/runs/sqxjs709' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/Avalanche/runs/sqxjs709</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping cuda:0 to cuda:0\n",
      "[InteractiveLogger] Resuming from checkpoint. Current time is 2024-07-26 11:54:30 +0100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Test</strong> at: <a href='https://wandb.ai/ahmedloumi456-ept/Avalanche/runs/sqxjs709' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/Avalanche/runs/sqxjs709</a><br/> View project at: <a href='https://wandb.ai/ahmedloumi456-ept/Avalanche' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/Avalanche</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240726_115422-sqxjs709\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import wandb\n",
    "\n",
    "\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # Initialize W&B with project and hyperparameters\n",
    "    wandb.init(\n",
    "        project=\"clcifar110\",\n",
    "        config={\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"architecture\": \"CNN\",\n",
    "            \"dataset\": \"CIFAR-110\",\n",
    "            \"epochs\": 30,\n",
    "            \"batch_size\": 64,\n",
    "            \"optimizer\": \"SGD\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Access W&B configuration\n",
    "    config = wandb.config\n",
    "    learning_rate = config.learning_rate\n",
    "    epochs = config.epochs\n",
    "    batch_size = config.batch_size\n",
    "    optimizer_type = config.optimizer\n",
    "\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True),\n",
    "        loss_metrics(experience=True, stream=True),\n",
    "        loggers=[InteractiveLogger(), WandBLogger()]\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Cumulative\n",
    "    strategy = Cumulative(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=batch_size,\n",
    "        train_epochs=epochs,\n",
    "        eval_mb_size=batch_size,\n",
    "        device=device,\n",
    "        evaluator=evaluation_plugin\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/Cumulative.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # Log metrics to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": strategy.clock.train_exp_epochs,\n",
    "            \"train_loss\": strategy.evaluator.get_last_metrics()[f\"Loss_Experience/train_phase/train_stream/Task000/Exp{train_exp.current_experience}\"],\n",
    "            \"train_accuracy\": strategy.evaluator.get_last_metrics()[f\"Top1_Acc_Experience/train_phase/train_stream/Task000/Exp{train_exp.current_experience}\"],\n",
    "            \"eval_loss\": strategy.evaluator.get_last_metrics()[f\"Loss_Stream/eval_phase/test_stream/Task000\"],\n",
    "            \"eval_accuracy\": strategy.evaluator.get_last_metrics()[f\"Top1_Acc_Stream/eval_phase/test_stream/Task000\"]\n",
    "        })\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "    # Finish W&B run\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c39d50-2b6f-4156-8ddc-40f8688bab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wandb --upgrade\n",
    "from avalanche.logging import WandBLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0efda041-52ce-4653-ac97-78eda9893223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:r9cuij1z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.091 MB uploaded\\r'), FloatProgress(value=0.01258007417397168, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Cumulative Method</strong> at: <a href='https://wandb.ai/ahmedloumi456-ept/CIFAR-110/runs/r9cuij1z' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/CIFAR-110/runs/r9cuij1z</a><br/> View project at: <a href='https://wandb.ai/ahmedloumi456-ept/CIFAR-110' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/CIFAR-110</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240729_152159-r9cuij1z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:r9cuij1z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6368a6e0faf2403baf4a40e6ebd51d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ahmed\\Downloads\\wandb\\run-20240729_152825-5cquc7px</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ahmedloumi456-ept/CIFAR-110/runs/5cquc7px' target=\"_blank\">Cumulative Method</a></strong> to <a href='https://wandb.ai/ahmedloumi456-ept/CIFAR-110' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ahmedloumi456-ept/CIFAR-110' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/CIFAR-110</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ahmedloumi456-ept/CIFAR-110/runs/5cquc7px' target=\"_blank\">https://wandb.ai/ahmedloumi456-ept/CIFAR-110/runs/5cquc7px</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping cuda:0 to cuda:0\n",
      "[InteractiveLogger] Resuming from checkpoint. Current time is 2024-07-29 15:28:34 +0100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    wandb_logger = WandBLogger(project_name=\"CIFAR-110\", run_name=\"Cumulative Method\")\n",
    "\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger, wandb_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Cumulative\n",
    "    strategy = Cumulative(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=evaluation_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Cumulative.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # Log some metrics manually to ensure they are being logged\n",
    "        wandb_logger.wandb.log({\"Epoch\": strategy.clock.train_epoch, \"Loss_Epoch\": strategy.loss, \"Top1_Acc_Epoch\": strategy.acc})\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5789c06-4723-4e4e-9b97-a75ea9da2d58",
   "metadata": {},
   "source": [
    "# Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91620d7b-1404-4b63-8082-6991a065313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from avalanche.training.templates import SupervisedTemplate\n",
    "# from torch.optim import Optimizer\n",
    "# from avalanche.training.templates.strategy_mixin_protocol import CriterionType\n",
    "# from\n",
    "\n",
    "# class SupervisedPlugin(BaseSGDPlugin[Template], ABC):\n",
    "#     \"\"\"ABC for SupervisedTemplate plugins.\n",
    "\n",
    "#     See `BaseTemplate` for complete description of the train/eval loop.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         Inizializes an instance of a supervised plugin.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "\n",
    "# def default_evaluator() -> EvaluationPlugin:\n",
    "#     return EvaluationPlugin(\n",
    "#         accuracy_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "#         loss_metrics(minibatch=False, epoch=True, experience=True, stream=True),\n",
    "#         loggers=default_loggers,\n",
    "#     )\n",
    "    \n",
    "# class Replay(SupervisedTemplate):\n",
    "#     \"\"\"Experience replay strategy.\n",
    "\n",
    "#     See ReplayPlugin for more details.\n",
    "#     This strategy does not use task identities.\n",
    "#     \"\"\"\n",
    "\n",
    "# def __init__(\n",
    "#         self,\n",
    "#         *,\n",
    "#         model: Module,\n",
    "#         optimizer: Optimizer,\n",
    "#         criterion: CriterionType,\n",
    "#         mem_size: int = 200,\n",
    "#         train_mb_size: int = 1,\n",
    "#         train_epochs: int = 1,\n",
    "#         eval_mb_size: Optional[int] = None,\n",
    "#         device: Union[str, torch.device] = \"cpu\",\n",
    "#         plugins: Optional[List[SupervisedPlugin]] = None,\n",
    "#         evaluator: Union[\n",
    "#             EvaluationPlugin, Callable[[], EvaluationPlugin]\n",
    "#         ] = default_evaluator,\n",
    "#         eval_every=-1,\n",
    "#         **base_kwargs\n",
    "#     ):\n",
    "#         \"\"\"Init.\n",
    "\n",
    "#         :param model: The model.\n",
    "#         :param optimizer: The optimizer to use.\n",
    "#         :param criterion: The loss criterion to use.\n",
    "#         :param mem_size: replay buffer size.\n",
    "#         :param train_mb_size: The train minibatch size. Defaults to 1.\n",
    "#         :param train_epochs: The number of training epochs. Defaults to 1.\n",
    "#         :param eval_mb_size: The eval minibatch size. Defaults to 1.\n",
    "#         :param device: The device to use. Defaults to None (cpu).\n",
    "#         :param plugins: Plugins to be added. Defaults to None.\n",
    "#         :param evaluator: (optional) instance of EvaluationPlugin for logging\n",
    "#             and metric computations.\n",
    "#         :param eval_every: the frequency of the calls to `eval` inside the\n",
    "#             training loop. -1 disables the evaluation. 0 means `eval` is called\n",
    "#             only at the end of the learning experience. Values >0 mean that\n",
    "#             `eval` is called every `eval_every` epochs and at the end of the\n",
    "#             learning experience.\n",
    "#         :param **base_kwargs: any additional\n",
    "#             :class:`~avalanche.training.BaseTemplate` constructor arguments.\n",
    "#         \"\"\"\n",
    "\n",
    "#         rp = ReplayPlugin(mem_size)\n",
    "#         if plugins is None:\n",
    "#             plugins = [rp]\n",
    "#         else:\n",
    "#             plugins.append(rp)\n",
    "#         super().__init__(\n",
    "#             model=model,\n",
    "#             optimizer=optimizer,\n",
    "#             criterion=criterion,\n",
    "#             train_mb_size=train_mb_size,\n",
    "#             train_epochs=train_epochs,\n",
    "#             eval_mb_size=eval_mb_size,\n",
    "#             device=device,\n",
    "#             plugins=plugins,\n",
    "#             evaluator=evaluator,\n",
    "#             eval_every=eval_every,\n",
    "#             **base_kwargs\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c66c991-b3bb-44ac-acdf-dcaed5076c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:29<00:00, 26.08it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2030\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7374\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1806\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 782/782 [00:07<00:00, 109.00it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8264\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6992\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2902\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 782/782 [00:08<00:00, 88.21it/s] \n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6504\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7631\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3718\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 782/782 [00:09<00:00, 80.05it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5243\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8218\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4321\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:10<00:00, 76.46it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4209\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4235\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4764\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:10<00:00, 77.52it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3295\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7075\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5159\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:09<00:00, 81.15it/s] \n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2781\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1454\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5368\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 98.63it/s] \n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2207\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2808\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5611\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:08<00:00, 96.00it/s] \n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1887\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0970\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5744\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 96.25it/s] \n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7031\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5834\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 100.53it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1294\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3826\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5962\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.13it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1139\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5636\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6022\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.54it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0908\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4183\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6135\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:07<00:00, 102.10it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0749\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8201\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6186\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.99it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0525\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4022\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6278\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.53it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0405\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5174\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6296\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.31it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0270\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8448\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6379\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.87it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0196\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0204\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6414\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.24it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0024\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1876\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.75it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9931\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5585\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.10it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9851\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2055\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6530\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.64it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9735\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0042\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6614\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:08<00:00, 93.03it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9672\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7466\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6620\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.71it/s] \n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9619\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7920\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6625\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:08<00:00, 93.81it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9554\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0754\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6641\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.63it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9460\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6013\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6677\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:08<00:00, 93.41it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9404\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9065\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6705\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:08<00:00, 95.84it/s] \n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9421\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0731\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6695\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:08<00:00, 92.57it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9338\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7674\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6728\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:08<00:00, 95.68it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9317\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3810\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6742\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.29it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8139\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7260\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.6320\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.2715\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.8055\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.9021\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 14.0473\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.9728\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3630\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.18it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.6667\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1546\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1373\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.16it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6364\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2740\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.65it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2050\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3574\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3685\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.52it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9552\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4017\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4344\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.87it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7944\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2467\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4723\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.65it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6928\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1717\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5032\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.75it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5825\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5286\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.47it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5113\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9199\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5484\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.99it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4510\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9835\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5690\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.92it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3926\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6958\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5841\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.73it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3355\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7046\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6007\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.18it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2963\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5747\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6091\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.31it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2652\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6373\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6220\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.49it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2323\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7297\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6282\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.37it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2060\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4554\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6370\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.28it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1856\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4925\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6399\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.57it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1713\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6358\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6465\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.13it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1477\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5128\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6517\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.72it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1315\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7238\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6570\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.06it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1128\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6624\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.83it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1003\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4897\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6660\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.35it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0838\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5025\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6721\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.30it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0666\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6181\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6739\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.60it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0621\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4601\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6781\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.69it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0532\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6366\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6810\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.21it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0435\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3464\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6823\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.73it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0263\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5233\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6877\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.94it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0091\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4963\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6916\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.17it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0120\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4858\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6928\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.89it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0082\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4177\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6904\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:25<00:00,  6.06it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.4917\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3145\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.13it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.5405\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5280\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.78it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.8332\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.6442\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.2040\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 12.0486\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.6729\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2100\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.57it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.2718\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6886\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.44it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6647\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9454\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3163\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.12it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1001\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5346\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4141\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.23it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8472\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2994\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4646\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.43it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6827\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2358\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5127\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.51it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6009\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0371\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5316\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.81it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4995\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9770\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5627\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.76it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4377\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8428\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5748\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.73it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3902\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6906\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5878\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.95it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3226\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7877\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6082\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.40it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2832\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6087\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6171\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.06it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2631\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8936\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6272\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.96it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2138\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7679\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6371\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.90it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1911\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7585\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6446\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.62it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1816\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7618\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.03it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1654\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0923\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.45it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1518\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8077\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6547\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.72it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1210\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7430\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6619\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.45it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1145\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7335\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6673\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.16it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0876\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6542\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6739\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.81it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0749\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6770\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.88it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0596\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5425\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6822\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.24it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0518\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5945\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6869\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.97it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0479\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6590\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6838\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.61it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0257\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5333\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6926\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.16it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0235\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5334\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6906\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.02it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0042\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4224\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7025\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.14it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9994\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5417\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6997\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.19it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9988\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4612\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6997\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.84it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9828\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5013\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7043\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:17<00:00,  9.07it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 6.2844\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1138\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 6.0234\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0730\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.3987\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.5755\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.1475\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 13.2333\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  2.00it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 13.9588\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.9184\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1217\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.40it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.6851\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.6399\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0531\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.53it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0650\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3993\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2848\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.18it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1743\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1243\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4215\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.59it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8372\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0912\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4831\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.74it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6503\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2249\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5200\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.41it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5503\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6853\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5483\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.45it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4735\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5734\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5710\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.49it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4103\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7358\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5860\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.10it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3803\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0432\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5927\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.30it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3490\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9083\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6034\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.07it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2995\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6771\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6135\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.91it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2894\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6330\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6183\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.29it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2572\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6616\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6262\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.88it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2324\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6941\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6296\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.41it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2185\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8463\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6384\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.33it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2007\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4604\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6390\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.51it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1831\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6749\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6416\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.63it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1834\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7168\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6484\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.79it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1618\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6301\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6476\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.26it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1399\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5775\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6551\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.71it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1524\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7197\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6563\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.90it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1393\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6834\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6569\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.76it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1060\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6591\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6626\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.39it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1139\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6277\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6640\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.77it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0927\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4996\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6681\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.63it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0961\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5631\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6677\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.42it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0857\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5791\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6704\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.81it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0692\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5004\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6762\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.90it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0803\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5519\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6733\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.92it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4672\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6796\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:16<00:00,  9.38it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.5002\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0961\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.2278\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0220\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 6.4765\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0660\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.04it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.5077\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5425\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 14.4606\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 14.1430\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.2317\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1111\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.9021\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.6431\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0209\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0250\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.00it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.6218\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.5573\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0093\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0125\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.43it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.3889\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.0088\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0311\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1000\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.37it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2443\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4376\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2870\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.08it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0946\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0833\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4461\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.51it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6230\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9836\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5309\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.89it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4787\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0529\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5708\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.67it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3778\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7589\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5968\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.47it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3215\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0319\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6092\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.20it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2652\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7329\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6262\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.16it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2386\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7425\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6320\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.82it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1760\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7480\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6474\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.47it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1661\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6089\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.03it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1475\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5229\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6561\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.11it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1248\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6827\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6648\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.71it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1151\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6919\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6673\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.52it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0970\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6943\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6697\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.51it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0878\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7331\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6727\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.50it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0761\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4336\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6776\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.17it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0584\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5248\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6822\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.05it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0416\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4619\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6851\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.92it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0345\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5561\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6855\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.97it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0200\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4682\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6901\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.96it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0138\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4941\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6954\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.66it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0077\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5167\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6964\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.61it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9917\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5010\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6965\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.09it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9898\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5273\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6998\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.46it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9790\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5879\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6998\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.16it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9823\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4620\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7002\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.65it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9751\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5050\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7063\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:17<00:00,  9.00it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.6191\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0503\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 9.0530\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0195\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 7.7758\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0385\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 6.9899\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0205\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.3667\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5740\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 14.2848\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.2566\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0904\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.29it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.6349\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5102\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1337\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.59it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1535\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3682\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.50it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9761\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2644\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4648\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.86it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6877\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9144\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5191\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.42it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5362\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6983\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5531\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.76it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4481\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6822\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5755\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.48it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3749\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8452\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5951\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.11it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3321\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7907\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6014\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.68it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3048\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6025\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6079\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.26it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2756\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5851\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6163\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.49it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2567\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6545\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6254\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.75it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2331\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6516\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6315\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.16it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2071\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5017\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6356\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.11it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1985\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5730\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6353\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.00it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1802\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5116\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6472\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8250\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.33it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1732\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6833\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6455\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.02it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1508\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4604\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6502\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8625\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.51it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1480\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4607\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6551\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.88it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1363\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4351\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6546\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.56it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1232\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4232\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6590\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.99it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1219\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5184\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6634\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.37it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1038\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6221\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6670\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.39it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0861\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5286\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6697\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.39it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0848\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4208\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6691\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.96it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0741\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5305\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6734\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.60it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0778\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6012\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6735\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.57it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0707\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3394\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6769\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.74it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0542\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5096\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6795\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8500\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.94it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0577\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4324\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6795\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.67it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0393\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4251\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6822\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:17<00:00,  8.83it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.5708\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0124\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.3246\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0225\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.89it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.7734\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0070\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [41:12:01<00:00, 4635.06s/it]      \n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 7.2320\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0395\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.40it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 1.5147\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.5315\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.5522\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0693\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.supervised.strategy_wrappers import Replay\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Replay\n",
    "    strategy = Replay(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        mem_size=200,               # Size of the replay buffer\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c57865-347f-48bc-bee6-2ae9f3369335",
   "metadata": {},
   "source": [
    "#  GenerativeReplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fa9fe6b-4d49-4588-baab-d5519fd640ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Generative Replay Strategy\\n\\n    This implements Deep Generative Replay for a Scholar consisting of a Solver\\n    and Generator as described in https://arxiv.org/abs/1705.08690.\\n\\n    The model parameter should contain the solver. As an optional input\\n    a generator can be wrapped in a trainable strategy\\n    and passed to the generator_strategy parameter. By default a simple VAE will\\n    be used as generator.\\n\\n    For the case where the Generator is the model itself that is to be trained,\\n    please simply add the GenerativeReplayPlugin() when instantiating\\n    your Generator's strategy.\\n\\n    See GenerativeReplayPlugin for more details.\\n    This strategy does not use task identities.\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  GenerativeReplay:\n",
    "\"\"\"\n",
    "    Generative Replay Strategy\n",
    "\n",
    "    This implements Deep Generative Replay for a Scholar consisting of a Solver\n",
    "    and Generator as described in https://arxiv.org/abs/1705.08690.\n",
    "\n",
    "    The model parameter should contain the solver. As an optional input\n",
    "    a generator can be wrapped in a trainable strategy\n",
    "    and passed to the generator_strategy parameter. By default a simple VAE will\n",
    "    be used as generator.\n",
    "\n",
    "    For the case where the Generator is the model itself that is to be trained,\n",
    "    please simply add the GenerativeReplayPlugin() when instantiating\n",
    "    your Generator's strategy.\n",
    "\n",
    "    See GenerativeReplayPlugin for more details.\n",
    "    This strategy does not use task identities.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8452760-207f-442d-8503-a02f14962012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GenerativeReplay(SupervisedTemplate):\n",
    "\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         *,\n",
    "#         model: Module,\n",
    "#         optimizer: Optimizer,\n",
    "#         criterion: CriterionType = CrossEntropyLoss(),\n",
    "#         train_mb_size: int = 1,\n",
    "#         train_epochs: int = 1,\n",
    "#         eval_mb_size: Optional[int] = None,\n",
    "#         device: Union[str, torch.device] = \"cpu\",\n",
    "#         plugins: Optional[List[SupervisedPlugin]] = None,\n",
    "#         evaluator: Union[\n",
    "#             EvaluationPlugin, Callable[[], EvaluationPlugin]\n",
    "#         ] = default_evaluator,\n",
    "#         eval_every=-1,\n",
    "#         generator_strategy: Optional[BaseTemplate] = None,\n",
    "#         replay_size: Optional[int] = None,\n",
    "#         increasing_replay_size: bool = False,\n",
    "#         **base_kwargs\n",
    "#     ):\n",
    "#         \"\"\"\n",
    "#         Creates an instance of Generative Replay Strategy\n",
    "#         for a solver-generator pair.\n",
    "\n",
    "#         :param model: The solver model.\n",
    "#         :param optimizer: The optimizer to use.\n",
    "#         :param criterion: The loss criterion to use.\n",
    "#         :param train_mb_size: The train minibatch size. Defaults to 1.\n",
    "#         :param train_epochs: The number of training epochs. Defaults to 1.\n",
    "#         :param eval_mb_size: The eval minibatch size. Defaults to 1.\n",
    "#         :param device: The device to use. Defaults to None (cpu).\n",
    "#         :param plugins: Plugins to be added. Defaults to None.\n",
    "#         :param evaluator: (optional) instance of EvaluationPlugin for logging\n",
    "#             and metric computations.\n",
    "#         :param eval_every: the frequency of the calls to `eval` inside the\n",
    "#             training loop. -1 disables the evaluation. 0 means `eval` is called\n",
    "#             only at the end of the learning experience. Values >0 mean that\n",
    "#             `eval` is called every `eval_every` epochs and at the end of the\n",
    "#             learning experience.\n",
    "#         :param generator_strategy: A trainable strategy with a generative model,\n",
    "#             which employs GenerativeReplayPlugin. Defaults to None.\n",
    "#         :param **base_kwargs: any additional\n",
    "#             :class:`~avalanche.training.BaseTemplate` constructor arguments.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Check if user inputs a generator model\n",
    "#         # (which is wrapped in a strategy that can be trained and\n",
    "#         # uses the GenerativeReplayPlugin;\n",
    "#         # see 'VAETraining\" as an example below.)\n",
    "#         if generator_strategy is not None:\n",
    "#             self.generator_strategy = generator_strategy\n",
    "#         else:\n",
    "#             # By default we use a fully-connected VAE as the generator.\n",
    "#             # model:\n",
    "#             generator = MlpVAE((1, 28, 28), nhid=2, device=device)\n",
    "#             # optimzer:\n",
    "#             lr = 0.01\n",
    "#             from torch.optim import Adam\n",
    "\n",
    "#             to_optimize: List[Parameter] = list(\n",
    "#                 filter(lambda p: p.requires_grad, generator.parameters())\n",
    "#             )\n",
    "#             optimizer_generator = Adam(\n",
    "#                 to_optimize,\n",
    "#                 lr=lr,\n",
    "#                 weight_decay=0.0001,\n",
    "#             )\n",
    "#             # strategy (with plugin):\n",
    "#             self.generator_strategy = VAETraining(\n",
    "#                 model=generator,\n",
    "#                 optimizer=optimizer_generator,\n",
    "#                 criterion=VAE_loss,\n",
    "#                 train_mb_size=train_mb_size,\n",
    "#                 train_epochs=train_epochs,\n",
    "#                 eval_mb_size=eval_mb_size,\n",
    "#                 device=device,\n",
    "#                 plugins=[\n",
    "#                     GenerativeReplayPlugin(\n",
    "#                         replay_size=replay_size,\n",
    "#                         increasing_replay_size=increasing_replay_size,\n",
    "#                     )\n",
    "#                 ],\n",
    "#             )\n",
    "\n",
    "#         rp = GenerativeReplayPlugin(\n",
    "#             generator_strategy=self.generator_strategy,\n",
    "#             replay_size=replay_size,\n",
    "#             increasing_replay_size=increasing_replay_size,\n",
    "#         )\n",
    "\n",
    "#         tgp = TrainGeneratorAfterExpPlugin()\n",
    "\n",
    "#         if plugins is None:\n",
    "#             plugins = [tgp, rp]\n",
    "#         else:\n",
    "#             plugins.append(tgp)\n",
    "#             plugins.append(rp)\n",
    "\n",
    "#         super().__init__(\n",
    "#             model=model,\n",
    "#             optimizer=optimizer,\n",
    "#             criterion=criterion,\n",
    "#             train_mb_size=train_mb_size,\n",
    "#             train_epochs=train_epochs,\n",
    "#             eval_mb_size=eval_mb_size,\n",
    "#             device=device,\n",
    "#             plugins=plugins,\n",
    "#             evaluator=evaluator,\n",
    "#             eval_every=eval_every,\n",
    "#             **base_kwargs\n",
    "#         )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ba55ebb-6a6a-48b0-b2a8-9207c680f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a simple VAE generator model (example, adjust to your needs)\n",
    "# class MlpVAE(nn.Module):\n",
    "#     def __init__(self, input_shape, nhid, device):\n",
    "#         super(MlpVAE, self).__init__()\n",
    "#         self.device = device\n",
    "#         self.fc1 = nn.Linear(np.prod(input_shape), nhid)\n",
    "#         self.fc21 = nn.Linear(nhid, nhid)\n",
    "#         self.fc22 = nn.Linear(nhid, nhid)\n",
    "#         self.fc3 = nn.Linear(nhid, np.prod(input_shape))\n",
    "#         self.fc4 = nn.Linear(nhid, np.prod(input_shape))\n",
    "    \n",
    "#     def encode(self, x):\n",
    "#         h1 = F.relu(self.fc1(x.view(-1, np.prod(x.size()[1:]))))\n",
    "#         return self.fc21(h1), self.fc22(h1)\n",
    "    \n",
    "#     def reparameterize(self, mu, logvar):\n",
    "#         std = torch.exp(0.5*logvar)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return mu + eps*std\n",
    "    \n",
    "#     def decode(self, z):\n",
    "#         h3 = F.relu(self.fc3(z))\n",
    "#         return torch.sigmoid(self.fc4(h3))\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         mu, logvar = self.encode(x)\n",
    "#         z = self.reparameterize(mu, logvar)\n",
    "#         return self.decode(z), mu, logvar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0619626f-a511-4bd4-b2fb-96896e1f8d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:31<00:00, 24.71it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1973\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2410\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1830\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.22it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8342\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8077\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2873\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.27it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6508\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5557\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3739\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.64it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5197\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2793\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4336\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.80it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4167\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4175\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4806\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 109.25it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3334\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6090\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5148\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:07<00:00, 107.19it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2769\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2250\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5407\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.36it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2312\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3158\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5569\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.07it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1866\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9365\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5720\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.68it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1571\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5117\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5852\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 782/782 [00:08<00:00, 92.99it/s] \n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1297\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9507\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5969\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:09<00:00, 84.59it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1098\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1058\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6033\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:09<00:00, 83.90it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0834\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3171\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6133\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:09<00:00, 85.49it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0684\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9133\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6196\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:09<00:00, 84.16it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0492\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9300\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6292\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:09<00:00, 85.89it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0390\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4387\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6346\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:09<00:00, 84.10it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0189\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6387\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:08<00:00, 90.45it/s] \n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0141\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2696\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6437\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 105.43it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0030\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7787\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.80it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9899\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8557\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6525\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:07<00:00, 98.83it/s] \n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9828\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6566\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:08<00:00, 91.67it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9722\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4973\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6599\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:08<00:00, 93.61it/s] \n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9677\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5532\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6624\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:08<00:00, 91.36it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9561\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3217\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6656\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 97.41it/s] \n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9524\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0320\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6682\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 90.69it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9449\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9583\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6706\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:08<00:00, 95.21it/s] \n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9388\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0499\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6725\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.83it/s] \n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9322\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7300\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6763\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.18it/s] \n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9299\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9206\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6757\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 92.65it/s] \n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7016\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6783\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "-- >> Start of training phase << --\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 139\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Parse known arguments and ignore the rest\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     args, _ \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args(sys\u001b[38;5;241m.\u001b[39margv)\n\u001b[1;32m--> 139\u001b[0m \u001b[43mmain_with_checkpointing\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 117\u001b[0m, in \u001b[0;36mmain_with_checkpointing\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# STEP 3: USE THE \"initial_exp\" to resume training\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_exp \u001b[38;5;129;01min\u001b[39;00m benchmark\u001b[38;5;241m.\u001b[39mtrain_stream[initial_exp:]:\n\u001b[1;32m--> 117\u001b[0m     \u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersistent_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     strategy\u001b[38;5;241m.\u001b[39meval(benchmark\u001b[38;5;241m.\u001b[39mtest_stream, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# STEP 4: SAVE the checkpoint after training on each experience.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:211\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    205\u001b[0m     experiences: Union[TDatasetExperience, Iterable[TDatasetExperience]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    210\u001b[0m ):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mget_last_metrics()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base.py:164\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_exp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperience, eval_streams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_after_training_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_cleanup()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base.py:323\u001b[0m, in \u001b[0;36mBaseTemplate._after_training_exp\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_after_training_exp\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 323\u001b[0m     \u001b[43mtrigger_plugins\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mafter_training_exp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\utils.py:75\u001b[0m, in \u001b[0;36mtrigger_plugins\u001b[1;34m(strategy, event, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mplugins:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(p, event):\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\plugins\\generative_replay.py:171\u001b[0m, in \u001b[0;36mTrainGeneratorAfterExpPlugin.after_training_exp\u001b[1;34m(self, strategy, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plugin \u001b[38;5;129;01min\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mplugins:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(plugin) \u001b[38;5;129;01mis\u001b[39;00m GenerativeReplayPlugin:\n\u001b[1;32m--> 171\u001b[0m         \u001b[43mplugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:211\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    205\u001b[0m     experiences: Union[TDatasetExperience, Iterable[TDatasetExperience]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    210\u001b[0m ):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mget_last_metrics()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base.py:163\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperience \u001b[38;5;129;01min\u001b[39;00m experiences_list:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:337\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[1;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_epoch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\update_type\\sgd_update.py:35\u001b[0m, in \u001b[0;36mSGDUpdate.training_epoch\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Loss & Backward\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_backward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\avalanche\\training\\templates\\problem_type\\supervised_problem.py:43\u001b[0m, in \u001b[0;36mSupervisedProblem.criterion\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcriterion\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loss function for supervised problems.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_criterion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmb_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmb_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DDP\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Optional, Sequence, List, Union\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch import sigmoid\n",
    "from torch.nn import Module, CrossEntropyLoss\n",
    "from torch.optim import Optimizer\n",
    "from avalanche.models.packnet import PackNetModel, PackNetModule, PackNetPlugin\n",
    "\n",
    "from avalanche.models.pnn import PNN\n",
    "from avalanche.training.plugins.evaluation import (\n",
    "    default_evaluator,\n",
    "    default_loggers,\n",
    ")\n",
    "from avalanche.training.plugins import (\n",
    "    SupervisedPlugin,\n",
    "    CWRStarPlugin,\n",
    "    ReplayPlugin,\n",
    "    GenerativeReplayPlugin,\n",
    "    TrainGeneratorAfterExpPlugin,\n",
    "    GDumbPlugin,\n",
    "    LwFPlugin,\n",
    "    AGEMPlugin,\n",
    "    GEMPlugin,\n",
    "    EWCPlugin,\n",
    "    EvaluationPlugin,\n",
    "    SynapticIntelligencePlugin,\n",
    "    CoPEPlugin,\n",
    "    GSS_greedyPlugin,\n",
    "    LFLPlugin,\n",
    "    MASPlugin,\n",
    "    BiCPlugin,\n",
    "    MIRPlugin,\n",
    "    FromScratchTrainingPlugin,\n",
    ")\n",
    "from avalanche.training.templates.base import BaseTemplate\n",
    "from avalanche.training.templates import SupervisedTemplate\n",
    "from avalanche.evaluation.metrics import loss_metrics\n",
    "from avalanche.models.generator import MlpVAE, VAE_loss\n",
    "from avalanche.models.expert_gate import AE_loss\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.training.templates.strategy_mixin_protocol import CriterionType\n",
    "from avalanche.training import GenerativeReplay\n",
    "from torch.optim import Adam, SGD\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "import sys\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Define the VAE generator model and its training strategy\n",
    "    generator = MlpVAE((3, 32, 32), nhid=256, device=device)\n",
    "    optimizer_generator = Adam(generator.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "    \n",
    "    # Define the VAE training strategy\n",
    "    from avalanche.training.templates import SupervisedTemplate\n",
    "    from avalanche.training.plugins import GenerativeReplayPlugin, TrainGeneratorAfterExpPlugin\n",
    "    \n",
    "    class VAETraining(SupervisedTemplate):\n",
    "        # Implementation of VAE training strategy\n",
    "        pass\n",
    "\n",
    "    vae_training_strategy = VAETraining(\n",
    "        model=generator,\n",
    "        optimizer=optimizer_generator,\n",
    "        criterion=CrossEntropyLoss(),\n",
    "        train_mb_size=64,\n",
    "        train_epochs=30,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        plugins=[GenerativeReplayPlugin(replay_size=200)],\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Create the Generative Replay strategy\n",
    "    strategy = GenerativeReplay(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=30,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        generator_strategy=vae_training_strategy,  # The generator strategy\n",
    "        replay_size=200,  # Size of the replay buffer\n",
    "        increasing_replay_size=False,  # Whether to increase the replay buffer size over time\n",
    "        evaluator=EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loggers=[InteractiveLogger()],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/GenerativeReplay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50808b6-e2ef-4c72-bae2-6d45f7152095",
   "metadata": {},
   "source": [
    "# EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d9c80-8dda-4a2f-88a8-5b68351b7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWC :\n",
    "\"\"\"Elastic Weight Consolidation (EWC) strategy.\n",
    "\n",
    "    See EWC plugin for details.\n",
    "    This strategy does not use task identities.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056970f-eae7-4b8f-821d-3c73510c621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWC(SupervisedTemplate):\n",
    "    \"\"\"Elastic Weight Consolidation (EWC) strategy.\n",
    "\n",
    "    See EWC plugin for details.\n",
    "    This strategy does not use task identities.\n",
    "    \"\"\"\n",
    "\n",
    "def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model: Module,\n",
    "        optimizer: Optimizer,\n",
    "        criterion: CriterionType,\n",
    "        ewc_lambda: float,\n",
    "        mode: str = \"separate\",\n",
    "        decay_factor: Optional[float] = None,\n",
    "        keep_importance_data: bool = False,\n",
    "        train_mb_size: int = 1,\n",
    "        train_epochs: int = 1,\n",
    "        eval_mb_size: Optional[int] = None,\n",
    "        device: Union[str, torch.device] = \"cpu\",\n",
    "        plugins: Optional[List[SupervisedPlugin]] = None,\n",
    "        evaluator: Union[\n",
    "            EvaluationPlugin, Callable[[], EvaluationPlugin]\n",
    "        ] = default_evaluator,\n",
    "        eval_every=-1,\n",
    "        **base_kwargs\n",
    "    ):\n",
    "        \"\"\"Init.\n",
    "\n",
    "        :param model: The model.\n",
    "        :param optimizer: The optimizer to use.\n",
    "        :param criterion: The loss criterion to use.\n",
    "        :param ewc_lambda: hyperparameter to weigh the penalty inside the total\n",
    "               loss. The larger the lambda, the larger the regularization.\n",
    "        :param mode: `separate` to keep a separate penalty for each previous\n",
    "               experience. `onlinesum` to keep a single penalty summed over all\n",
    "               previous tasks. `onlineweightedsum` to keep a single penalty\n",
    "               summed with a decay factor over all previous tasks.\n",
    "        :param decay_factor: used only if mode is `onlineweightedsum`.\n",
    "               It specify the decay term of the importance matrix.\n",
    "        :param keep_importance_data: if True, keep in memory both parameter\n",
    "                values and importances for all previous task, for all modes.\n",
    "                If False, keep only last parameter values and importances.\n",
    "                If mode is `separate`, the value of `keep_importance_data` is\n",
    "                set to be True.\n",
    "        :param train_mb_size: The train minibatch size. Defaults to 1.\n",
    "        :param train_epochs: The number of training epochs. Defaults to 1.\n",
    "        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n",
    "        :param device: The device to use. Defaults to None (cpu).\n",
    "        :param plugins: Plugins to be added. Defaults to None.\n",
    "        :param evaluator: (optional) instance of EvaluationPlugin for logging\n",
    "            and metric computations.\n",
    "        :param eval_every: the frequency of the calls to `eval` inside the\n",
    "            training loop. -1 disables the evaluation. 0 means `eval` is called\n",
    "            only at the end of the learning experience. Values >0 mean that\n",
    "            `eval` is called every `eval_every` epochs and at the end of the\n",
    "            learning experience.\n",
    "        :param base_kwargs: any additional\n",
    "            :class:`~avalanche.training.BaseTemplate` constructor arguments.\n",
    "        \"\"\"\n",
    "        ewc = EWCPlugin(ewc_lambda, mode, decay_factor, keep_importance_data)\n",
    "        if plugins is None:\n",
    "            plugins = [ewc]\n",
    "        else:\n",
    "            plugins.append(ewc)\n",
    "\n",
    "        super().__init__(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            train_mb_size=train_mb_size,\n",
    "            train_epochs=train_epochs,\n",
    "            eval_mb_size=eval_mb_size,\n",
    "            device=device,\n",
    "            plugins=plugins,\n",
    "            evaluator=evaluator,\n",
    "            eval_every=eval_every,\n",
    "            **base_kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a751ee-59f0-4481-9879-2f5a900f670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from avalanche.benchmarks.datasets import CIFAR10, CIFAR100\n",
    "from avalanche.benchmarks.utils import classification_dataset\n",
    "import avalanche.benchmarks.scenarios.dataset_scenario\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import (\n",
    "    Cumulative, Naive, ICaRL, LwF, EWC, GenerativeReplay, JointTraining, CWRStar\n",
    ")\n",
    "\n",
    "from avalanche.evaluation.metrics import (\n",
    "    Accuracy, TaskAwareAccuracy, accuracy_metrics, loss_metrics, forgetting_metrics,\n",
    "    cpu_usage_metrics, gpu_usage_metrics, MAC_metrics\n",
    ")\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "from avalanche.training.determinism.rng_manager import RNGManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1b89d-4edd-484a-88ea-15e6ccc10489",
   "metadata": {},
   "source": [
    "## ewc_lambda = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c774da-7b9a-4672-96c7-60f82c3d7d56",
   "metadata": {},
   "source": [
    "## ewc cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f6b720-a844-415b-97fe-4bb567720523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.54it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8423\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7008\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5753\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.27it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6176\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4856\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6727\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.15it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5725\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5795\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7074\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.74it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5414\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7046\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7308\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.93it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5139\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5656\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7544\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.76it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4912\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5606\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7668\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.69it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4394\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7754\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.47it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4576\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5428\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7856\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.29it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4573\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7899\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 107.46it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4232\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5106\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8122\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.42it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4007\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2144\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8180\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.23it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4156\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4716\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8165\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 106.02it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4073\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8074\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8200\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.26it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3715\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3590\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8382\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.28it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4008\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6994\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8248\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 99.12it/s] \n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3675\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4204\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8411\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.83it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3607\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1530\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8435\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.82it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3473\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8497\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.41it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3414\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4872\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8512\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.13it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3510\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2029\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8495\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.90it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3342\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8617\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.66it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3209\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4068\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8628\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.28it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3221\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4846\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8654\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.69it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3219\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1927\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8656\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.54it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3084\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5269\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8749\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.56it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3147\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2687\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8670\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.44it/s] \n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3151\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3360\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8661\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.40it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2892\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2833\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8782\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.04it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2878\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2468\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8791\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.96it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2855\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3988\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8834\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3016\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8835\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.6914\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.8789\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.0085\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 10.7102\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.1181\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1767\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0058\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6019\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5423\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.68it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5099\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2833\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7794\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.05it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3640\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2631\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8509\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.32it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3020\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4480\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8823\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.16it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2861\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1736\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8877\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.32it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2639\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2600\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8998\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.05it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2361\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0955\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9083\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.69it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2379\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1982\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9078\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.60it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2289\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1468\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9144\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.47it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2127\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3428\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9171\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.44it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2098\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5685\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9205\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.84it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2126\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2273\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9216\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.61it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2000\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0289\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9264\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.83it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1878\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3461\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9286\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.72it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1944\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0691\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9266\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.75it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1738\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0947\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9350\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.92it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1722\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2070\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9349\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.23it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1691\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0935\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9380\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.15it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1710\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0345\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9357\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.57it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1688\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4718\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9349\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.91it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1756\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2050\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9344\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.81it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1677\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1302\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9355\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.04it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1539\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0429\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.04it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1507\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0982\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9437\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.88it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1610\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0394\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9414\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.91it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1453\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5321\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9457\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.99it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1467\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0539\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9466\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.95it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1460\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0681\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9481\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.73it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1358\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0365\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9493\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.98it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1420\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1923\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9476\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.9203\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1526\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9560\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.8598\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.9349\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 10.2455\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.2226\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1912\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:19<00:00,  8.12it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2914\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3508\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4826\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.45it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4593\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3473\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8216\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.94it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3584\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3007\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8621\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.28it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3023\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2352\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8904\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.81it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2710\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0932\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9003\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.11it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2302\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0530\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9178\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.04it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2055\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2714\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9251\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.60it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1803\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9383\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.82it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1658\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1192\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9442\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.78it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1618\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3780\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9433\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.62it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1435\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0852\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.04it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1336\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0618\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9531\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [03:39<00:00,  1.40s/it]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1347\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1095\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9534\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.43it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1347\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0483\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9546\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.03it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1266\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0200\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9589\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.77it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1192\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3504\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9590\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.14it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1169\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1821\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9616\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.06it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1262\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1573\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9561\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.85it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1183\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1658\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9619\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.47it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1144\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2073\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9618\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.72it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1008\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1370\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9665\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.59it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1107\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5943\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9637\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.54it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1150\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0387\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9605\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.74it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0926\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1470\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9689\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.66it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1036\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0512\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9670\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.72it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0930\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0733\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9696\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.09it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0888\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0322\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9695\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.98it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1022\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1339\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9663\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.14it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0838\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1896\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9708\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.79it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.0985\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0148\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9680\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.3972\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.7129\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1806\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9355\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.6430\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.2335\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.6334\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1871\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.85it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4525\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7542\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3960\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.04it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7096\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7821\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5802\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.70it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4600\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2678\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8126\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.75it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3509\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1938\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8754\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.36it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3400\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4859\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8772\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.54it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3066\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2353\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8908\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.07it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2691\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0778\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9059\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.41it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2658\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3675\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9053\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.11it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2499\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1835\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9115\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.65it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2278\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2065\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9233\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.11it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2170\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0956\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9279\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.73it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2290\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1311\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9215\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.11it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2042\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2742\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9322\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.12it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1982\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0959\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9342\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.53it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1958\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1787\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9322\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.07it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1875\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1554\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9365\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.29it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1862\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2781\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9389\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.25it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1828\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1971\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9397\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.74it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1771\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4742\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9406\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.69it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1741\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2270\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9417\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.80it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1688\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1830\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9409\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.38it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1685\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2227\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9422\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.10it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1602\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1052\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9473\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.64it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1571\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0407\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9495\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.58it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1546\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1511\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9502\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.28it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1559\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1854\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9471\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.23it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1467\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0533\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9529\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.38it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1516\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1491\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9503\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.49it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1439\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0829\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9536\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.17it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.1389\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0620\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9524\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.9287\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.5024\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.9231\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1561\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9610\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.9092\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.4839\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1922\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.56it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3221\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8531\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4443\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.63it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7625\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8805\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4820\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.08it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7678\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7408\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4916\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:04<00:00, 37.92it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7528\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4982\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.45it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.7522\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9008\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5074\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.63it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6854\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8291\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6482\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:04<00:00, 39.14it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5569\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5928\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7571\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:04<00:00, 36.92it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4938\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2629\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7981\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.33it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4526\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4025\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8229\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.36it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4310\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3709\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8360\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:04<00:00, 39.20it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4063\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3285\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:04<00:00, 37.38it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3819\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3967\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8589\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.98it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3463\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3325\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8743\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.63it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3242\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2740\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8863\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.50it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2941\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0961\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8932\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.13it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2871\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1392\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8962\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.32it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2778\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7115\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8991\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.65it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2704\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1070\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9022\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:04<00:00, 39.20it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2675\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0772\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9056\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.66it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2616\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1727\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9057\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.37it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2683\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1014\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9029\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.81it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2529\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1661\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.87it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2547\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1205\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9144\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.18it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2599\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2772\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9079\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.95it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2461\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0833\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9132\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.15it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2349\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1134\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9195\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.23it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2417\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3844\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9135\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:04<00:00, 37.86it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2446\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0663\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9134\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.81it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2298\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4031\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9197\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.45it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2315\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1363\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9205\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 16.0350\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.07it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.4949\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.1016\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.7299\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2045\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9245\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.3132\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1849\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from torch.optim import SGD\n",
    "import sys\n",
    "import torch\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR10(5)\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the EWC strategy\n",
    "    ewc_lambda = 0.1  # Regularization strength for EWC\n",
    "    strategy = EWC(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=30,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        ewc_lambda=ewc_lambda,\n",
    "        evaluator=EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loggers=[InteractiveLogger()],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d89ed6-4eba-4c1b-8ed3-73730ab41833",
   "metadata": {},
   "source": [
    "## ewc cifar10 (ewc_lambda = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bdb6eb-c003-4cad-8879-793bc76b9615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:35<00:00,  4.38it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8426\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5758\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.23it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6169\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4769\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6714\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.50it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5721\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5797\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7079\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.55it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5415\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6856\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7303\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.66it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5147\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5528\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7529\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.27it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4924\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5746\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7676\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.50it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4764\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3338\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7759\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.91it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4561\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5794\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7862\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4759\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8030\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.21it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.5243\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.09it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.1510\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:31<00:00,  1.01it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.1460\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.5031\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.1601\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1606\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:38<00:00,  4.11it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9953\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5735\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5073\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.36it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6178\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4485\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6991\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.22it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5217\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3888\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7648\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.72it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4114\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2829\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8233\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.62it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3730\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3688\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8435\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.52it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3244\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3046\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8664\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.37it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3044\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2650\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8752\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.75it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2688\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3050\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8898\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.08it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.2437\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4752\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.7420\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:32<00:00,  1.01s/it]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.2270\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.4860\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:29<00:00,  1.07it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.5839\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.2032\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1484\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:33<00:00,  4.74it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0527\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5740\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5666\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.71it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4607\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8157\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.36it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4126\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5559\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8334\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.37it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3740\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4196\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8532\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.98it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3156\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0897\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8780\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.47it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2876\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1600\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.26it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2493\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9077\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:04<00:00, 36.22it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2421\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1279\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9111\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.61it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.7363\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.63it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.4695\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.5131\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.7215\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.4750\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.7579\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.9904\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1443\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.70it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3931\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7516\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4187\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.61it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6389\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4205\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6596\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.29it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4574\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4420\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8157\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.35it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3776\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1397\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8455\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.50it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3573\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8581\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.71it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3193\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5871\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8737\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.80it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3096\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3754\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8796\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.39it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2700\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.0703\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8945\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.9336\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 7.4836\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.2761\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4386\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.7600\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.6736\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.7611\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1520\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0258\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4493\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6446\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.70it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4640\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2954\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8088\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 39.68it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4113\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6763\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8376\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.87it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3726\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2563\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8574\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:04<00:00, 39.09it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3566\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1878\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8648\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.86it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3428\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2116\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8666\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.03it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3192\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2188\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8771\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.78it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3222\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2463\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8767\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.5801\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.9916\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.8039\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 10.9234\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.4766\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.8395\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.7551\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1679\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from torch.optim import SGD\n",
    "import sys\n",
    "import torch\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR10(5)\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the EWC strategy\n",
    "    ewc_lambda = 0.01  # Regularization strength for EWC\n",
    "    strategy = EWC(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=8,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        ewc_lambda=ewc_lambda,\n",
    "        evaluator=EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loggers=[InteractiveLogger()],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb759e6-8942-4c01-a40d-f03b41649e0f",
   "metadata": {},
   "source": [
    "## ewc cifar10 (ewc_lambda = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c79cb95-be69-42eb-a98d-6deae9273585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:25<00:00,  6.15it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8421\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7030\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5763\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 85.78it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6165\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4820\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6730\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:01<00:00, 87.28it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5718\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5924\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7094\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 88.29it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5408\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6861\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7316\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 79.67it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5151\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5198\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7508\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 83.99it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4937\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5886\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7680\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 84.88it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4750\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3481\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7747\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:01<00:00, 81.88it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4574\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7868\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4803\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8030\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.4617\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.0322\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.83it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.0152\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.4261\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.0831\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1606\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:19<00:00,  7.96it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1785\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5287\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5219\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.98it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6079\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5178\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7345\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.51it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4521\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3853\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8308\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.52it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3823\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2696\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8578\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.71it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3523\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2529\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8726\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.37it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3570\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2201\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8747\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.73it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3228\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2600\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8838\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.87it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3007\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2107\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8976\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.88it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.0610\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2698\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9035\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.1816\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.8842\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 10.5060\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.1805\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1807\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.73it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5092\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7245\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5304\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.21it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4030\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2034\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8796\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.21it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3318\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5019\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8991\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.27it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3150\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4587\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9034\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.83it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2999\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9107\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 52.17it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2941\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2140\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9126\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.08it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2600\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3951\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9243\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.99it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2525\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1959\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9276\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.8758\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 9.9425\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2221\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9520\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.2898\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 13.2255\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.5111\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1904\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.75it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2234\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8471\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4833\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.11it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5207\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2922\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8413\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.07it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4288\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3285\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8742\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.98it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4093\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4058\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8862\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.69it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3610\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6440\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9009\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.68it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3706\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3779\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8961\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.91it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3689\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4667\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8945\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.29it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3334\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1636\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9100\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.1647\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 7.6682\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 7.8570\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2112\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9275\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.0808\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.1964\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1855\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.70it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2152\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6495\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4303\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.11it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5400\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3115\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8402\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.47it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5158\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4772\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8487\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.98it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4745\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4674\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8600\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.11it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4711\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2864\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8607\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.83it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4409\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4942\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8709\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.22it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4499\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5722\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8674\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.36it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4428\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3196\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8660\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.04it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.7590\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 9.1475\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.6148\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.6447\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.3339\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.8750\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.3000\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1750\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from torch.optim import SGD\n",
    "import sys\n",
    "import torch\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR10(5)\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the EWC strategy\n",
    "    ewc_lambda = 100  # Regularization strength for EWC\n",
    "    strategy = EWC(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=8,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        ewc_lambda=ewc_lambda,\n",
    "        evaluator=EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loggers=[InteractiveLogger()],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09103467-ea8e-4e86-b4ca-633cbeb7898d",
   "metadata": {},
   "source": [
    "## ewc cifar10 (ewc_lambda = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe5e94c-94f4-44ed-a51c-02b1892a7186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.37it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.8417\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7035\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5770\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.71it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6160\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4684\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6716\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.24it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5726\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5980\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7082\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.20it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5382\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6799\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7322\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.36it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5120\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5594\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7548\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.94it/s] \n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4919\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5675\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7696\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:01<00:00, 98.02it/s] \n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3504\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7737\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.42it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4553\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5776\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7872\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4712\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8120\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.4524\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.0007\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.0468\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 8.4321\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.0806\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1624\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.29it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2109\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6110\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5114\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.67it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.6270\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6059\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7180\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 78.13it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4571\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3604\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8218\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 75.21it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3843\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2333\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8573\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.57it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3773\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4262\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8602\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 77.06it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3395\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1888\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8759\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 76.53it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3245\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2385\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8877\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.90it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2948\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8933\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.5169\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3215\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8810\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.4397\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 10.9095\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 9.8383\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.8052\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1762\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3592\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5604\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5911\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.23it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4143\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1512\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8695\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.51it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3032\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5624\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9078\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.01it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2967\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4339\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9110\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.51it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2791\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2354\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9163\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.66it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2634\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1663\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9241\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.68it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2347\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3180\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9346\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.51it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.2370\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.1524\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9328\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 10.0318\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 10.7821\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1723\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9470\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 16.1786\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 14.4875\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.3305\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1894\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.80it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3370\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7124\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4744\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.28it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5229\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2832\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.26it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4084\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4292\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8842\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.08it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3889\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4586\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8878\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.59it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3386\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4810\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9084\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.76it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3630\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9014\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.68it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3590\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4123\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8973\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.08it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.3200\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2051\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9157\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.5798\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 7.8072\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.6740\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1975\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9360\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.6359\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.7789\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1872\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.47it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9463\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5277\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4792\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.86it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.5499\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3075\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8290\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.11it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4803\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4599\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8561\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.30it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4528\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3631\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8596\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.29it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4318\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.2813\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8692\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "100%|██████████| 157/157 [00:04<00:00, 37.14it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4084\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.3609\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8820\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.41it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4222\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4990\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8739\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.68it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.4034\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4048\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8826\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.6259\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.90it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.7694\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.3477\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.00it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.7388\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2928\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.8875\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.1549\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1775\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from torch.optim import SGD\n",
    "import sys\n",
    "import torch\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR10(5)\n",
    "    model = SimpleCNN(num_classes=10)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the EWC strategy\n",
    "    ewc_lambda = 50  # Regularization strength for EWC\n",
    "    strategy = EWC(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=8,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        ewc_lambda=ewc_lambda,\n",
    "        evaluator=EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loggers=[InteractiveLogger()],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e1b732-fc19-4eac-8516-f044edb07304",
   "metadata": {},
   "source": [
    "## ewc cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87450dcf-2154-4467-8a39-1277b101bbdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.51it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4880\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9142\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0501\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.55it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8692\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9653\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1032\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.38it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6828\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3544\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1489\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.24it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5988\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7935\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1730\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.11it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5463\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7228\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1963\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.57it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4986\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2946\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2099\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.34it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4398\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4558\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2269\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.80it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3776\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0564\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2510\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 97.88it/s] \n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3379\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1838\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2634\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.06it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2753\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3616\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2867\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.28it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2019\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7280\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3036\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.87it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1869\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8152\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3155\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.13it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1250\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4910\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3331\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 104.00it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0996\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8505\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3436\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.26it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0608\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0182\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3605\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 105.72it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0426\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9512\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3675\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.45it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0088\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1216\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3749\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.78it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9593\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0159\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4018\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 95.97it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9366\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4316\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3995\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.13it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3336\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4059\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.96it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8660\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6373\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4223\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 102.31it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8556\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7290\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4279\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.82it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8248\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4958\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4351\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.99it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7863\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0992\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4504\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.57it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7449\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0146\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4637\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 103.08it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7130\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1698\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4725\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.29it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7164\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3139\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4729\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:01<00:00, 101.61it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7076\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6768\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4770\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:01<00:00, 96.76it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6561\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6560\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4931\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:01<00:00, 100.38it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6347\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2509\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4964\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.5552\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5345\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 9.8043\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 9.3161\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 9.5172\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 9.5855\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.9557\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1069\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.30it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.6600\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2368\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0383\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.43it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1616\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2741\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0493\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.52it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0537\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8220\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0733\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.28it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0043\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7595\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0834\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.17it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8698\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8047\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1091\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.45it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7575\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7840\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1469\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.28it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6985\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7056\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1635\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.96it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6360\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4991\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1800\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.89it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5739\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6414\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2086\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.30it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4984\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2998\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2326\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.64it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4353\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6947\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2519\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.92it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3817\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9049\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2720\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 74.40it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3040\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5531\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2881\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.68it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2206\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9158\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3143\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.85it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1745\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0960\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3269\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.81it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1215\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8491\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3430\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.97it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0558\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9290\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3663\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.09it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0210\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7914\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3738\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.03it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9848\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8160\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3830\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.55it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9241\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1983\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3960\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.97it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8952\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6696\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4132\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.09it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8638\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7061\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4202\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.41it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8292\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3643\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4398\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.90it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7988\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2163\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4374\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.12it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7660\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1350\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.95it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7509\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7985\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4545\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.81it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7188\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0577\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4702\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.61it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7207\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3718\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4683\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.86it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6709\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4802\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 73.32it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6610\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9229\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4849\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.8572\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.5142\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5300\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.06it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.4670\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.5055\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.6147\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.1917\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1060\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.27it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.1913\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.5350\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0242\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.65it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4865\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.5742\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0385\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.99it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3684\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3560\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0414\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.59it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0845\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0460\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0821\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.03it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.9186\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0189\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1059\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.63it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8274\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4114\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1318\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.64it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7578\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8414\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.45it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6644\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7257\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1737\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.55it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5726\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6261\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1938\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.54it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4974\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5220\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2139\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.11it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4410\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4448\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2325\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.58it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3738\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2993\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2555\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.54it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3099\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8918\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2841\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.41it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2605\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0917\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2985\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.46it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2085\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4614\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3147\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.29it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1585\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3229\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3356\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.74it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1019\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8724\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3473\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.39it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0847\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7832\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3599\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.68it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0489\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2669\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3650\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.25it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0043\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0325\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3826\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.52it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9862\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9235\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3861\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.43it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9701\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9782\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3982\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.64it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3707\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4061\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.56it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8802\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9957\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4203\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.18it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8757\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0709\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4266\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.05it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8565\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5400\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4269\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.80it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8313\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7854\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4409\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.01it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8209\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3352\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4391\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.90it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7943\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8865\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.82it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7860\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9055\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4524\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 9.2261\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 9.6260\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6715\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4880\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.1989\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.99it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.9334\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.9312\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0976\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.62it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 5.2907\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.7773\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.62it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4821\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.2359\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.41it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.0290\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.8637\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0262\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.21it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.7558\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.6623\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0488\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.04it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5916\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.5354\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0488\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.19it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4884\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.4491\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.89it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4184\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3912\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0448\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.97it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3682\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3503\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0493\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.78it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3209\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3202\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0577\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.52it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2034\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2268\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0739\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.80it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2103\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0890\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.56it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0413\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7286\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1046\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:03<00:00, 52.03it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.9664\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9171\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1185\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.29it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8966\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1314\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.98it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8382\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0236\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1435\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.08it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7463\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4252\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1689\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.71it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6132\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9684\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2056\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.35it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4996\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5376\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2398\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.89it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3204\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2578\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.67it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3500\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3779\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2758\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.46it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2891\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5101\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2987\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.97it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2289\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3415\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3137\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.06it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1918\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3257\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.43it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1424\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2762\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3445\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.29it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0694\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1542\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3666\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.08it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0019\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2583\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3834\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.58it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9962\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7939\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3920\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.22it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9658\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4570\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3960\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.79it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9323\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4880\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4051\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.93it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8923\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0942\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4195\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.09it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 8.6179\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.9236\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.08it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.9499\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.11it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.7580\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4650\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.10it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.7794\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.0058\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0930\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.50it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.7476\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.2657\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0067\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.11it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4667\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.1736\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0463\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.02it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3332\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9188\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0686\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.53it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1917\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8209\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0994\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.28it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0245\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9813\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1345\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.26it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8284\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0854\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1711\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.40it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6782\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5617\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2083\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.96it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5487\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5607\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2314\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.45it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4622\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7878\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2503\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.96it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3917\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5520\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2748\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.23it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3246\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5484\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2988\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.08it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2660\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6642\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3098\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.24it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1873\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1963\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3361\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.84it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1339\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0646\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3573\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.30it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0562\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2553\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3788\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.27it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0166\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1951\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3895\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.15it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9786\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8010\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3996\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.44it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9483\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3750\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.56it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9105\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7703\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4218\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.11it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8807\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9880\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4340\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.87it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9577\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4387\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.46it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8338\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6868\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4492\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.75it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8009\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6053\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4532\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.52it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7824\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8463\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4600\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.27it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7598\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7009\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4683\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.01it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7557\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5662\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4671\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.31it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7377\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1043\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4752\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.59it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7246\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5328\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4857\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.18it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7035\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9446\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4857\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.45it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6882\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6139\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4896\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.4626\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.1494\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.97it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.7236\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.2281\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.98it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.5021\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5275\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.6132\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1055\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitCIFAR100\n",
    "from torch.optim import SGD\n",
    "import sys\n",
    "import torch\n",
    "from avalanche.training.determinism.rng_manager import RNGManager\n",
    "from avalanche.checkpointing import maybe_load_checkpoint, save_checkpoint\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR100(5)\n",
    "    model = SimpleCNN(num_classes=100)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the EWC strategy\n",
    "    ewc_lambda = 0.1  # Regularization strength for EWC\n",
    "    strategy = EWC(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=30,\n",
    "        eval_mb_size=64,\n",
    "        device=device,\n",
    "        ewc_lambda=ewc_lambda,\n",
    "        evaluator=EvaluationPlugin(\n",
    "            accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "            loggers=[InteractiveLogger()],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46356f-3242-4330-8860-4df5e158f5e9",
   "metadata": {},
   "source": [
    "# Size of the replay buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e251f-0999-4427-b68a-fa659ba232b0",
   "metadata": {},
   "source": [
    "## Size of the replay buffer = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe09b755-d531-440a-abb3-01ece55938bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:33<00:00, 23.30it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2045\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7487\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1794\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 782/782 [00:07<00:00, 109.47it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8304\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6864\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2883\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 782/782 [00:07<00:00, 111.56it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6510\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8016\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3739\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 111.15it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7666\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4279\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.95it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4324\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8124\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4735\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.17it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3464\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4037\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5073\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:06<00:00, 113.79it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2831\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0591\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5363\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:06<00:00, 114.62it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2334\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0993\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5581\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:07<00:00, 109.87it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2008\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0863\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5687\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 111.59it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1723\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3371\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5808\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:06<00:00, 113.68it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1400\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3556\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5903\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:06<00:00, 113.52it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3222\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6058\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.55it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0891\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4191\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6153\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 106.16it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0704\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7753\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6197\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:07<00:00, 102.95it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0509\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4909\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6288\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 104.30it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0415\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4144\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6306\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:07<00:00, 102.15it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0275\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9858\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6394\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 101.72it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0127\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0336\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6446\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:07<00:00, 108.30it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0018\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0068\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6485\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:07<00:00, 103.20it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9945\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4077\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6548\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:07<00:00, 108.13it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9872\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2561\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6546\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 95.99it/s] \n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9783\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0540\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6577\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.36it/s] \n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9718\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0049\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6584\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 92.70it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9703\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9348\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6585\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:08<00:00, 97.69it/s] \n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9554\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4400\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6665\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 96.47it/s] \n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9467\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.6813\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6693\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 782/782 [00:08<00:00, 95.56it/s] \n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9406\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1326\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6737\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 89.83it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9346\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0543\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6755\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:08<00:00, 92.90it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9303\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9549\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6777\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:08<00:00, 94.40it/s] \n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9282\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5176\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6776\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.59it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8447\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7268\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.90it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.4705\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.5969\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.1561\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.6402\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.5840\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.2671\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3634\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.00it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3574\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9191\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2523\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.28it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3641\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7820\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3521\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.43it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1152\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9554\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3972\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.55it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0086\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8192\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4192\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.55it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9141\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6570\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4412\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.55it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8529\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6825\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4586\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.43it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8142\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6379\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4642\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.54it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7815\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7526\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4774\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.18it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7328\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5294\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4841\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.16it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7158\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4304\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4888\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.38it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6710\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1609\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5100\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.82it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6651\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1501\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5026\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.16it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6442\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8198\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5117\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.81it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6133\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1605\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5255\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.82it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6007\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2841\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5240\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.56it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5748\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2143\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5295\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.62it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5528\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4585\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5410\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.93it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5592\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6027\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5352\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.93it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5278\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1358\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5422\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.26it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5241\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3381\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5451\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.74it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5130\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1672\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5507\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.04it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4819\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1790\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5555\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.13it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4720\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4303\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5620\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.15it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4815\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3274\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5576\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.28it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4790\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2167\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5586\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.50it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4566\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5647\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.59it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4573\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2271\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5613\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.85it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4371\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1067\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5688\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.91it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4368\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1230\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5685\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.29it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4257\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9369\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5713\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.47it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.4412\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5982\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.5039\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5465\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.9981\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.2143\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.3538\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.2698\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 5.4546\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3538\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.96it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.8957\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8329\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1576\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.69it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7475\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4362\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2864\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.13it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4558\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8990\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3311\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.80it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3027\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3078\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3624\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.06it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2220\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1843\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3778\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.93it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1496\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1363\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3977\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.32it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1131\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0856\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4074\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.30it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0789\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8794\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4139\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.31it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0370\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0694\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4273\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.21it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0050\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6689\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4344\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.18it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9835\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9837\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4362\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.14it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9630\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4446\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.91it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9430\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1902\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4469\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.48it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9135\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6942\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4513\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.85it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8949\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3589\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4550\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.81it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8866\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6653\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4607\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.32it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8708\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7743\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4649\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.62it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8519\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6025\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4711\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.57it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8530\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6865\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4719\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.57it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8424\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3320\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4706\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.17it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8324\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8787\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4768\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.05it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8132\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4848\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.43it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8164\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8780\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4784\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.54it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7960\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7351\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4859\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.69it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7853\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6438\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4882\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.58it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7697\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7642\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4926\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.42it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7491\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7659\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4949\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.07it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7547\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6361\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4945\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.63it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7291\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7968\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4985\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.77it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7359\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4371\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5020\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:19<00:00,  8.11it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.0571\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4656\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.3602\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3410\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6984\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.5300\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.2758\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.78it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.7888\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.7897\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 5.0198\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3199\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:23<00:00,  6.79it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4712\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.6682\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0549\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.44it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.3392\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7885\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1986\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.05it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7043\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2300\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2771\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.43it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4436\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1987\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3229\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.05it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3364\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2853\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3420\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.30it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2628\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5566\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3587\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.70it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2172\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2729\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3621\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.81it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1914\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1730\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3758\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.05it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1622\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0985\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3803\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.09it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1612\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2748\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3827\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.88it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1188\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1567\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3924\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.10it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1111\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2444\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3914\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.91it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1003\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3721\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3985\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.42it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1039\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0213\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3953\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.39it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0643\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8371\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4067\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.87it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0552\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8306\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4071\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.57it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0451\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0388\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4102\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.82it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0400\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9097\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4090\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.26it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0198\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9836\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4157\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.42it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0105\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1910\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4179\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.79it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0094\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4138\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.28it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9974\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6680\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4247\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.23it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9810\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9765\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4261\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.93it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9703\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7724\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4237\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.57it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1291\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4280\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.33it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9469\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9744\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4378\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.44it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9422\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9368\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4315\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.57it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9394\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8485\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4367\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.43it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9315\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0023\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4361\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.80it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9263\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9589\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4414\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:20<00:00,  7.51it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.5434\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3318\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.8316\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2750\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.72it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.8534\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2605\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.7901\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5090\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.8318\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.6120\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 4.3636\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2703\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.04it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.5562\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3350\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0802\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.30it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2438\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4427\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2220\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.82it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6392\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5705\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3004\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.56it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4507\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1572\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3366\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.04it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3682\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3822\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3539\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.17it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2963\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5345\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3691\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.14it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2510\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2020\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3793\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.93it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2312\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5029\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3833\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.43it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2033\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5873\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3896\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.72it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1932\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5173\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3921\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.03it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1642\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0216\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3948\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.33it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1477\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2419\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4028\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.09it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1519\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1813\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3953\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.51it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1330\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9932\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4013\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.05it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1188\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9184\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4019\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.04it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1194\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0127\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4035\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.05it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1066\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2503\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4136\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.80it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0785\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1828\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4154\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.54it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0875\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0272\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.86it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0738\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3752\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4137\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2625\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.80it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0635\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7515\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4199\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.55it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0513\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1415\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4196\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.18it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0581\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1293\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4242\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.18it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0366\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0050\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4292\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.43it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0271\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9118\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4310\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.07it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0184\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3114\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4277\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.37it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0098\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9047\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4322\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.57it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0028\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9758\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4334\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.38it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0142\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0500\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4310\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.09it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9866\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8818\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4350\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.87it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.0433\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2635\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.3218\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2320\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.3405\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2015\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.78it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.1469\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1920\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.7488\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5330\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.8750\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.8650\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2476\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.98it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.7744\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.7207\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0482\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2250\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.09it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5620\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7200\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2044\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.79it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7074\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6437\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3016\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2625\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.81it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4919\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5707\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3457\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.05it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4077\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3786\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3621\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.79it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3344\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4167\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3764\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.39it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2880\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3052\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3855\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.18it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2701\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1569\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3951\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.81it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2492\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2199\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3960\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.18it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2216\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3325\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4029\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.98it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2086\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3994\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4078\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.75it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1760\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3740\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4106\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.62it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1911\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9231\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4091\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.56it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1622\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0208\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4170\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.79it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1481\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8965\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4187\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.82it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1291\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1525\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4218\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.05it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1252\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2148\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4304\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.78it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1186\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1888\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4257\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.06it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1229\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3634\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4224\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.06it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1088\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0864\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4266\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.44it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0763\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1222\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4385\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.16it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0729\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0840\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4380\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.30it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0699\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5356\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4380\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.11it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0490\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2151\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4397\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.30it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0616\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9340\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4367\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.81it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0435\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0017\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4416\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.05it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0405\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9646\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4428\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.30it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0228\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0657\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4480\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.55it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0141\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7562\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4458\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.19it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0199\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0444\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4515\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.95it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.3155\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2526\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.7409\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1605\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.8287\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1630\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.85it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.7047\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1505\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.4185\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1575\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 1.7464\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.5635\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.3017\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2458\n"
     ]
    }
   ],
   "source": [
    "# Size of the replay buffer = 2000\n",
    "from avalanche.training.supervised.strategy_wrappers import Replay\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Replay\n",
    "    strategy = Replay(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        mem_size=2000,               # Size of the replay buffer\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    initial_exp=0\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c6cd1f-01f7-46c9-8b4e-671bff1969d9",
   "metadata": {},
   "source": [
    "## Size of the replay buffer = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "820900d3-1122-482a-a843-e25cf8f95521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 782/782 [00:28<00:00, 27.12it/s] \n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2028\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7332\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1816\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 782/782 [00:08<00:00, 93.20it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8276\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7671\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 782/782 [00:08<00:00, 89.45it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6578\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9236\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3717\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 782/782 [00:09<00:00, 86.70it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5363\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7937\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4228\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 782/782 [00:09<00:00, 86.31it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4344\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6117\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4737\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:09<00:00, 86.60it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3477\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5996\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5080\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:09<00:00, 83.55it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2877\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1716\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5331\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:09<00:00, 85.58it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2377\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1052\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5531\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:09<00:00, 83.82it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1998\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9744\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5703\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:09<00:00, 85.74it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1695\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4488\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5807\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 88.91it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1426\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4121\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5911\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:08<00:00, 89.52it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1103\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4981\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6063\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:08<00:00, 90.10it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0985\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9850\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6099\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:09<00:00, 82.58it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0761\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9438\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6173\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.31it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0623\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5905\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6248\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.07it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0420\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3471\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6327\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:09<00:00, 78.67it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0264\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8844\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6393\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.96it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0157\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0214\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6439\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:09<00:00, 78.83it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0040\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2878\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.07it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9976\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8129\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6505\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.02it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9886\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0726\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6526\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.08it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9813\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2800\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6547\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.88it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9752\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7554\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6569\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.03it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9698\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8085\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6622\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.35it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9700\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4636\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6614\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 782/782 [00:09<00:00, 80.20it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9525\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9059\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6669\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.03it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9446\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8148\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6688\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 782/782 [00:09<00:00, 80.13it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9432\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2189\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6699\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:09<00:00, 79.37it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9360\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8986\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6743\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 782/782 [00:09<00:00, 80.29it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9358\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.4230\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6761\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:25<00:00,  6.16it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8563\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7088\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.9977\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.76it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.1138\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.6265\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 12.5435\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 11.5545\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.4118\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3544\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.94it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.4943\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1903\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.59it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5556\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9241\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3093\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.86it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2954\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0421\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3539\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.32it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1821\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7835\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3778\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.58it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0912\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7828\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3991\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.27it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0206\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7676\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4153\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.30it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9700\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6936\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4276\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.98it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9236\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8889\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4347\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.62it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8965\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9157\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4487\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.80it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8692\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4525\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.74it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8479\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5670\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4594\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.20it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8130\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5839\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4695\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.38it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7929\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8145\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4742\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.57it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7721\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7925\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4799\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.80it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7635\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5737\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4833\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.58it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7266\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2535\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4912\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.58it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7273\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4212\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4931\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.70it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7145\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7657\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4924\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.02it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7102\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4731\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4977\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.56it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6782\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6378\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5057\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.31it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6581\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4378\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5049\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.60it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6647\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3694\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5057\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.72it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6450\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4707\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.61it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6346\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6715\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5162\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.94it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6321\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3431\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5170\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.98it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6200\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3122\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5181\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.69it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6152\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5697\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5247\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.51it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5904\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5263\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5300\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.99it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6006\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7646\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5286\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.40it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5782\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3551\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5314\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:19<00:00,  8.19it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.2839\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6429\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.77it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.6684\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5230\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 10.7117\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 10.4531\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 10.7457\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 10.3862\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 5.0385\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3738\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  6.88it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.9670\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0347\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1605\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1625\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.06it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8833\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1848\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2518\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.04it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5822\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4694\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2957\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 62.05it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4750\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3700\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3148\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.15it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4073\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1071\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3320\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.15it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3564\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2452\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3412\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.36it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3125\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3652\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3532\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.12it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2809\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2000\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3629\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.45it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2661\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5735\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3645\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.50it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2550\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0933\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3668\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.19it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2262\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1309\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3770\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.54it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2175\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9495\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3751\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.73it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1954\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0099\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3826\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.30it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1860\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2975\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3835\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.56it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1807\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0946\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3867\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.63it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1639\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2649\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.78it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1456\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1173\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3935\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.25it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1335\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0704\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3982\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.21it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1478\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1556\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3992\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.29it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1162\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1419\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3987\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.74it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1252\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2160\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4000\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.70it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1035\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9258\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4077\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4750\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.75it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1114\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1942\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4071\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.87it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0858\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0016\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4117\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.47it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0850\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1177\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4115\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.73it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0812\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9970\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4150\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.66it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0736\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1393\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4191\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.39it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0684\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1796\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4189\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.66it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0558\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1509\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4180\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.02it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0465\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1179\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4207\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.46it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.9753\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4554\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.76it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1465\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4135\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.9426\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4755\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 10.3974\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.91it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 10.7056\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.91it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 9.9978\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 4.5066\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3166\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.03it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.3194\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.4373\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0810\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.04it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1390\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7181\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2251\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.14it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6772\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7740\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2941\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.86it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5068\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7905\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3291\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2625\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.80it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4348\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4622\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3437\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.76it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3820\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0933\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3521\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.97it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3627\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5298\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3634\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.76it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3302\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3790\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3670\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.61it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2983\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3723\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.25it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2869\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3787\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3733\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.77it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2594\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2125\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3805\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.10it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2576\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5397\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3836\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.50it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2440\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2989\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3909\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.30it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2342\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4173\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3917\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.97it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2266\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4036\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3908\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.70it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1990\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3334\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3967\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.44it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1974\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1575\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3969\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4000\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.27it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1879\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4055\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4007\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.00it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1746\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7162\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4040\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.95it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1722\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0235\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4019\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.76it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1563\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3921\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4032\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.94it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1589\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2279\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4083\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.45it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1724\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1542\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4059\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.09it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1430\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5077\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4091\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.38it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1384\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0222\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4088\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.29it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1353\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5400\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4125\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.31it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1259\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2204\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4149\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.23it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1184\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4731\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4155\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.76it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1107\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4728\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4178\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.11it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0955\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2928\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4195\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.51it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.1847\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4270\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.4365\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3365\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.7445\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2480\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.6577\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5685\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.87it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.1451\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.84it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 10.6880\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.9595\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3288\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:21<00:00,  7.18it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.7949\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.4345\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0224\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0250\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.33it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.0634\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.7302\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0924\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1625\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.21it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2232\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8224\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2194\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.53it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7776\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6799\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2821\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.83it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5891\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7130\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3167\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.02it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5163\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6980\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3301\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2750\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.54it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4847\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0248\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3353\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.76it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4400\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6087\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3447\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2750\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.17it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4276\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5926\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3458\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.43it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4061\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6879\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3558\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.37it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3959\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6731\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3579\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2750\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.32it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3827\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8714\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3665\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.94it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6988\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3632\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.85it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3596\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5237\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3716\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.66it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3615\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6747\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3691\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.61it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3438\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5165\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3705\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.73it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3258\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5083\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3791\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.73it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3270\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8385\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3779\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.01it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3144\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3021\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3776\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.37it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3110\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4326\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3790\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.12it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3031\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4199\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3844\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.31it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2795\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3911\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3838\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.75it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2960\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5754\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3826\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3625\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.11it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2868\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4792\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3872\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.41it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2888\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2684\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3864\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.70it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2770\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5669\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3836\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.94it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2696\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3904\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.90it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2615\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6343\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3925\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.01it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2607\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7517\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3939\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.11it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2452\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6176\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3971\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.40it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.4975\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3266\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.8510\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2570\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.0028\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2080\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.7615\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2715\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.76it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.6947\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5950\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 10.9013\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.3699\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2964\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.09it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.7642\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.7197\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0529\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.42it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.6182\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.3556\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1850\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2125\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.26it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.9142\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.2644\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2672\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.28it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.7318\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0052\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3038\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2375\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.14it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6485\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0079\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3201\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.74it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5801\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8502\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3307\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2750\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.07it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5708\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6791\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3384\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2750\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.59it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5581\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8440\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3381\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.41it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5175\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7882\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3491\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.10it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5203\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7047\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3539\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2625\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.20it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5077\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4474\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3495\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.49it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4892\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5714\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3570\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.17it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4804\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8231\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3556\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.99it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4620\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4274\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3612\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.59it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4474\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2940\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3623\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.29it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4330\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5694\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3692\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3250\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.51it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4228\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7063\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3674\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2875\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.31it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4222\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7796\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3709\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3375\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.34it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4251\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4937\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3732\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.39it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4132\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3910\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3682\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.39it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3890\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3323\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3779\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.36it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4169\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0250\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3713\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2250\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.22it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4002\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7830\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3793\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.50it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4042\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0930\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3752\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.95it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3843\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6579\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3794\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2625\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.53it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3873\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5062\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3757\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3500\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.95it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3865\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9066\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3786\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 68.47it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3745\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.8349\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3789\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.92it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3684\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7471\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3820\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2000\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.40it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3728\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5485\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3807\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.66it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.6444\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3240\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.1004\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2325\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.3808\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1800\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.80it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.9266\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2005\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.9235\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2380\n",
      "-- Starting eval on experience 5 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 5 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp005 = 1.7726\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.5840\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.7326\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3055\n"
     ]
    }
   ],
   "source": [
    "# Size of the replay buffer = 5000\n",
    "import sys\n",
    "from avalanche.training.supervised.strategy_wrappers import Replay\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR110(6)\n",
    "    model = SimpleCNN(num_classes=110)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Replay\n",
    "    strategy = Replay(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        mem_size=5000,               # Size of the replay buffer\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    initial_exp=0\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42733e43-d85e-4cc1-8ed7-7cf76878de3c",
   "metadata": {},
   "source": [
    "# test statistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f717f-fff2-4e53-90da-53417366e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Example data for dropout = 0.05\n",
    "accuracies_005 = np.random.rand(8, 5, 5)  # Replace with your actual data\n",
    "# Example data for dropout = 0.01\n",
    "accuracies_001 = np.random.rand(8, 5, 5)  # Replace with your actual data\n",
    "\n",
    "# Flatten the 3D arrays into 1D arrays\n",
    "flattened_005 = accuracies_005.flatten()\n",
    "flattened_001 = accuracies_001.flatten()\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "result = mannwhitneyu(x=flattened_005, y=flattened_001, alternative='two-sided')\n",
    "\n",
    "# Output the results\n",
    "print(f\"Statistic: {result.statistic}, p-value: {result.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b173ca7-d1b0-4406-a78d-7ada7d8c4341",
   "metadata": {},
   "source": [
    "# replay with different model (p=0.05 , size of buffer = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a7aef-7f4f-4bba-bce8-bd56354927fd",
   "metadata": {},
   "source": [
    "## with simpleCNN64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e96bf90-4878-48c6-be9f-11e159c536c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN64(nn.Module):\n",
    "    #p=0.05\n",
    "\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(SimpleCNN64, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.05),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(64, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32d5f4db-4a46-425d-b035-a98a97d7b614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5424\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 3.0843\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0421\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.97it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8241\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5218\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1068\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.01it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6274\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4026\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1685\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.84it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4893\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2139\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.79it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3952\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6142\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2504\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:08<00:00, 17.90it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3117\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9885\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2814\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.18it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2040\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2276\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3148\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.99it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1096\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8553\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3418\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:06<00:00, 25.00it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0283\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5967\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3688\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:06<00:00, 22.63it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9870\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6561\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3885\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.06it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8923\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6800\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4132\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:07<00:00, 22.39it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8269\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3860\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4381\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.57it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7606\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0760\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4602\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.72it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7057\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9372\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4713\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.69it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6479\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3681\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4887\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.78it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6027\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9502\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5056\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.64it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5713\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9319\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5138\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.93it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4920\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6468\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5390\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.75it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4962\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2222\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5398\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.51it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4383\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1624\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5615\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:06<00:00, 22.54it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3944\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2189\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5681\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.80it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3504\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2622\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5889\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.43it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3251\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3065\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5914\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.53it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3008\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8347\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6023\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.25it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2872\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4978\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6048\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.71it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2524\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1496\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6134\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.79it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2434\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1260\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6173\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.67it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2156\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1173\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6232\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:06<00:00, 22.48it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1749\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6805\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6368\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:06<00:00, 24.73it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1610\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9606\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6432\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.62it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1634\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6415\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 11.9850\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:20<00:00,  1.60it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.7341\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.70it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 11.8895\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.65it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 11.9237\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.7391\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1283\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:26<00:00,  6.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0655\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2608\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.03it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0439\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6218\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4273\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:05<00:00, 29.42it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8433\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7417\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4713\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:04<00:00, 35.88it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7225\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5246\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4971\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.76it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6349\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2738\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5248\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.98it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5853\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5342\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5319\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.85it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5275\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6123\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5504\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.37it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4851\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4512\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5658\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.73it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4415\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8714\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5726\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.93it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4138\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5065\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5793\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:03<00:00, 52.08it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3845\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0769\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5864\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.56it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3441\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1861\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5995\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.78it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3346\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1349\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6011\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.34it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3027\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9685\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6110\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.11it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2846\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9778\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6129\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.43it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2575\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0291\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6206\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.11it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2285\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0912\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6314\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.91it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2171\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7510\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6322\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.66it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1946\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8981\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6390\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.85it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8269\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6464\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.42it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1649\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0104\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6456\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.43it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1377\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9231\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6522\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:03<00:00, 52.04it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1378\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7100\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6579\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:02<00:00, 53.52it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1026\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7321\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6623\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.97it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0968\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9648\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6649\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.58it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0978\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1134\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6658\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.96it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0692\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9491\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6762\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.46it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0660\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2200\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6714\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.45it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0617\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8123\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6763\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.06it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0499\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.5629\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6788\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.83it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.0819\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5125\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.90it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.3425\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5930\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.89it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 14.8220\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.73it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 14.8732\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.74it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 15.3294\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.6898\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2211\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:25<00:00,  6.12it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.2886\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7994\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2338\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.37it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0190\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2103\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4309\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.76it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8178\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4705\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.92it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7028\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6102\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5023\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.86it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6427\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5132\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5163\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.42it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5796\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4371\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5310\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.72it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5362\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4960\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5462\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.51it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4996\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3422\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5589\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.72it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4594\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3405\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5647\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.29it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4497\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9302\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5658\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.56it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4313\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0702\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5697\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.61it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3955\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2700\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5787\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.32it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3792\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8818\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5866\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.82it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3491\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8980\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5966\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.76it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3481\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5907\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.75it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3327\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8362\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5985\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.32it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2929\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1713\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6143\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.42it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2863\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1380\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6139\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.47it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2789\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8785\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6123\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.89it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2587\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1074\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6187\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.16it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2501\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0761\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6222\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.77it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2452\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7187\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6258\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.28it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2366\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1153\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6228\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.10it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2219\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1396\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6281\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.06it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2091\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7280\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6331\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8000\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.55it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2027\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8975\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6345\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.80it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1818\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3343\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6423\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.97it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1713\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9565\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6449\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.26it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1690\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8718\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6469\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.07it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1738\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7601\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6433\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.76it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.3653\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3610\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.8937\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3860\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.86it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6011\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.5255\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 16.3366\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 16.6606\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 8.1715\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2545\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:27<00:00,  5.67it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.0747\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.7343\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1015\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3000\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.44it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2348\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0667\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3879\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.89it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8140\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4076\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4850\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.28it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6772\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5658\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5188\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.88it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5949\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4020\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5366\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.20it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5511\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4043\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5487\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.86it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5050\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2824\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5595\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [36:29<00:00, 13.94s/it]   \n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4642\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6216\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5707\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.07it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4257\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2697\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5776\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.48it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4333\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3261\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5731\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.38it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3790\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4614\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.74it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3727\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0073\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5938\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.34it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3482\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2833\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6047\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.27it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3240\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2503\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6085\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.78it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3072\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4449\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6121\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.41it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2946\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2110\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6136\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.05it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2830\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0950\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6190\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.37it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2715\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2239\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6228\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.95it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2736\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1267\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6228\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.96it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2413\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1778\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6285\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.99it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2276\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9742\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6341\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.66it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2384\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9321\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6286\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.96it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2164\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0664\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6367\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.88it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2145\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1019\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6364\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.72it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2019\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9378\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6377\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:05<00:00, 28.00it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1922\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9062\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6423\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.80it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1974\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8702\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6415\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.86it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1596\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1471\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6516\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.65it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1573\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8872\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6533\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.75it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1512\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0955\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6565\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.72it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.4586\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2675\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.88it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 4.0783\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3045\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.91it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.8661\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2260\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.92it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.5543\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5460\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.89it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 18.0405\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.3996\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2688\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.08it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.7386\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.5932\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0209\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0375\n",
      "100%|██████████| 157/157 [00:02<00:00, 55.66it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.4760\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.5702\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0264\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0250\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.39it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.7999\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2118\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1262\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3875\n",
      "100%|██████████| 157/157 [00:04<00:00, 39.21it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0655\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6515\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4301\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:06<00:00, 26.14it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7084\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6862\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5088\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.40it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6424\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7063\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5241\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.44it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5732\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3451\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5439\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.50it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5309\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4369\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5522\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.05it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4988\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4290\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5598\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.40it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4540\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3424\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5752\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.60it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4547\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3926\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5738\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.49it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4238\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0414\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5826\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.53it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3858\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2816\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5893\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.34it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3776\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3367\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5932\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.06it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3461\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0197\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6005\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:05<00:00, 26.89it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3519\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5774\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6014\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.33it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3447\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1908\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6022\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.56it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3211\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2533\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6094\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.87it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2952\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9830\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6144\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.59it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2937\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0969\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6158\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.68it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2689\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8327\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6209\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.67it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2606\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2091\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6234\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.76it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2644\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0097\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6228\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.53it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2570\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0063\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6271\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.77it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2355\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0028\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6300\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.72it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2162\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9690\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6391\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.58it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2133\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2368\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6374\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.96it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1984\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8632\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6430\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.90it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2161\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1389\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6345\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:05<00:00, 27.59it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1912\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9651\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6439\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:28<00:00,  1.14it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 5.4585\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2010\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:23<00:00,  1.38it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 5.1183\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2155\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.82it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 5.1060\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1745\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.8688\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2390\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:17<00:00,  1.81it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.5772\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5460\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 4.2258\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2752\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.supervised.strategy_wrappers import Replay\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR100(5)\n",
    "    model = SimpleCNN64(num_classes=100)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Replay\n",
    "    strategy = Replay(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        mem_size=2000,               # Size of the replay buffer\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56924c26-db1c-43f8-91e8-e4e80fa93b1c",
   "metadata": {},
   "source": [
    "## with simpleCNN128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b011fd2f-3e4b-437c-bd44-574be3b70f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN128(nn.Module):\n",
    "    #p=0.05\n",
    "\n",
    "    def __init__(self, num_classes=110):\n",
    "        super(SimpleCNN128, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.05),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(64, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22704118-2e25-46e4-9627-5c38e9f45c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avalanche.training.supervised.strategy_wrappers import Replay\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR100(5)\n",
    "    model = SimpleCNN128(num_classes=100)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Replay\n",
    "    strategy = Replay(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        mem_size=2000,               # Size of the replay buffer\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165ee13-73ce-46a8-9dcb-b28a6433fa8e",
   "metadata": {},
   "source": [
    "## with simpleCNN32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "761b7e7e-eb45-4ce7-8b72-17a6ad9d4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN32(nn.Module):\n",
    "    #p=0.05\n",
    "\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(SimpleCNN32, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool2d(1),\n",
    "            nn.Dropout(p=0.05),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(64, num_classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a4f281-2016-4d38-bd26-f21d266aff6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:25<00:00,  6.23it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5174\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9440\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0583\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 85.49it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8249\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.9659\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1069\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1250\n",
      "100%|██████████| 157/157 [00:01<00:00, 88.79it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.6808\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4878\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1494\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0625\n",
      "100%|██████████| 157/157 [00:01<00:00, 88.05it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5618\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.6950\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1939\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:01<00:00, 79.57it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4447\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.5513\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2331\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 81.49it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3540\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0157\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2656\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:01<00:00, 82.36it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2599\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3433\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2937\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 83.30it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1711\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0938\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3154\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 77.15it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1047\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2795\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3125\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.95it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0330\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.4223\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3738\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.1875\n",
      "100%|██████████| 157/157 [00:01<00:00, 83.47it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9648\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2584\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3895\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 70.40it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8977\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5245\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4166\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.87it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8213\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0051\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4391\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.2500\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.89it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7831\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7539\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4502\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.70it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7262\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8938\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4609\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.60it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6671\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3209\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4834\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.76it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6087\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6260\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5065\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 64.10it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5936\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6975\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5155\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 69.43it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5409\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5902\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5253\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.35it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4874\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2328\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5463\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.28it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4528\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2952\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5514\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.67it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4166\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2983\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5637\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.42it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4045\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5112\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5685\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4375\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.50it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3651\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8325\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5860\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.60it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3223\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5918\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5910\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 67.18it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3030\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3590\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5995\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 71.61it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2742\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7114\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6132\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:02<00:00, 66.43it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2637\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9264\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6145\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 65.50it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2191\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4063\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6301\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:02<00:00, 72.22it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2166\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7564\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6200\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.2322\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6285\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.41it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.8587\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.52it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.3967\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.48it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.4508\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.46it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 13.0114\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 10.3900\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1257\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:26<00:00,  5.86it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.9934\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.0224\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2632\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:04<00:00, 38.52it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.1438\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9270\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3943\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.57it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9202\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7324\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4495\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.49it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7992\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5439\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4763\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.00it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7015\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1046\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5020\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.17it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6420\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3627\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5178\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.25it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5912\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1843\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5357\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.89it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5533\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2411\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5426\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.74it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5035\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1134\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5591\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.10it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4763\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4200\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5652\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.55it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4396\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2170\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5691\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.60it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3996\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0933\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5829\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.32it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3930\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1989\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5816\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.17it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3544\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5514\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.62it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3428\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2907\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5938\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 47.73it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3079\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1749\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6050\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.76it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2826\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1594\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6118\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.99it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2708\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7326\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6163\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.31it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2573\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8548\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6246\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.68it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2327\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1638\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6241\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.34it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2173\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2485\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6285\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.84it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1959\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0094\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6434\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.95it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1758\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3599\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6447\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.30it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1755\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9462\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6437\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.37it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1545\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1003\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6474\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.80it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1377\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8255\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6532\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7375\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.94it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1179\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9972\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6593\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.46it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.1087\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0322\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6635\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.67it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0848\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9101\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6699\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.79it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.0924\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8240\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6685\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7750\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.9621\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5075\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.5451\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5440\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 13.8402\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.44it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.5282\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:22<00:00,  1.45it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 14.2687\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 9.0289\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2103\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:25<00:00,  6.16it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.7625\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2364\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1292\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4125\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.50it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3022\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.2327\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3719\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4250\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.92it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9441\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5787\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4440\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.46it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8005\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6680\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4757\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.14it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7247\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7599\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5018\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.99it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6557\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4298\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5143\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.29it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6108\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4613\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5255\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.30it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5710\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2356\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5418\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.16it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5537\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5723\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5377\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.40it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5267\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2156\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5522\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.28it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4975\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2557\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5582\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:03<00:00, 49.53it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4672\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3111\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5624\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.96it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4558\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2128\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5703\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.42it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4365\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0152\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5712\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.21it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4277\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9952\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5757\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.06it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3918\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2858\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5852\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.17it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3670\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1344\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5920\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.52it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3667\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1240\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5897\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.06it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3441\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0129\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6025\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.65it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3388\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4057\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5975\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.79it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3187\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.7738\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6052\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.24it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3157\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9017\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6078\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7625\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.65it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3039\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9998\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6087\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.42it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2826\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1465\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6121\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.57it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2781\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9879\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6130\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.65it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2753\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2068\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6142\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.55it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2765\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2810\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6180\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.07it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2338\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0424\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6307\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.91it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2352\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8120\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6269\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8125\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.49it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2368\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8623\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6276\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.19it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.2114\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3780\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.8065\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3555\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.7265\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4870\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.47it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 15.3055\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 15.5543\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 7.7208\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2441\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:27<00:00,  5.68it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.7107\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.3084\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1845\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.3750\n",
      "100%|██████████| 157/157 [00:02<00:00, 52.68it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0478\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9319\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4296\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.76it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8147\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5633\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4811\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.69it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7090\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4911\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5045\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.51it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6366\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3354\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5244\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.08it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6013\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5324\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.73it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5753\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5053\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5398\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:03<00:00, 51.25it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5523\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6185\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5454\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.18it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5142\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7816\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5517\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4875\n",
      "100%|██████████| 157/157 [00:03<00:00, 48.29it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4750\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1601\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5635\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:03<00:00, 50.61it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4712\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0938\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5687\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "100%|██████████| 157/157 [00:03<00:00, 46.82it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4504\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5050\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5738\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.55it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4141\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2271\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5824\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.79it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4183\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1306\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5809\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.62it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3899\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3002\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5876\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.94it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3785\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.7551\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5902\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5250\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.99it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3678\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1947\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5910\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 41.46it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3380\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2307\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6008\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.28it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3424\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2589\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6024\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.64it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3199\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9987\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6033\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.51it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3051\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2056\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6111\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:03<00:00, 40.61it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2841\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1390\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6169\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 157/157 [00:03<00:00, 43.36it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2862\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0576\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6161\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:03<00:00, 42.14it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2931\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4473\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6147\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.13it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2797\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8510\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6192\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.84it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2742\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4277\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6186\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6125\n",
      "100%|██████████| 157/157 [00:04<00:00, 35.24it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2543\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3600\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6213\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:03<00:00, 45.38it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2444\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.8953\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6257\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7250\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.27it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2178\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2960\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6332\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5750\n",
      "100%|██████████| 157/157 [00:03<00:00, 44.38it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2242\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9906\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6356\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7500\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:27<00:00,  1.17it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.4136\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2885\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:26<00:00,  1.23it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.9756\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2875\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.49it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.8445\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2310\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.96it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.5341\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5455\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.02it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 17.3849\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 6.2305\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2705\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 157/157 [00:18<00:00,  8.36it/s]\n",
      "Epoch 0 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.6206\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 4.2691\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0401\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.0875\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.58it/s]\n",
      "Epoch 1 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.1029\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 2.1611\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2387\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4625\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.53it/s]\n",
      "Epoch 2 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.9781\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.8114\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4497\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5125\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.19it/s]\n",
      "Epoch 3 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.7678\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4311\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4976\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 60.32it/s]\n",
      "Epoch 4 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6787\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5175\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.34it/s]\n",
      "Epoch 5 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.6478\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2286\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5279\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.96it/s]\n",
      "Epoch 6 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5912\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.6066\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5416\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.56it/s]\n",
      "Epoch 7 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5644\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0922\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5502\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6500\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.07it/s]\n",
      "Epoch 8 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.5244\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.2428\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5582\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.96it/s]\n",
      "Epoch 9 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4902\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.9094\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5678\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.4500\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.57it/s]\n",
      "Epoch 10 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4678\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1716\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5701\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6750\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.86it/s]\n",
      "Epoch 11 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4680\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5054\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5722\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:02<00:00, 59.48it/s]\n",
      "Epoch 12 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4279\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4012\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5819\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6000\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.36it/s]\n",
      "Epoch 13 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4225\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3448\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5823\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.05it/s]\n",
      "Epoch 14 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.4003\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.4892\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5878\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5500\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.16it/s]\n",
      "Epoch 15 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3919\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3901\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 54.90it/s]\n",
      "Epoch 16 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3946\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0171\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5922\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 61.80it/s]\n",
      "Epoch 17 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3539\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0267\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6008\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:02<00:00, 63.05it/s]\n",
      "Epoch 18 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3609\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5101\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5955\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5375\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.06it/s]\n",
      "Epoch 19 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3274\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3039\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6088\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5875\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.72it/s]\n",
      "Epoch 20 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3295\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1647\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6077\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.11it/s]\n",
      "Epoch 21 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3277\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0806\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6064\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.74it/s]\n",
      "Epoch 22 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2934\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.5817\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6208\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.5625\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.93it/s]\n",
      "Epoch 23 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.3072\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9831\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6148\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.94it/s]\n",
      "Epoch 24 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2638\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9806\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6295\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6625\n",
      "100%|██████████| 157/157 [00:02<00:00, 56.36it/s]\n",
      "Epoch 25 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2727\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.0041\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6257\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.00it/s]\n",
      "Epoch 26 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2615\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9982\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6279\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7125\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.42it/s]\n",
      "Epoch 27 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2619\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.3581\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6305\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6375\n",
      "100%|██████████| 157/157 [00:02<00:00, 58.27it/s]\n",
      "Epoch 28 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2658\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 0.9653\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6239\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6250\n",
      "100%|██████████| 157/157 [00:02<00:00, 57.87it/s]\n",
      "Epoch 29 ended.\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.2231\n",
      "\tLoss_MB/train_phase/train_stream/Task000 = 1.1932\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6363\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.6875\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:21<00:00,  1.51it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 5.7447\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2000\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:18<00:00,  1.77it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 4.9851\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2330\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:15<00:00,  2.05it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 5.0401\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1930\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.95it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.1320\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.2130\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:16<00:00,  1.94it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.5043\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.5605\n",
      "-- >> End of eval phase << --\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000 = 4.2812\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2799\n"
     ]
    }
   ],
   "source": [
    "from avalanche.training.supervised.strategy_wrappers import Replay\n",
    "\n",
    "def main_with_checkpointing(args):\n",
    "    # STEP 1: SET THE RANDOM SEEDS to guarantee reproducibility\n",
    "    RNGManager.set_random_seeds(1234)\n",
    "\n",
    "    # Nothing new here...\n",
    "    device = torch.device(\n",
    "        f\"cuda:{args.cuda}\" if torch.cuda.is_available() and args.cuda >= 0 else \"cpu\"\n",
    "    )\n",
    "    print(\"Using device\", device)\n",
    "\n",
    "    # CL Benchmark Creation (as usual)\n",
    "    benchmark = SplitCIFAR100(5)\n",
    "    model = SimpleCNN32(num_classes=100)\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Create the evaluation plugin (as usual)\n",
    "    evaluation_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(experience=True, stream=True), loggers=[InteractiveLogger()]\n",
    "    )\n",
    "\n",
    "    # choose some metrics and evaluation method\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    eval_plugin = EvaluationPlugin(\n",
    "        accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger],\n",
    "    )\n",
    "\n",
    "    # Create the strategy using Replay\n",
    "    strategy = Replay(\n",
    "        model=model,                # Ensure your model is capable of handling the increased number of classes\n",
    "        optimizer=optimizer,        # Optimizer, e.g., Adam or SGD\n",
    "        criterion=criterion,        # Loss function, e.g., CrossEntropyLoss\n",
    "        mem_size=2000,               # Size of the replay buffer\n",
    "        train_mb_size=64,           # Batch size; adjust based on your hardware and model requirements\n",
    "        train_epochs=30,            # Increased number of epochs to ensure adequate training\n",
    "        eval_mb_size=64,            # Evaluation batch size\n",
    "        device=device,              # Device, e.g., 'cuda' or 'cpu'\n",
    "        evaluator=eval_plugin # Evaluation plugin or metric, e.g., accuracy\n",
    "    )\n",
    "\n",
    "    # STEP 2: TRY TO LOAD THE LAST CHECKPOINT\n",
    "    # if the checkpoint exists, load it into the newly created strategy\n",
    "    # the method also loads the experience counter, so we know where to\n",
    "    # resume training\n",
    "    fname = \"./checkpoint/Replay.pkl\"  # name of the checkpoint file\n",
    "    os.makedirs(os.path.dirname(fname), exist_ok=True)  # Ensure the checkpoint directory exists\n",
    "    #strategy, initial_exp = maybe_load_checkpoint(strategy, fname)\n",
    "\n",
    "    initial_exp=0\n",
    "    # STEP 3: USE THE \"initial_exp\" to resume training\n",
    "    for train_exp in benchmark.train_stream[initial_exp:]:\n",
    "        strategy.train(train_exp, num_workers=4, persistent_workers=True)\n",
    "        strategy.eval(benchmark.test_stream, num_workers=4)\n",
    "\n",
    "        # STEP 4: SAVE the checkpoint after training on each experience.\n",
    "        save_checkpoint(strategy, fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'ipykernel_launcher' in sys.argv[0]:\n",
    "        # Running in a Jupyter environment\n",
    "        class Args:\n",
    "            cuda = 0\n",
    "        args = Args()\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--cuda\",\n",
    "            type=int,\n",
    "            default=0,\n",
    "            help=\"Select zero-indexed cuda device. -1 to use CPU.\",\n",
    "        )\n",
    "        # Parse known arguments and ignore the rest\n",
    "        args, _ = parser.parse_known_args(sys.argv)\n",
    "    main_with_checkpointing(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325f20a-c644-43b7-abb3-360c488299c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
